PMID,Title,Authors,Citation,First Author,Journal/Book,Publication Year,Create Date,PMCID,NIHMS ID,DOI,abstract,,,,
20841823,Automatically detecting medications and the reason for their prescription in clinical narrative text documents,"Meystre SM, Thibault J, Shen S, Hurdle JF, South BR.",Stud Health Technol Inform. 2010;160(Pt 2):944-8.,Meystre SM,Stud Health Technol Inform,2010,2010-09-16,PMC3238676,NIHMS341930,,"An important proportion of the information about the medications a patient is 
 taking is mentioned only in narrative text in the electronic health record. 
 Automated information extraction can make this information accessible for 
 decision support, research, or any other automated processing. In the context of 
 the ""i2b2 medication extraction challenge,"" we have developed a new NLP 
 application called Textractor to automatically extract medications and details 
 about them (e.g., dosage, frequency, reason for their prescription). This 
 application and its evaluation with part of the reference standard for this 
 ""challenge"" are presented here, along with an analysis of the development of 
 this reference standard. During this evaluation, Textractor reached a 
 system-level overall F<inf>1</inf>-measure, the reference metric for this 
 challenge, of about 77% for exact matches. The best performance was measured 
 with medication routes (F<inf>1</inf>-measure 86.4%), and the worst with 
 prescription reasons (F<inf>1</inf>-measure 29%). These results are consistent 
 with the agreement observed between human annotators when developing the 
 reference standard, and with other published research.
",NLP,drug prescriptions,F1 score,i2b2 medicine extraction competition
20841784,Extraction of adverse drug effects from clinical records,"Aramaki E, Miura Y, Tonoike M, Ohkuma T, Masuichi H, Waki K, Ohe K.",Stud Health Technol Inform. 2010;160(Pt 1):739-43.,Aramaki E,Stud Health Technol Inform,2010,2010-09-16,,,,"With the rapidly growing use of electronic health records, the possibility of 
 large-scale clinical information extraction has drawn much attention. We aim to 
 extract adverse drug events and effects from records. As the first step of this 
 challenge, this study assessed (1) how much adverse-effect information is 
 contained in records, and (2) automatic extracting accuracy of the current 
 standard Natural Language Processing (NLP) system. Results revealed that 7.7% of 
 records include adverse event information, and that 59% of them (4.5% in total) 
 can be extracted automatically. This result is particularly encouraging, 
 considering the massive amounts of records, which are increasing daily.
",NLP,notes,,
20841665,A usability study of patient-friendly terminology in an EMR system,"Hong Y, Ehlers K, Gillis R, Patrick T, Zhang J.",Stud Health Technol Inform. 2010;160(Pt 1):136-40.,Hong Y,Stud Health Technol Inform,2010,2010-09-16,,,,"Misunderstandings due to terminology differences between health care providers 
 and consumers may cause communication problems and adversely affect consumer 
 access to health information, resulting in poor satisfaction for patients and 
 providers. To investigate the usage patterns of consumer health vocabulary and 
 evaluate controlled terminologies used in electronic medical records, we 
 conducted a usability study of patient-friendly terms used in an ambulatory 
 electronic medical record (EMR) and associated patient web portal. After 
 identifying 340 unique diagnosis term/patient-friendly term pairs, we mapped the 
 term pairs determined by UMLS to be pairs of synonyms, near-synonyms, or 
 closely-related terms to the keywords of search queries extracted from a 
 consumer health information web portal to learn the comparative frequency of use 
 of members of each pair by consumers. We found out that use of patient-friendly 
 terms could help to bridge the language gap between providers and consumers but 
 not always. In some cases the professional diagnosis terms were used more 
 frequently than their patient-friendly counterparts, typically in cases where 
 the professional terms were more simple or common than the patient-friendly 
 terms.
",unrelated,,,investigate the usage patterns of consumer health vocabulary and  evaluate controlled terminologies used in electronic medical records 
20543306,Secondary use of clinical data,"Elkin PL, Trusko BE, Koppel R, Speroff T, Mohrer D, Sakji S, Gurewitz I, Tuttle M, Brown SH.",Stud Health Technol Inform. 2010;155:14-29.,Elkin PL,Stud Health Technol Inform,2010,2010-06-15,,,,"Clinicians involved in clinical care generate daily volumes of important data. 
 This data is important for continuity of care, referrals to specialists and back 
 to the patient's medical home. The same data can be used to generate alerts to 
 improve the practice and to generate care activities to ensure that all 
 appropriate care services are provided for the patient given their known medical 
 histories using electronic quality (eQuality) monitoring. For many years we have 
 used patient records as a data source for human abstraction of clinical research 
 data. With the advent of electronic health record (EHR) data we can now make use 
 of computable EHR data that can perform retrospective research studies more 
 rapidly and lower the activation energy necessary to ask the next important 
 question using electronic studies (eStudies). Barriers to these eStudies 
 include: the lack of interoperable data between and among practices, the lack of 
 computable definitions of measures, the lack of training of health professionals 
 to use Ontology based Informatics tools that allow the execution of this type of 
 logic, common methods need to be developed to distribute computable best 
 practice rules to ensure rapid dissemination of evidence, better translating 
 research into practice.
",review,,,
20841882,A qualitative analysis of Emergency Department physicians' practices and perceptions in relation to test result follow-up,"Callen J, Georgiou A, Prgomet M, Paoloni R, Westbrook J.",Stud Health Technol Inform. 2010;160(Pt 2):1241-5.,Callen J,Stud Health Technol Inform,2010,2010-09-16,,,,"Follow-up of abnormal test results for discharged Emergency Department (ED) 
 patients is a critical safety issue. This study aimed to explore ED physicians' 
 perceptions, practices, and suggestions for improvements of test result 
 follow-up when using an electronic provider order entry system to order all 
 laboratory and radiology tests and view results. Interviews were conducted with 
 seven ED physicians and one clinical information system support person. 
 Interviews were analyzed to elicit key concepts relating to physicians' 
 perceptions of test result follow-up and how the process could be improved. 
 Results described the current electronic test result follow-up system with two 
 paper-based manual back-up systems for microbiology and radiology results. The 
 key issues for physicians were: responsibility for test follow-up; the unique ED 
 environment and time pressures, and the role of the family physician in test 
 result follow-up. The key suggestion for improvement was a complete integrated 
 electronic information system with on-line result endorsement. The study 
 highlighted the complexity of the test result follow-up process and the 
 importance of engaging clinicians in devising solutions for improvements.
",physicians' practices and perceptions ,,interview,
21335697,Longitudinal analysis on utilization of medical document management system in a hospital with EPR implementation,"Kuwata S, Yamada H, Park K.",Stud Health Technol Inform. 2011;164:117-21.,Kuwata S,Stud Health Technol Inform,2011,2011-02-22,,,,"Document management systems (DMS) have widespread in major hospitals in Japan as 
 a platform to digitize the paper-based records being out of coverage by EPR. 
 This study aimed to examine longitudinal trends of actual use of DMS in a 
 hospital in which EPR had been in operation, which would be conducive to 
 planning the further information management system in the hospital. Degrees of 
 utilization of electronic documents and templates with DMS were analyzed based 
 on data extracted from a university-affiliated hospital with EPR. As a result, 
 it was found that the number of electronic documents as well as scanned 
 documents circulating at the hospital tended to increase. The result indicated 
 that replacement of paper-based documents with electronic documents did not 
 occur. Therefore it was anticipated that the need for DMS would continue to 
 increase in the hospital. The methods used this study to analyze the trend of 
 DMS utilization would be applicable to other hospitals with with a variety of 
 DMS implementation, such as electronic storage by scanning documents or paper 
 preservation that is compatible with EPR.
",utilization,,,
22874179,RAVEL: retrieval and visualization in ELectronic health records,"Thiessard F, Mougin F, Diallo G, Jouhet V, Cossin S, Garcelon N, Campillo B, Jouini W, Grosjean J, Massari P, Griffon N, Dupuch M, Tayalati F, Dugas E, Balvet A, Grabar N, Pereira S, Frandji B, Darmoni S, Cuggia M.",Stud Health Technol Inform. 2012;180:194-8.,Thiessard F,Stud Health Technol Inform,2012,2012-08-10,,,,"Because of the ever-increasing amount of information in patients' EHRs, 
 healthcare professionals may face difficulties for making diagnoses and/or 
 therapeutic decisions. Moreover, patients may misunderstand their health status. 
 These medical practitioners need effective tools to locate in real time relevant 
 elements within the patients' EHR and visualize them according to synthetic and 
 intuitive presentation models. The RAVEL project aims at achieving this goal by 
 performing a high profile industrial research and development program on the EHR 
 considering the following areas: (i) semantic indexing, (ii) information 
 retrieval, and (iii) data visualization. The RAVEL project is expected to 
 implement a generic, loosely coupled to data sources prototype so that it can be 
 transposed into different university hospitals information systems.
",visualization,,,
22874259,"Automatic extracting of patient-related attributes: disease, age, gender and race","Zhu H, Ni Y, Cai P, Qiu Z, Cao F.",Stud Health Technol Inform. 2012;180:589-93.,Zhu H,Stud Health Technol Inform,2012,2012-08-10,,,,"In the Evidence-based Medicine (EBM), PICO format is designed to easily and 
 correctly search for the best available evidence. As the main element of PICO, 
 the Patient/Problem (P) represents the attributes of patient in the clinical 
 question and studies. In order to better understand the clinical problems, 
 patient attribute identification is crucial and indispensable. Due to the 
 richness of the human nature language, many issues like various term 
 representations, grammar structures and abbreviations present challenges for 
 automatically extracting the patient-related attributes from the unstructured 
 data. In this paper, we employed the nature language processing (NLP) 
 technologies to deeply analyze the linguistic characteristics of the attributes. 
 Based on the NLP analysis results, we built the rule sets for different 
 attributes and applied the rule-based approach to extract the patient-related 
 attributes.
",NLP,,,
22874245,A loosely coupled framework for terminology controlled distributed EHR search for patient cohort identification in clinical research,"Zhao L, Lim Choi Keung SN, Taweel A, Tyler E, Ogunsina I, Rossiter J, Delaney BC, Peterson KA, Hobbs FD, Arvanitis TN.",Stud Health Technol Inform. 2012;180:519-23.,Zhao L,Stud Health Technol Inform,2012,2012-08-10,,,,"Heterogeneous data models and coding schemes for electronic health records 
 present challenges for automated search across distributed data sources. This 
 paper describes a loosely coupled software framework based on the terminology 
 controlled approach to enable the interoperation between the search interface 
 and heterogeneous data sources. Software components interoperate via common 
 terminology service and abstract criteria model so as to promote component reuse 
 and incremental system evolution.
",software framework,,,
22874148,Data Definition Ontology for clinical data integration and querying,"Assélé Kama A, Primadhanty A, Choquet R, Teodoro D, Enders F, Duclos C, Jaulent MC.",Stud Health Technol Inform. 2012;180:38-42.,Assélé Kama A,Stud Health Technol Inform,2012,2012-08-10,,,,"This paper describes an approach to build a Data Definition Ontology (DDO) in 
 the context of full domain ontology integration with datasets in order to share 
 and query clinical heterogeneous data repositories. We have adapted an existing 
 semantic web tool (D2RQ) to implement a process that automatically generates the 
 DDO from a database information model, thanks to reverse engineering and schema 
 mapping approaches. This study has been performed in the context of the DebugIT 
 European project (Detecting and Eliminating Bacteria UsinG Information 
 Technology) that aims to control and monitor the bacterial growth via a semantic 
 interoperability platform (IP). The evaluation of the process is based, first, 
 on the accuracy of the produced DDO for different samples of database storage 
 and second, by checking the congruency between the DDO and the D2RQ database 
 mapping file.
",,,,
22874189,Inventory of tools for Dutch clinical language processing,"Cornet R, Van Eldik A, De Keizer N.",Stud Health Technol Inform. 2012;180:245-9.,Cornet R,Stud Health Technol Inform,2012,2012-08-10,,,,"Automated encoding of free-text clinical narratives using concepts from 
 terminological systems is widely performed. However, the majority of natural 
 language processing (NLP) tools and terminological systems involve the English 
 language. As parts of the NLP process are language independent, and tools for 
 various languages are available, an overview is needed to determine the 
 applicability to performing NLP of Dutch medical texts. To this end an inventory 
 of tools is created. A literature study and internet search were performed to 
 describe available components for a Dutch NLP system, enabling to encode Dutch 
 text as structured SNOMED CT output without the need to translate SNOMED CT in 
 Dutch. We have found 31 papers, describing a variety of NLP frameworks and tools 
 for the various NLP components for processing English and Dutch free text. Most 
 of them are suitable for English free text, some of them are (also) usable for 
 Dutch. To enable automated encoding of Dutch free text narratives, further 
 research is needed to create a spelling checker, a negation detector, a 
 domain-specific abbreviation/acronym list, and a concept mapper (to map Dutch 
 terms to concepts in a terminological system). Furthermore evaluation of 
 performance for the Dutch 'medical' language is needed.
",,,,
22874256,A semantic model for multimodal data mining in healthcare information systems,"Iakovidis D, Smailis C.",Stud Health Technol Inform. 2012;180:574-8.,Iakovidis D,Stud Health Technol Inform,2012,2012-08-10,,,,"Electronic health records (EHRs) are representative examples of 
 multimodal/multisource data collections; including measurements, images and free 
 texts. The diversity of such information sources and the increasing amounts of 
 medical data produced by healthcare institutes annually, pose significant 
 challenges in data mining. In this paper we present a novel semantic model that 
 describes knowledge extracted from the lowest-level of a data mining process, 
 where information is represented by multiple features i.e. measurements or 
 numerical descriptors extracted from measurements, images, texts or other 
 medical data, forming multidimensional feature spaces. Knowledge collected by 
 manual annotation or extracted by unsupervised data mining from one or more 
 feature spaces is modeled through generalized qualitative spatial semantics. 
 This model enables a unified representation of knowledge across multimodal data 
 repositories. It contributes to bridging the semantic gap, by enabling direct 
 links between low-level features and higher-level concepts e.g. describing body 
 parts, anatomies and pathological findings. The proposed model has been 
 developed in web ontology language based on description logics (OWL-DL) and can 
 be applied to a variety of data mining tasks in medical informatics. It utility 
 is demonstrated for automatic annotation of medical data.
",,,,
22874277,Ontology-based reusable clinical document template production system,"Nam S, Lee S, Kim JG, Kim HG.",Stud Health Technol Inform. 2012;180:677-82.,Nam S,Stud Health Technol Inform,2012,2012-08-10,,,,"Clinical documents embody professional clinical knowledge. This paper shows an 
 effective clinical document template (CDT) production system that uses a 
 clinical description entity (CDE) model, a CDE ontology, and a knowledge 
 management system called STEP that manages ontology-based clinical description 
 entities. The ontology represents CDEs and their inter-relations, and the STEP 
 system stores and manages CDE ontology-based information regarding CDTs. The 
 system also provides Web Services interfaces for search and reasoning over 
 clinical entities. The system was populated with entities and relations 
 extracted from 35 CDTs that were used in admission, discharge, and progress 
 reports, as well as those used in nursing and operation functions. A clinical 
 document template editor is shown that uses STEP.
",,,,
22874193,A semantic approach for digital long-term preservation of electronic health documents,"Kiefer S, Schäfer M, Rauch J.",Stud Health Technol Inform. 2012;180:265-9.,Kiefer S,Stud Health Technol Inform,2012,2012-08-10,,,,"Long-term preservation of electronic patient health information is a key issue 
 for life-long electronic health records, however, it is poorly implemented in 
 healthcare institutions and little attention is given to problems like 
 obsolescence of formats and EHR applications or changing regulations, which 
 jeopardize reusability of information after decades of preservation. We present 
 in this paper an ontology driven approach to digital preservation and related 
 metadata management which seems to be superior to conventional concepts of the 
 digital library world.
",,,,
22874380,A clinical research analytics toolkit for cohort study,"Yu Y, Zhu Y, Sun X, Tao Y, Zhang S, Xu L, Pan Y.",Stud Health Technol Inform. 2012;180:1141-3.,Yu Y,Stud Health Technol Inform,2012,2012-08-10,,,,"This paper presents a clinical informatics toolkit that can assist physicians to 
 conduct cohort studies effectively and efficiently. The toolkit has three key 
 features: 1) support of procedures defined in epidemiology, 2) recommendation of 
 statistical methods in data analysis, and 3) automatic generation of research 
 reports. On one hand, our system can help physicians control research quality by 
 leveraging the integrated knowledge of epidemiology and medical statistics; on 
 the other hand, it can improve productivity by reducing the complexities for 
 physicians during their cohort studies.
",,,,
22874274,Automatic detection of inconsistencies between free text and coded data in Sarcoma discharge letters,"Rinott R, Torresani M, Bertulli R, Goldsteen A, Casali P, Carmeli B, Slonim N.",Stud Health Technol Inform. 2012;180:661-6.,Rinott R,Stud Health Technol Inform,2012,2012-08-10,,,,"Discordance between data stored in Electronic Health Records (EHR) may have a 
 harmful effect on patient care. Automatic identification of such situations is 
 an important yet challenging task, especially when the discordance involves 
 information stored in free text fields. Here we present a method to 
 automatically detect inconsistencies between data stored in free text and 
 related coded fields. Using EHR data we train an ensemble of classifiers to 
 predict the value of coded fields from the free text fields. Cases in which the 
 classifiers predict with high confidence a code different from the clinicians' 
 choice are marked as potential inconsistencies. Experimental results over 
 discharge letters of sarcoma patients, verified by a domain expert, demonstrate 
 the validity of our method.
",,,,
22874254,Interoperability in clinical research: from metadata registries to semantically annotated CDISC ODM,"Bruland P, Breil B, Fritz F, Dugas M.",Stud Health Technol Inform. 2012;180:564-8.,Bruland P,Stud Health Technol Inform,2012,2012-08-10,,,,"Planning case report forms for data capture in clinical trials is a 
 labor-insensitive and not formalized process. These CRFs are often neither 
 standardized nor using defined data elements. Metadata registries as the NCI 
 caDSR provide the capability to create forms based on common data elements. 
 However, an exchange of these forms into clinical trial management systems 
 through a standardized format like CDISC ODM is currently not offered. Thus, our 
 objectives were to develop a mapping model between NCI forms and ODM. We 
 analyzed 3012 NCI forms and included common data elements regarding their 
 frequency and uniqueness. In this paper, we have created a mapping model between 
 both formats and identified limitations in the conversion process: Semantic 
 codes requested from the caDSR registry did not allow a proper mapping to ODM 
 items and information like the number of module repetitions got lost. 
 Summarized, it can be stated that our mapping model is feasible. However, 
 mapping of semantic concepts in ODM needs to be specified more precisely.
",,,,
22491122,Merging genomic and phenomic data for research and clinical impact,"Shublaq NW, Coveney PV.",Stud Health Technol Inform. 2012;174:111-5.,Shublaq NW,Stud Health Technol Inform,2012,2012-04-12,,,,"Driven primarily by advances in genomics, pharmacogenomics and systems biology 
 technologies, large amounts of genomic and phenomic data are today being 
 collected on individuals worldwide. Integrative analysis, mining, and computer 
 modeling of these data, facilitated by information technology, have led to the 
 development of predictive, preventive, and personalized medicine. This 
 transformative approach holds the potential inter alia to enable future general 
 practitioners and physicians to prescribe the right drug to the right patient at 
 the right dosage. For such patient-specific medicine to be adopted as standard 
 clinical practice, publicly accumulated knowledge of genes, proteins, molecular 
 functional annotations, and interactions need to be unified and with electronic 
 health records including phenotypic information, most of which still reside as 
 paper-based records in hospitals. We review the state-of-the-art in terms of 
 electronic data capture and medical data standards. Some of these activities are 
 drawn from research projects currently being performed within the European 
 Virtual Physiological Human (VPH) initiative; all are being monitored by the VPH 
 INBIOMEDvision Consortium. Various ethical, legal and societal issues linked 
 with privacy will increasingly arise in the post-genomic era. This will require 
 a closer interaction between the bioinformatics/systems biology and medical 
 informatics/healthcare communities. Planning for how individuals will own their 
 personal health records is urgently needed, as the cost of sequencing a whole 
 human genome will soon be less than U.S. $100. We discuss some of the issues 
 that will need to be addressed by society as a result of this revolution in 
 healthcare.
",,,,
22874367,Semantic enrichment of medical forms - semi-automated coding of ODM-elements via web services,"Breil B, Watermann A, Haas P, Dziuballe P, Dugas M.",Stud Health Technol Inform. 2012;180:1102-4.,Breil B,Stud Health Technol Inform,2012,2012-08-10,,,,"Semantic interoperability is an unsolved problem which occurs while working with 
 medical forms from different information systems or institutions. Standards like 
 ODM or CDA assure structural homogenization but in order to compare elements 
 from different data models it is necessary to use semantic concepts and codes on 
 an item level of those structures. We developed and implemented a web-based tool 
 which enables a domain expert to perform semi-automated coding of ODM-files. For 
 each item it is possible to inquire web services which result in unique concept 
 codes without leaving the context of the document. Although it was not feasible 
 to perform a totally automated coding we have implemented a dialog based method 
 to perform an efficient coding of all data elements in the context of the whole 
 document. The proportion of codable items was comparable to results from 
 previous studies.
",,,,
22797046,Using the general practice EMR for improving blood pressure medication adherence,"Warren J, Kennelly J, Warren D, Elley CR, Wai KC, Manukia M, Davy J, Mabotuwana T, Robinson E.",Stud Health Technol Inform. 2012;178:228-34.,Warren J,Stud Health Technol Inform,2012,2012-07-17,,,,"PURPOSE: Analysis of practice electronic medical records (EMRs) demonstrated 
 widespread antihypertensive medication adherence problems in a Pacific-led 
 general practice serving a predominantly Pacific (majority Samoan) caseload in 
 suburban New Zealand. Adherence was quantified in terms of medication possession 
 ratio (MPR, percent of days covered by medication supply) from the practice's 
 prescribing data. We studied the effectiveness of general practice staff 
 follow-up guided by EMR data to improve medication adherence.
 METHODS: A framework for identification of suboptimal long-term condition 
 management from routinely-collected EMR data, the ChronoMedIt (Chronological 
 Medical Audit) tool, was applied to data of two Pacific-led general practices to 
 identify patients with low MPR. One practice undertook intervention, the other 
 provided usual care. A cohort was based on MPR<80% for antihypertensive 
 medication in a baseline 6-month period. At the intervention practice a team was 
 established to provide reminders and motivation for these patients and discuss 
 their specific needs for assistance to improve adherence for 12 months. MPR and 
 systolic blood pressure (SBP) was collected at baseline and for last six months 
 of intervention based on practice EMRs; national claims data provided assessment 
 of MPR based on dispensing. Nursing notes were analysed, and patient and 
 provider focus groups were conducted.
 RESULTS: Of the 252 intervention patients with MPR<80% initially, MPR improved 
 12.0% (p=0.0002) and systolic blood pressure was 3.5mmHg lower (p=0.07) as 
 compared to the control cohort. MPR from national claims data improved by 11.5% 
 (p=0.0001) as compared to the control. Patients welcomed the approach as caring 
 and useful. Providers felt the approach worthy of wider deployment but that it 
 required dedicated staffing.
 DISCUSSION AND CONCLUSIONS: Systematic follow-up of patients with demonstrated 
 poor medication possession appears effective in the context of a Pacific-led 
 general practice serving a largely Pacific caseload. It was possible to exploit 
 the EMR database to identify patients with low antihypertensive medication 
 possession and to raise their level of medication possession significantly. The 
 measured effect on systolic BP was only marginally significant, leaving open the 
 question of the precise value of the intervention in terms of morbidity and 
 mortality. The intervention was found to be feasible and was met with good 
 acceptance from the intervention patients, who appreciated the concern reflected 
 in the follow-up effort. The intervention practice is continuing use of 
 ChronoMedIt to guide long-term condition management with extension to 
 cholesterol and blood sugar.
",,,,
23823358,Computer-interpretable guidelines,Hasman A.,Stud Health Technol Inform. 2013;190:3-7.,Hasman A,Stud Health Technol Inform,2013,2013-07-05,,,,"In this contribution the concept of computer-interpretable guidelines is 
 discussed. Several guideline formalisms are presented and the GASTON and GASTINE 
 formalisms are given as examples. Finally the problems associated with the 
 integration of CIGs with EPR systems are mentioned.
",,,,
23920968,Hierarchical semantic structures for medical NLP,"Taira RK, Arnold CW.",Stud Health Technol Inform. 2013;192:1194.,Taira RK,Stud Health Technol Inform,2013,2013-08-08,,,,"We present a framework for building a medical natural language processing (NLP) 
 system capable of deep understanding of clinical text reports. The framework 
 helps developers understand how various NLP-related efforts and knowledge 
 sources can be integrated. The aspects considered include: 1) computational 
 issues dealing with defining layers of intermediate semantic structures to 
 reduce the dimensionality of the NLP problem; 2) algorithmic issues in which we 
 survey the NLP literature and discuss state-of-the-art procedures used to map 
 between various levels of the hierarchy; and 3) implementation issues to 
 software developers with available resources. The objective of this poster is to 
 educate readers to the various levels of semantic representation (e.g., word 
 level concepts, ontological concepts, logical relations, logical frames, 
 discourse structures, etc.). The poster presents an architecture for which 
 diverse efforts and resources in medical NLP can be integrated in a principled 
 way.
",,,,
23920862,Toward image analysis and decision support for ultrasound technology,"Crofts G, Padman R, Maharaja N.",Stud Health Technol Inform. 2013;192:1088.,Crofts G,Stud Health Technol Inform,2013,2013-08-08,,,,"Ultrasound is a low cost and efficient method of detecting diseases and 
 abnormalities in the body. Yet there is a lack of precision and reliability 
 associated with the technology, partly due to the operator dependent nature of 
 ultrasound scanning. When scanning is performed to an agreed protocol, 
 ultrasound has been shown to be highly reliable. This research aims to minimize 
 these limitations that arise during ultrasound training, scanning and reporting 
 by developing and evaluating an image analysis and decision support system that 
 can aid the decision making process. We hypothesize that this intervention will 
 likely increase the role of ultrasound in diagnosis when compared with other 
 imaging technologies, particularly in low resource settings.
",,,,
23920750,The characteristics and key issues in electronic medical records (EMR) of traditional Chinese medicine TCM,"Shi C, Xu L, Gong Q, Wang X.",Stud Health Technol Inform. 2013;192:976.,Shi C,Stud Health Technol Inform,2013,2013-08-08,,,,"This poster briefly introduces the characteristics of TCM data, significances of 
 EMR of TCM, and several key factors in the establishment of EMR of TCM.
",,,,
23920854,Query engine optimization for the EHR4CR protocol feasibility scenario,"Soto-Rey I, Bache R, Dugas M, Fritz F.",Stud Health Technol Inform. 2013;192:1080.,Soto-Rey I,Stud Health Technol Inform,2013,2013-08-08,,,,"An essential step when recruiting patients for a Clinical Trial (CT) is to 
 determine the number of patients that satisfy the Eligibility Criteria (ECs) for 
 that trial. An innovative feature of the Electronic Health Records for Clinical 
 Research (EHR4CR) platform is that when automatically determining patient 
 counts, it also allows the user to view counts for subsets of the ECs. This is 
 helpful because some combinations of ECs may be so restrictive that they yield 
 very few or zero patients. If we wanted to show all possible combinations of 
 ECs, the number of queries we would have to execute would be of 2<sup>n</sup>, 
 where n is the total number of ECs. Assuming that an average study has between 
 20 and 30 ECs, the program would have to execute between 2<sup>20</sup> 
 (1,048,576) and 2<sup>30</sup> (1,073,741,824) queries. This is not only 
 computationally expensive but also impractical to visualise. The purpose of our 
 research is to reduce possible combinationsto a manageable number.
",,,,
23920846,Model-based query language for analyzing clinical processes,"Barzdins J, Barzdins J, Rencis E, Sostaks A.",Stud Health Technol Inform. 2013;192:1072.,Barzdins J,Stud Health Technol Inform,2013,2013-08-08,,,,"Nowadays large databases of clinical process data exist in hospitals. However, 
 these data are rarely used in full scope. In order to perform queries on 
 hospital processes, one must either choose from the predefined queries or 
 develop queries using MS Excel-type software system, which is not always a 
 trivial task. In this paper we propose a new query language for analyzing 
 clinical processes that is easily perceptible also by non-IT professionals. We 
 develop this language based on a process modeling language which is also 
 described in this paper. Prototypes of both languages have already been verified 
 using real examples from hospitals.
",,,,
23920664,Predicate argument structure frames for modeling information in operative notes,"Wang Y, Pakhomov S, Melton GB.",Stud Health Technol Inform. 2013;192:783-7.,Wang Y,Stud Health Technol Inform,2013,2013-08-08,PMC4662251,NIHMS726035,,"The rich information about surgical procedures contained in operative notes is a 
 valuable data source for improving the clinical evidence base and clinical 
 research. In this study, we propose a set of Predicate Argument Structure (PAS) 
 frames for surgical action verbs to assist in the creation of an information 
 extraction (IE) system to automatically extract details about the techniques, 
 equipment, and operative steps from operative notes. We created PropBank style 
 PAS frames for the 30 top surgical action verbs based on examination of randomly 
 selected sample sentences from 3,000 Laparoscopic Cholecystectomy notes. To 
 assess completeness of the PAS frames to represent usage of same action verbs, 
 we evaluated the PAS frames created on sample sentences from operative notes of 
 6 other gastrointestinal surgical procedures. Our results showed that the PAS 
 frames created with one type of surgery can successfully denote the usage of the 
 same verbs in operative notes of broader surgical categories.
",,,,
23920749,"Quality assurance of LOINC mapping for laboratory tests - a local experience with people, process and technology","Mok J, Ho PC, Tsui K, Ng L, Fung V.",Stud Health Technol Inform. 2013;192:975.,Mok J,Stud Health Technol Inform,2013,2013-08-08,,,,"In Hong Kong Hospital Authority (HA), the Electronic Patient Record (ePR) module 
 of Clinical Management System, implemented since 2003, bring together all the 
 information from various clinical module and hospitals into a single corporate 
 wide, longitudinal, integrated record. Nowadays there are billions of laboratory 
 test results stored in the web-based ePR where laboratory results being shared 
 with the HA clinicians for patient care. In order to produce interoperable 
 laboratory data in the ePR, the HA adopts LOINC (Logical Observation Identifiers 
 Names and Codes) as the reference standard for laboratory tests. Every local 
 test codes have been mapped with LOINC code where possible. Thus, the accuracy 
 of LOINC mapping for laboratory tests in the HA is imperative. This paper 
 describes a quality assurance program of LOINC mapping for laboratory tests 
 conducted in 2011/12. With the use of right people, right process and right 
 technology, we reviewed over 28,000 local test codes and there are around 2,400 
 distinct LOINC concepts mapped and defined in the system.
",,,,
23920923,Using text prediction for facilitating input and improving readability of clinical text,"Ahltorp M, Skeppstedt M, Dalianis H, Kvist M.",Stud Health Technol Inform. 2013;192:1149.,Ahltorp M,Stud Health Technol Inform,2013,2013-08-08,,,,"Text prediction has the potential for facilitating and speeding up the 
 documentation work within health care, making it possible for health personnel 
 to allocate less time to documentation and more time to patient care. It also 
 offers a way to produce clinical text with fewer misspellings and abbreviations, 
 increasing readability. We have explored how text prediction can be used for 
 input of clinical text, and how the specific challenges of text prediction in 
 this domain can be addressed. A text prediction prototype was constructed using 
 data from a medical journal and from medical terminologies. This prototype 
 achieved keystroke savings of 26% when evaluated on texts mimicking authentic 
 clinical text. The results are encouraging, indicating that there are feasible 
 methods for text prediction in the clinical domain.
",,,,
23920741,"High intensity, multimodality and incoherence: grand challenges in the analysis of data for health-enabling technologies","Kohlmann M, Gietzelt M, Marschollek M, Song B, Wolf KH, Haux R.",Stud Health Technol Inform. 2013;192:967.,Kohlmann M,Stud Health Technol Inform,2013,2013-08-08,,,,"When working with health-enabling technologies, researchers all over the world 
 usually have to analyze highly intensive, multimodal and incoherent data. We 
 explain that there is a lack of systematization within the set of methods of 
 analysis suitable for these data. As a first step towards a methodology in this 
 context, we present the Systematic Nomenclature for Contexts, Analysis Methods 
 and Problems in Health-Enabling Technologies (SNOCAP-HET).
",,,,
23920985,Building a common pipeline for rule-based document classification,"Patterson OV, Ginter T, DuVall SL.",Stud Health Technol Inform. 2013;192:1211.,Patterson OV,Stud Health Technol Inform,2013,2013-08-08,,,,"Instance-based classification of clinical text is a widely used natural language 
 processing task employed as a step for patient classification, document 
 retrieval, or information extraction. Rule-based approaches rely on concept 
 identification and context analysis in order to determine the appropriate class. 
 We propose a five-step process that enables even small research teams to develop 
 simple but powerful rule-based NLP systems by taking advantage of a common UIMA 
 AS based pipeline for classification. Our proposed methodology coupled with the 
 general-purpose solution provides researchers with access to the data locked in 
 clinical text in cases of limited human resources and compact timelines.
",,,,
23920997,Model-based auditability of clinical trial recruitment,"Curcin V, Lim Choi Keung SN, Danger R, Rossiter J, Zhao L, Arvanitis TN.",Stud Health Technol Inform. 2013;192:1223.,Curcin V,Stud Health Technol Inform,2013,2013-08-08,,,,"Detailed insight into the recruitment parameters of a clinical trial is crucial 
 to interpretation of its results, and reasons for its success or failure. Such 
 recruitment is increasingly done through specialized software tools, sometimes 
 linked to Electronic Health Record (EHR) systems, enabling automated capture of 
 audit logs. However, in the absence of shared semantic models underpinning these 
 logs, gathered data remains insular and opaque. We propose a standardized 
 syntactical representation to capture the provenance of the recruitment task, 
 and ground it in CRIM, a variant of the established PCROM information model for 
 research in primary care. The method has been successfully prototyped in the EU 
 FP7 TRANSFoRm project, where the recruitment eligibility query module has been 
 integrated with a provenance capture infrastructure, resulting in the full 
 reproducibility of the study design process.
",,,,
23920991,Comparison of clinical knowledge bases for summarization of electronic health records,"McCoy AB, Sittig DF, Wright A.",Stud Health Technol Inform. 2013;192:1217.,McCoy AB,Stud Health Technol Inform,2013,2013-08-08,,,,"Automated summarization tools that create condition-specific displays may 
 improve clinician efficiency. These tools require new kinds of knowledge that is 
 difficult to obtain. We compared five problem-medication pair knowledge bases 
 generated using four previously described knowledge base development approaches. 
 The number of pairs in the resulting mapped knowledge bases varied widely due to 
 differing mapping techniques from the source terminologies, ranging from 2,873 
 to 63,977,738 pairs. The number of overlapping pairs across knowledge bases was 
 low, with one knowledge base having half of the pairs overlapping with another 
 knowledge base, and most having less than a third overlapping. Further research 
 is necessary to better evaluate the knowledge bases independently in additional 
 settings, and to identify methods to integrate the knowledge bases.
",,,,
23920690,Modeling decision support rule interactions in a clinical setting,"Sordo M, Rocha BH, Morales AA, Maviglia SM, Oglio ED, Fairbanks A, Aroy T, Dubois D, Bouyer-Ferullo S, Rocha RA.",Stud Health Technol Inform. 2013;192:908-12.,Sordo M,Stud Health Technol Inform,2013,2013-08-08,,,,"Traditionally, rule interactions are handled at implementation time through rule 
 task properties that control the order in which rules are executed. By doing so, 
 knowledge about the behavior and interactions of decision rules is not captured 
 at modeling time. We argue that this is important knowledge that should be 
 integrated in the modeling phase. In this project, we build upon current work on 
 a conceptual schema to represent clinical knowledge for decision support in the 
 form of if <formula></formula> then rules. This schema currently captures 
 provenance of the clinical content, context where such content is actionable 
 (i.e. constraints) and the logic of the rule itself. For this project, we 
 borrowed concepts from both the Semantic Web (i.e., Ontologies) and Complex 
 Adaptive Systems (CAS), to explore a conceptual approach for modeling rule 
 interactions in an enterprise-wide clinical setting. We expect that a more 
 comprehensive modeling will facilitate knowledge authoring, editing and update; 
 foster consistency in rules implementation and maintenance; and develop 
 authoritative knowledge repositories to promote quality, safety and efficacy of 
 healthcare.
",,,,
23920937,Natural language processing and inference rules as strategies for updating problem list in an electronic health record,"Plazzotta F, Otero C, Luna D, de Quiros FG.",Stud Health Technol Inform. 2013;192:1163.,Plazzotta F,Stud Health Technol Inform,2013,2013-08-08,,,,"Physicians do not always keep the problem list accurate, complete and updated.
 OBJECTIVE: To analyze natural language processing (NLP) techniques and inference 
 rules as strategies to maintain completeness and accuracy of the problem list in 
 EHRs.
 METHODS: Non systematic literature review in PubMed, in the last 10 years. 
 Strategies to maintain the EHRs problem list were analyzed in two ways: 
 inputting and removing problems from the problem list.
 RESULTS: NLP and inference rules have acceptable performance for inputting 
 problems into the problem list. No studies using these techniques for removing 
 problems were published Conclusion: Both tools, NLP and inference rules have had 
 acceptable results as tools for maintain the completeness and accuracy of the 
 problem list.
",,,,
23920639,Analyzing differences between chinese and english clinical text: a cross-institution comparison of discharge summaries in two languages,"Wu Y, Lei J, Wei WQ, Tang B, Denny JC, Rosenbloom ST, Miller RA, Giuse DA, Zheng K, Xu H.",Stud Health Technol Inform. 2013;192:662-6.,Wu Y,Stud Health Technol Inform,2013,2013-08-08,PMC4957806,NIHMS803375,,"Worldwide adoption of Electronic Medical Records (EMRs) databases in health care 
 have generated an unprecedented amount of clinical data available 
 electronically. There has been an increasing trend in US and western 
 institutions towards collaborating with China on medical research using EMR 
 data. However, few studies have investigated characteristics of EMR data in 
 China and their differences with the data in US hospitals. As an initial step 
 towards differentiating EMR data in Chinese and US systems, this study attempts 
 to understand system and cultural differences that may exist between Chinese and 
 English clinical documents. We collected inpatient discharge summaries from one 
 Chinese and from three US institutions and manually analyzed three major 
 clinical components in text: medical problems, tests, and treatments. We 
 reported comparison results at the document level and section level and 
 discussed potential reasons for observed differences. Documenting and 
 understanding differences in clinical reports from the US and China EMRs are 
 important for cross-country collaborations. Our study also provided valuable 
 insights for developing natural language processing tools for Chinese clinical 
 text.
",,,,
23920764,An analysis of the openehr archetype semantics based on a typed lambda theory,"Tatsukawa A, Shinohara EY, Kawazoe Y, Imai T, Ohe K.",Stud Health Technol Inform. 2013;192:990.,Tatsukawa A,Stud Health Technol Inform,2013,2013-08-08,,,,"The openEHR has adopted the dual model architecture consisting of Reference 
 Model and Archetype. The specification, however, lacks formal definitions of 
 archetype semantics, so that its behaviors have remained ambiguous. The 
 objective of this poster is to analyze semantics of the openEHR archetypes: its 
 variance and mutability. We use a typed lambda calculus as an analyzing tool. As 
 a result, we have reached the conclusion that archetypes should be 1) covariant 
 and 2) immutable schema.
",,,,
23920599,An example of an application of the semiotic inspection method in the domain of computerized patient record system,"Tancredi W, Torgersson O.",Stud Health Technol Inform. 2013;192:471-5.,Tancredi W,Stud Health Technol Inform,2013,2013-08-08,,,,"Efficiently navigating through an interface and conducting work tasks in flow is 
 what GUI designers strive for. Dental professionals, who alternate between 
 examination and treatment of a patient and insertion of data into the 
 Computerized Patient Record system, particularly need an interface that would 
 facilitate the workflow. In this paper we present an inspection evaluation of an 
 existing and widely used Computerized Patient Record system. The Semiotic 
 Inspection Method was applied with the expectation that the method could provide 
 evidence that task flow, navigation and wayfinding were major usability issues 
 of the interface. Also expected was that the Semiotic Inspection would reveal 
 the means and strategies used in the interface in order to communicate the flow. 
 The analysis conducted using the Semiotic Inspection Method showed 
 inconsistencies in the communication of the way forward through the interface. 
 In addition, the profile of the users, regarding digital skills, appears to be 
 ambiguous. Finally, the strategies used in the interface for conveying the 
 workflow could be identified as well.
",,,,
23920600,Automatic de-identification of French clinical records: comparison of rule-based and machine-learning approaches,"Grouin C, Zweigenbaum P.",Stud Health Technol Inform. 2013;192:476-80.,Grouin C,Stud Health Technol Inform,2013,2013-08-08,,,,"In this paper, we present a comparison of two approaches to automatically 
 de-identify medical records written in French: a rule-based system and a 
 machine-learning based system using a conditional random fields (CRF) formalism. 
 Both systems have been designed to process nine identifiers in a corpus of 
 medical records in cardiology. We performed two evaluations: first, on 62 
 documents in cardiology, and on 10 documents in foetopathology - produced by 
 optical character recognition (OCR) - to evaluate the robustness of our systems. 
 We achieved a 0.843 (rule-based) and 0.883 (machine-learning) exact match 
 overall F-measure in cardiology. While the rule-based system allowed us to 
 achieve good results on nominative (first and last names) and numerical data 
 (dates, phone numbers, and zip codes), the machine-learning approach performed 
 best on more complex categories (postal addresses, hospital names, medical 
 devices, and towns). On the foetopathology corpus, although our systems have not 
 been designed for this corpus and despite OCR character recognition errors, we 
 obtained promising results: a 0.681 (rule-based) and 0.638 (machine-learning) 
 exact-match overall F-measure. This demonstrates that existing tools can be 
 applied to process new documents of lower quality.
",,,,
23920929,Program for validation of aggregated hospital discharge data,"Rakovac I, Maharjan B, Stein C, Loyola E.",Stud Health Technol Inform. 2013;192:1155.,Rakovac I,Stud Health Technol Inform,2013,2013-08-08,,,,"Hospitals are major providers of health services and analysis of hospital 
 activity data is of great interest for both policy makers and public health 
 researchers. The WHO Regional Office for Europe disseminates the hospital 
 discharge data from European countries through the European Hospital Morbidity 
 Database, available on http://data.euro.who.int/hmdb. In order to ensure that 
 reliable high quality data on hospital activities can be published in a timely 
 manner, a program for validation of hospital discharge data has been developed 
 using the R language for statistical computing. This program has been in use 
 since the October 2012 version of the European Hospital Morbidity Database and 
 its use has contributed to improved quality and comparability of data on 
 hospital activities across Europe.
",,,,
23920921,Development of a SNOMED CT based national medication decision support system,Greibe K.,Stud Health Technol Inform. 2013;192:1147.,Greibe K,Stud Health Technol Inform,2013,2013-08-08,,,,"Physicians often lack the time to familiarize themselves with the details of 
 particular allergies or other drug restrictions. Clinical Decision Support 
 (CDS), based on a structured terminology as SNOMED CT (SCT), can help physicians 
 get an overview, by automatically alerting allergy, interactions and other 
 important information. The centralized CDS platform based on SCT, controls 
 Allergy, Interactions, Risk Situation Drugs and Max Dose restrictions by the 
 help of databases developed for these specific purposes. The CDS will respond to 
 automatic web service requests from the hospital or GP electronic medication 
 system (EMS) during prescription, and return alerts and information. The CDS 
 also contains a Physicians Preference Database where the physicians individually 
 can set which kind of alerts they want to see. The result is clinically useful 
 information physicians can use as a base for a more effective and safer 
 treatment, without developing alert fatigue.
",,,,
23920668,Exposing public health surveillance data using existing standards,"Turbelin C, Boëlle PY.",Stud Health Technol Inform. 2013;192:802-6.,Turbelin C,Stud Health Technol Inform,2013,2013-08-08,,,,"With the growing use of information technologies, an increased volume of data is 
 produced in Public Health Surveillance, enabling utilization of new data sources 
 and analysis methods. Public health and research will benefit from the use of 
 data standards promoting harmonization and data description through metadata. No 
 data standard has yet been universally accepted for exchanging public health 
 data. In this work, we implemented two existing standards eligible to expose 
 public health data: Statistical Data and Metadata Exchange - Health Domain 
 (SDMX-HD) proposed by the World Health Organization and Open Data Protocol 
 (OData) proposed by Microsoft Corp. SDMX-HD promotes harmonization through 
 controlled vocabulary and predefined data structure suitable for public health 
 but requires important investment, while OData, a generic purpose standard, 
 proposes a simple way to expose data with minimal documentation and end-user 
 integration tools. The two solutions were implemented and are publicly available 
 at http://sdmx.sentiweb.fr and http://odata.sentiweb.fr. These solutions show 
 that data sharing and interoperability are already possible in Public Health 
 Surveillance.
",,,,
23920744,Fostering ontology alignment sharing: a general-purpose RDF mapping format,"Anguita A, Escrich A, Maojo V.",Stud Health Technol Inform. 2013;192:970.,Anguita A,Stud Health Technol Inform,2013,2013-08-08,,,,"RDF has established in the last years as the language for describing, publishing 
 and sharing biomedical resources. Following this trend, a great amount of 
 RDF-based data sources, as well as ontologies, have appeared. Using a common 
 language as RDF has provided a unified syntactic for sharing resources, but the 
 semantics remain as the main cause of heterogeneity, hampering data integration 
 and homogenization efforts. To overcome this issue, ontology alignment based 
 solutions have been typically used. However, alignment information is usually 
 codified using ad-hoc formats. In this paper, we present a general purpose 
 ontology mapping format, totally independent from the homogenization approach to 
 be applied. The format is accompanied with a Java API that offers mapping 
 construction and parsing features, as well as some basic algorithms for applying 
 it to data translation solutions.
",,,,
23388282,Processing medical reports to automatically populate ontologies,"Borrego L, Quaresma P.",Stud Health Technol Inform. 2013;183:201-5.,Borrego L,Stud Health Technol Inform,2013,2013-02-08,,,,"Medical reports are, quite often, written and stored in computer systems in a 
 non-structured free text form. As a consequence, the information contained in 
 these reports is not easily available and it is not possible to take it into 
 account by medical decision support systems. We propose a methodology to 
 automatically process and analyze medical reports, identifying concepts and 
 their instances, and populating a new ontology. This methodology is based in 
 natural language processing techniques using linguistic and statistical 
 information. The proposed system was applied successfully to a set of medical 
 reports from the Veterinary Hospital of the University of Évora.
",,,,
23920514,Taming EHR data: using semantic similarity to reduce dimensionality,"Kalankesh L, Weatherall J, Ba-Dhfari T, Buchan I, Brass A.",Stud Health Technol Inform. 2013;192:52-6.,Kalankesh L,Stud Health Technol Inform,2013,2013-08-08,,,,"Medical care data is a valuable resource that can be used for many purposes 
 including managing and planning for future health needs as well as clinical 
 research. However, the heterogeneity and complexity of medical data can be an 
 obstacle in applying data mining techniques. Much of the potential value of this 
 data therefore goes untapped. In this paper we have developed a methodology that 
 reduces the dimensionality of primary care data, in order to make it more 
 amenable to visualisation, mining and clustering. The methodology involves 
 employing a combination of ontology-based semantic similarity and principal 
 component analysis (PCA) to map the data into an appropriate and informative low 
 dimensional space. Throughout the study, we had access to anonymised patient 
 data from primary care in Salford, UK. The results of our application of this 
 methodology show that diagnosis codes in primary care data can be used to map 
 patients into an informative low dimensional space, which in turn provides the 
 opportunity to support further data exploration and medical hypothesis 
 formulation.
",,,,
23920868,From data mining rules to medical logical modules and medical advices,"Gomoi V, Vida M, Robu R, Stoicu-Tivadar V, Bernad E, Lupşe O.",Stud Health Technol Inform. 2013;192:1094.,Gomoi V,Stud Health Technol Inform,2013,2013-08-08,,,,"Using data mining in collaboration with Clinical Decision Support Systems adds 
 new knowledge as support for medical diagnosis. The current work presents a tool 
 which translates data mining rules supporting generation of medical advices to 
 Arden Syntax formalism. The developed system was tested with data related to 
 2326 births that took place in 2010 at the Bega Obstetrics - Gynaecology 
 Hospital, Timişoara. Based on processing these data, 14 medical rules regarding 
 the Apgar score were generated and then translated in Arden Syntax language.
",,,,
23920832,Empirical analysis of knowledge bases to support structured output in the Arden syntax,Jenders RA.,Stud Health Technol Inform. 2013;192:1058.,Jenders RA,Stud Health Technol Inform,2013,2013-08-08,,,,"BACKGROUND: Structured output has been suggested for the Arden Syntax to 
 facilitate interoperability.
 OBJECTIVE: Tabulate the components of WRITE statements in a corpus of medical 
 logic modules (MLMs)in order to validate requiring structured output.
 METHODS: WRITE statements were tabulated in 258 MLMs from 2 organizations.
 RESULTS: In a total of 351 WRITE statements, email destinations (226) 
 predominated, and 39 orders and 40 coded output elements also were tabulated. 
 Free-text strings predominated as the message data.
 CONCLUSIONS: Arden WRITE statements contain considerable potentially structured 
 data now included as free text. A future, normative structured WRITE statement 
 must address a variety of data types and destinations.
",,,,
23920838,Construction of the integrated multicentre discharge summary database,"Takahiro S, Shunsuke D, Shinsuke F, Yutaka H, Masayuki H, Yasushi M, Gen S, Mitsuhiro T, Shusaku T, Hideto Y, Katsuhiko T.",Stud Health Technol Inform. 2013;192:1064.,Takahiro S,Stud Health Technol Inform,2013,2013-08-08,,,,"We started a multi-year project to collect discharge summaries from multiple 
 hospitals and create a big text database to build a common document vector 
 space, and develop various applications such as the autoselection of the 
 disease. As the first step, we extracted discharge summary from two hospitals. 
 Using a text mining method, we carried out a DPC selection. There was a 
 difference in term structure and number of terms between the discharge summaries 
 from both hospitals. Nevertheless, the selection rate of the disease is 
 resembled closely.
",,,,
23920627,Semantic interoperation and electronic health records: context sensitive mapping from SNOMED CT to ICD-10,"Campbell JR, Brear H, Scichilone R, White S, Giannangelo K, Carlsen B, Solbrig H, Fung KW.",Stud Health Technol Inform. 2013;192:603-7.,Campbell JR,Stud Health Technol Inform,2013,2013-08-08,,,,"An important case for successful deployment of a lifetime electronic health 
 record is reuse of clinical data from the electronic health record (EHR) for 
 epidemiology, reimbursement, and research. We report a collaboration between the 
 IHTSDO and the WHO to develop knowledge-based tools supporting translation of 
 data from SNOMED CT to the ICD-10 classification. These tools have been vetted 
 by an international community and are available for system vendors to enhance 
 the interoperability of their products. The maps we created are also informing 
 the development of the next generation of classifications which will employ a 
 common ontology base between SNOMED CT and ICD-11 to promote interoperability.
",,,,
23920643,Using linked data for mining drug-drug interactions in electronic health records,"Pathak J, Kiefer RC, Chute CG.",Stud Health Technol Inform. 2013;192:682-6.,Pathak J,Stud Health Technol Inform,2013,2013-08-08,PMC3909652,NIHMS547249,,"By nature, healthcare data is highly complex and voluminous. While on one hand, 
 it provides unprecedented opportunities to identify hidden and unknown 
 relationships between patients and treatment outcomes, or drugs and allergic 
 reactions for given individuals, representing and querying large network 
 datasets poses significant technical challenges. In this research, we study the 
 use of Semantic Web and Linked Data technologies for identifying drug-drug 
 interaction (DDI) information from publicly available resources, and determining 
 if such interactions were observed using real patient data. Specifically, we 
 apply Linked Data principles and technologies for representing patient data from 
 electronic health records (EHRs) at Mayo Clinic as Resource Description 
 Framework (RDF), and identify potential drug-drug interactions (PDDIs) for 
 widely prescribed cardiovascular and gastroenterology drugs. Our results from 
 the proof-of-concept study demonstrate the potential of applying such a 
 methodology to study patient health outcomes as well as enabling genome-guided 
 drug therapies and treatment interventions.
",,,,
23920917,Separation of metadata and pixel data to speed DICOM tag morphing,"Ismail M, Philbin J.",Stud Health Technol Inform. 2013;192:1143.,Ismail M,Stud Health Technol Inform,2013,2013-08-08,,,,"The DICOM information model combines pixel data and metadata in single DICOM 
 object. It is not possible to access the metadata separately from the pixel 
 data. There are use cases where only metadata is accessed. The current DICOM 
 object format increases the running time of those use cases. Tag morphing is one 
 of those use cases. Tag morphing includes deletion, insertion or manipulation of 
 one or more of the metadata attributes. It is typically used for order 
 reconciliation on study acquisition or to localize the issuer of patient ID 
 (IPID) and the patient ID attributes when data from one domain is transferred to 
 a different domain. In this work, we propose using Multi-Series DICOM (MSD) 
 objects, which separate metadata from pixel data and remove duplicate 
 attributes, to reduce the time required for Tag Morphing. The time required to 
 update a set of study attributes in each format is compared. The results show 
 that the MSD format significantly reduces the time required for tag morphing.
",,,,
23920859,Isosemantic rendering of clinical information using formal ontologies and RDF,"Martínez-Costa C, Bosca D, Legaz-García MC, Tao C, Fernández Breis JT, Schulz S, Chute CG.",Stud Health Technol Inform. 2013;192:1085.,Martínez-Costa C,Stud Health Technol Inform,2013,2013-08-08,,,,"The generation of a semantic clinical infostructure requires linking ontologies, 
 clinical models and terminologies [1]. Here we describe an approach that would 
 permit data coming from different sources and represented in different standards 
 to be queried in a homogeneous and integrated way. Our assumption is that data 
 providers should be able to agree and share the meaning of the data they want to 
 exchange and to exploit. We will describe how Clinical Element Model (CEM) and 
 OpenEHR datasets can be jointly exploited in Semantic Web environments.
",,,,
23920913,Inconsistencies between recorded opportunistic infections and WHO HIV staging in western Kenya,"Oluoch T, de Keizer N, Kwaro D, Wattoyi I, Okeyo N, Cornet R.",Stud Health Technol Inform. 2013;192:1139.,Oluoch T,Stud Health Technol Inform,2013,2013-08-08,,,,"Opportunistic infections (OIs) are the main cause of morbidity and mortality 
 among patients with HIV in developing countries. It is therefore critical that 
 accurate diagnoses are made and that they are correctly recorded and managed. We 
 reviewed 200 randomly selected records of clinical encounters with HIV infected 
 pregnant women attending the ante-natal care (ANC) clinic in July 2012 at the 
 Jaramogi Oginga Odinga Teaching and Referral Hospital in Kenya. None of the 
 clients in WHO stage 4 and 2.8% of those in WHO stage 3 had a new OI diagnosis 
 recorded during the clinical encounter. This data suggests current 
 under-recording of OIs and the inconsistency between WHO staging and OI 
 diagnosis. Structured methods such as SNOMED CT have the potential to improve 
 complete and accurate recording of OIs which, in turn, enable automatedand 
 accurate WHO staging.
",,,,
23920672,An efficient pancreatic cyst identification methodology using natural language processing,"Mehrabi S, Schmidt CM, Waters JA, Beesley C, Krishnan A, Kesterson J, Dexter P, Al-Haddad MA, Tierney WM, Palakal M.",Stud Health Technol Inform. 2013;192:822-6.,Mehrabi S,Stud Health Technol Inform,2013,2013-08-08,,,,"Pancreatic cancer is one of the deadliest cancers, mostly diagnosed at late 
 stages. Patients with pancreatic cysts are at higher risk of developing cancer 
 and their surveillance can help to diagnose the disease in earlier stages. In 
 this retrospective study we collected a corpus of 1064 records from 44 patients 
 at Indiana University Hospital from 1990 to 2012. A Natural Language Processing 
 (NLP) system was developed and used to identify patients with pancreatic cysts. 
 NegEx algorithm was used initially to identify the negation status of concepts 
 that resulted in precision and recall of 98.9% and 89% respectively. Stanford 
 Dependency parser (SDP) was then used to improve the NegEx performance resulting 
 in precision of 98.9% and recall of 95.7%. Features related to pancreatic cysts 
 were also extracted from patient medical records using regex and NegEx algorithm 
 with 98.5% precision and 97.43% recall. SDP improved the NegEx algorithm by 
 increasing the recall to 98.12%.
",,,,
23920902,Synonym-based word frequency analysis to support the development and presentation of a public health quality improvement taxonomy in an online exchange,"Pina J, Chester K, Danoff D, Koyanagi M.",Stud Health Technol Inform. 2013;192:1128.,Pina J,Stud Health Technol Inform,2013,2013-08-08,,,,"Word frequency analysis has not been fully explored as an input to public health 
 taxonomy development. We used document analysis, expert review, and 
 user-centered design to develop a taxonomy of public health quality improvement 
 concepts for an online exchange of quality improvement work (www.phqix.org). 
 Online entries were made searchable using a faceted search approach. To present 
 the most relevant facets to users, we analyzed 334 published public health 
 quality improvement documents using word frequency analysis to identify the most 
 prevalent clusters of word meanings. We reviewed the highest-weighted concepts 
 and identified their relationships to quality improvement details in our 
 taxonomy. The meanings were mapped to items in our taxonomy, and presented in 
 order of their weighted percentages in the data. Using this combination of 
 methods, we developed and sorted concepts in the faceted search presentation so 
 that relevant search criteria were accessible to users of the online exchange. 
 Word frequency analysis may be a useful method to incorporate in other taxonomy 
 development and presentationwhen relevant data is available.
",,,,
23920754,Analyzing SNOMED CT and HL7 terminology binding for semantic interoperability on post-genomic clinical trials,"Aso S, Perez-Rey D, Alonso-Calvo R, Rico-Diez A, Bucur A, Claerhout B, Maojo V.",Stud Health Technol Inform. 2013;192:980.,Aso S,Stud Health Technol Inform,2013,2013-08-08,,,,"Current post-genomic clinical trials in cancer involve the collaboration of 
 several institutions. Multi-centric retrospective analysis requires advanced 
 methods to ensure semantic interoperability. In this scenario, the objective of 
 the EU funded INTEGRATE project, is to provide an infrastructure to share 
 knowledge and data in post-genomic breast cancer clinical trials. This paper 
 presents the process carried out in this project, to bind domain terminologies 
 in the area, such as SNOMED CT, with the HL7 v3 Reference Information Model 
 (RIM). The proposed terminology binding follow the HL7 recommendations, but 
 should also consider important issues such as overlapping concepts and domain 
 terminology coverage. Although there are limitations due to the large 
 heterogeneity of the data in the area, the proposed process has been 
 successfully applied within the context of the INTEGRATE project. An improvement 
 in semantic interoperability of patient data from modern breast cancer clinical 
 trials, aims to enhance the clinical practice in oncology.
",,,,
23920555,User-centered design in clinical handover: exploring post-implementation outcomes for clinicians,"Wong MC, Cummings E, Turner P.",Stud Health Technol Inform. 2013;192:253-7.,Wong MC,Stud Health Technol Inform,2013,2013-08-08,,,,"This paper examines the outcomes for clinicians from their involvement in the 
 development of an electronic clinical hand-over tool developed using principles 
 of user-centered design. Conventional e-health post-implementation evaluations 
 tend to emphasize technology-related (mostly positive) outcomes. More recently, 
 unintended (mostly negative) consequences arising from the implementation of 
 e-health technologies have also been reported. There remains limited focus on 
 the post-implementation outcomes for users, particularly those directly involved 
 in e-health design processes. This paper presents detailed analysis and insights 
 into the outcomes experienced post-implementation by a cohort of junior 
 clinicians involved in developing an electronic clinical handover tool in 
 Tasmania, Australia. The qualitative methods used included observations, 
 semi-structured interviews and analysis of clinical handover notes. 
 Significantly, a number of unanticipated flow-on effects were identified that 
 mitigated some of the challenges arising during the design and implementation of 
 the tool. The paper concludes by highlighting the importance of identifying 
 post-implementation user outcomes beyond conventional system adoption and use 
 and also points to the need for more comprehensive evaluative frameworks to 
 encapsulate these broader socio-technical user outcomes.
",,,,
23920616,Evaluation of a computerized tool allowing retrospective detection of potential vitamin K antagonist overdoses in complex contexts,"Ferret L, Luyckx M, Merlin B, Ficheur G, Chazard E, Beuscart R.",Stud Health Technol Inform. 2013;192:553-6.,Ferret L,Stud Health Technol Inform,2013,2013-08-08,,,,"Management of vitamin K antagonists (VKA) is difficult, and overdoses can have 
 dramatic hemorrhagic consequences. These works form part of a European 
 computerized medical data processing project, which aims to develop IT tools for 
 describing adverse drug events (ADEs). Materials and methods A tool enabling 
 retrospective research of potential ADE cases was developed, using complex ADE 
 detection rules taking into account chronological parameters: the ADE 
 scorecards. The rules were applied on 14,748 medical records from a community 
 hospital. We evaluated the predictive positive value of the rules related to INR 
 elevation by an expert review of the detected cases. The severity of the 
 clinical consequences was evaluated. Results 49 cases were detected, among which 
 11 cases were ADEs. The predictive positive value of the rules is 22.44%, mostly 
 related to antibiotics and amiodarone introduction. The four cases of clinical 
 damage related to a drug were properly designated by the rules. Discussion - 
 Conclusion Our study shows the great potential of developing complex rules for 
 the identification of adverse drug events in large medical databases.
",,,,
25000021,The development and evaluation of a new coding system for medical records,Papazissis E.,Stud Health Technol Inform. 2014;202:83-6.,Papazissis E,Stud Health Technol Inform,2014,2014-07-08,,,,"PURPOSE: The present study aims to develop a simple, reliable and easy tool 
 enabling clinicians to codify the major part of individualized medical details 
 (patient history and findings of physical examination) quickly and easily in 
 routine medical practice, by entering data to a purpose-built software 
 application, using structure data elements and detailed medical illustrations.
 MATERIALS AND METHODS: We studied medical records of 9,320 patients and we 
 extracted individualized medical details. We recorded the majority of symptoms 
 and the majority of findings of physical examination into the system, which was 
 named IMPACT® (Intelligent Medical Patient Record and Coding Tool). Subsequently 
 the system was evaluated by clinicians, based on the examination of 1206 
 patients.
 RESULTS: The evaluation results showed that IMPACT® is an efficient tool, easy 
 to use even under time-pressing conditions.
 CONCLUSION: IMPACT® seems to be a promising tool for illustration-guided, 
 structured data entry of medical narrative, in electronic patient records.
",,,,
25000038,Recognizing Questions and Answers in EMR Templates Using Natural Language Processing,"Divita G, Shen S, Carter ME, Redd A, Forbush T, Palmer M, Samore MH, Gundlapalli AV.",Stud Health Technol Inform. 2014;202:149-52.,Divita G,Stud Health Technol Inform,2014,2014-07-08,,,,"Templated boilerplate structures pose challenges to natural language processing 
 (NLP) tools used for information extraction (IE). Routine error analyses while 
 performing an IE task using Veterans Affairs (VA) medical records identified 
 templates as an important cause of false positives. The baseline NLP pipeline 
 (V3NLP) was adapted to recognize negation, questions and answers (QA) in various 
 template types by adding a negation and slot:value identification annotator. The 
 system was trained using a corpus of 975 documents developed as a reference 
 standard for extracting psychosocial concepts. Iterative processing using the 
 baseline tool and baseline+negation+QA revealed loss of numbers of concepts with 
 a modest increase in true positives in several concept categories. Similar 
 improvement was noted when the adapted V3NLP was used to process a random sample 
 of 318,000 notes. We demonstrate the feasibility of adapting an NLP pipeline to 
 recognize templates.
",,,,
25000009,Machine Learning for Knowledge Extraction from PHR Big Data,"Poulymenopoulou M, Malamateniou F, Vassilacopoulos G.",Stud Health Technol Inform. 2014;202:36-9.,Poulymenopoulou M,Stud Health Technol Inform,2014,2014-07-08,,,,"Cloud computing, Internet of things (IOT) and NoSQL database technologies can 
 support a new generation of cloud-based PHR services that contain heterogeneous 
 (unstructured, semi-structured and structured) patient data (health, social and 
 lifestyle) from various sources, including automatically transmitted data from 
 Internet connected devices of patient living space (e.g. medical devices 
 connected to patients at home care). The patient data stored in such PHR systems 
 constitute big data whose analysis with the use of appropriate machine learning 
 algorithms is expected to improve diagnosis and treatment accuracy, to cut 
 healthcare costs and, hence, to improve the overall quality and efficiency of 
 healthcare provided. This paper describes a health data analytics engine which 
 uses machine learning algorithms for analyzing cloud based PHR big health data 
 towards knowledge extraction to support better healthcare delivery as regards 
 disease diagnosis and prognosis. This engine comprises of the data preparation, 
 the model generation and the data analysis modules and runs on the cloud taking 
 advantage from the map/reduce paradigm provided by Apache Hadoop.
",,,,
25160179,SNOMED CT adoption in Denmark--why is it so hard?,"Højen AR, Elberg PB, Andersen SK.",Stud Health Technol Inform. 2014;205:226-30.,Højen AR,Stud Health Technol Inform,2014,2014-08-28,,,,"What prevents the National Health Care Terminology based on SNOMED CT from being 
 implemented in the EHR systems and ongoing EHR implementations in Denmark? 
 SNOMED CT was translated into Danish language from 2006-2009 and by 2013 it is 
 not yet implemented in a clinical information system. Fourteen key persons 
 broadly representing all major stakeholders in the process of system 
 configuration accepted an invitation to discuss questions about what kind of 
 challenges they experience in handling terminology in clinical information 
 systems today and what they expect from a future implementation of a SNOMED CT 
 based national terminology. Three types of challenges of terminology 
 implementations resulted from two parallel focus group interviews: 1. Methods to 
 manage terminology-implementation like preventing inconsistency and redundant 
 representations of identical information. 2. The existing terminology and 
 classifications used are sufficient to accommodate the required governance and 
 3. SNOMED CT is expected to be immature for system-implementation. These results 
 suggest further research in methods to facilitate implementation of a complex 
 terminology and studies that evaluate SNOMED CT in clinical use; but the results 
 also support national and regional decision makers regarding what kind of 
 challenges they must manage.
",,,,
24825683,A reference architecture for semantic interoperability and its practical application,"Zunner C, Ganslandt T, Prokosch HU, Bürkle T.",Stud Health Technol Inform. 2014;198:40-6.,Zunner C,Stud Health Technol Inform,2014,2014-05-15,,,,"OBJECTIVE: Reusing EPR data for secondary purposes often requires mapping to 
 classifications and vocabularies such as ICD, LOINC or NCI thesaurus. We aimed 
 for a common architecture which supports the use of different vocabularies and 
 mapping tools.
 METHODS: We integrated the components clinical data warehouse, vocabulary 
 resources and mapping tools with the EPR and client applications.
 RESULTS: In two projects we used this architecture to map laboratory parameters 
 from the LIS to LOINC, and to map clinical data elements from the Soarian EPR to 
 the cancer registry system using the NCI-Thesaurus®.
 CONCLUSION: The approach was successful in both projects. The reference 
 architecture does not resolve the mapping task, but provides reusable 
 integration links between the different components and thus facilitates further 
 mapping activities.
",,,,
25160311,Interconnection of electronic medical record with clinical data management system by CDISC ODM,"Matsumura Y, Hattori A, Manabe S, Takeda T, Takahashi D, Yamamoto Y, Murata T, Mihara N.",Stud Health Technol Inform. 2014;205:868-72.,Matsumura Y,Stud Health Technol Inform,2014,2014-08-28,,,,"EDC system has been used in the field of clinical research. The current EDC 
 system does not connect with electronic medical record system (EMR), thus a 
 medical staff has to transcribe the data in EMR to EDC system manually. This 
 redundant process causes not only inefficiency but also human error. We 
 developed an EDC system cooperating with EMR, in which the data required for a 
 clinical research form (CRF) is transcribed automatically from EMR to electronic 
 CRF (eCRF) and is sent via network. We call this system as ""eCRF reporter"". The 
 interface module of eCRF reporter can retrieves the data in EMR database 
 including patient biography data, laboratory test data, prescription data and 
 data entered by template in progress notes. The eCRF reporter also enables users 
 to enter data directly to eCRF. The eCRF reporter generates CDISC ODM file and 
 PDF which is a translated form of Clinical data in ODM. After storing eCRF in 
 EMR, it is transferred via VPN to a clinical data management system (CDMS) which 
 can receive the eCRF files and parse ODM. We started some clinical research by 
 using this system. This system is expected to promote clinical research 
 efficiency and strictness.
",,,,
25160281,Abbreviations in Swedish Clinical Text--use by three professions,"Lövestam E, Velupillai S, Kvist M.",Stud Health Technol Inform. 2014;205:720-4.,Lövestam E,Stud Health Technol Inform,2014,2014-08-28,,,,"A list of 266 abbreviations from dieticians' notes in patient records was used 
 to extract the same abbreviations from patient records written by three 
 professions: dieticians, nurses and physicians. A context analysis of 40 of the 
 abbreviations showed that ambiguous meanings were common. Abbreviations used by 
 dieticians were found to be used by other professions, but not always with the 
 same meaning. This ambiguity of abbreviations might cause misunderstandings and 
 put patient safety at risk.
",,,,
25160258,Comparing narrative versus numerical display of functional information: impact on sense-making,"Weir C, Dunlea R, Staggers N, Dooing-Harris K, Mccormick T, Barrus R.",Stud Health Technol Inform. 2014;205:609-13.,Weir C,Stud Health Technol Inform,2014,2014-08-28,PMC4863447,NIHMS783366,,"Contextual information consists of functional, social, and financial information 
 about patients. Physicians routinely have difficulty incorporating contextual 
 information into clinical decision-making despite the emphasis on 
 patient-centered care and functional status. One reason for this difficulty is 
 that such information is not well-represented in the patient medical record. 
 This study assesses the impact of a ""story-form"" model versus a ""medical"" model 
 on a practitioner's ability to recall and incorporate contextual information. We 
 assessed this question through the analysis of responses of 30 clinicians to 2 
 vignettes presenting contextual information in both formats. Overall, there was 
 a statistically significant difference between the narrative and numerical form 
 with those receiving the narrative form for contextual information being more 
 likely to consider it a top issue. Reference to goals in the report of key 
 clinical factors was also significantly higher for the group receiving goal 
 information. Implications for sharing contextual information in EMRs are 
 discussed.
",,,,
25087537,A case study on parsing chemotherapy related free-text data,"Prodan A, Curry J.",Stud Health Technol Inform. 2014;204:116-22.,Prodan A,Stud Health Technol Inform,2014,2014-08-05,,,,"When modelling and simulating healthcare related processes, free-text data is 
 often the only possible source of information. This data may contain vocabulary 
 variations such as mistyped, misspelled and/or abbreviated words. This paper 
 describes a semi-automated approach to free-text normalisation based on a 
 combination of commonly used techniques and local expertise of medical oncology 
 nurses. The approach emphasises the effectiveness of the vocabulary creation 
 process through an interactive software application. When local knowledge is 
 successfully captured, normalisation of large data sets can be done very rapidly 
 with a high accuracy rate achieved. Furthermore, the techniques for localised 
 normalisation can have significant benefits to free-text parsing accuracy when 
 data is aggregated from multiple sites (hospitals). This research may lead to 
 increased understanding of issues associated with chemotherapy related free-text 
 data which in turn may impact patient treatment safety.
",,,,
25160294,The use of DRG for identifying clinical trials centers with high recruitment potential: a feasability study,"Aegerter P, Bendersky N, Tran TC, Ropers J, Taright N, Chatellier G.",Stud Health Technol Inform. 2014;205:783-7.,Aegerter P,Stud Health Technol Inform,2014,2014-08-28,,,,"Recruitment of large samples of patients is crucial for evidence level and 
 efficacy of clinical trials (CT). Clinical Trial Recruitment Support Systems 
 (CTRSS) used to estimate patient recruitment are generally specific to Hospital 
 Information Systems and few were evaluated on a large number of trials. Our aim 
 was to assess, on a large number of CT, the usefulness of commonly available 
 data as Diagnosis Related Groups (DRG) databases in order to estimate potential 
 recruitment. We used the DRG database of a large French multicenter medical 
 institution (1.2 million inpatient stays and 400 new trials each year). 
 Eligibility criteria of protocols were broken down into in atomic entities 
 (diagnosis, procedures, treatments...) then translated into codes and operators 
 recorded in a standardized form. A program parsed the forms and generated 
 requests on the DRG database. A large majority of selection criteria could be 
 coded and final estimations of number of eligible patients were close to 
 observed ones (median difference = 25). Such a system could be part of the 
 feasability evaluation and center selection process before the start of the 
 clinical trial.
",,,,
25000039,Detecting earlier indicators of homelessness in the free text of medical records,"Redd A, Carter M, Divita G, Shen S, Palmer M, Samore M, Gundlapalli AV.",Stud Health Technol Inform. 2014;202:153-6.,Redd A,Stud Health Technol Inform,2014,2014-07-08,,,,"Early warning indicators to identify US Veterans at risk of homelessness are 
 currently only inferred from administrative data. References to indicators of 
 risk or instances of homelessness in the free text of medical notes written by 
 Department of Veterans Affairs (VA) providers may precede formal identification 
 of Veterans as being homeless. This represents a potentially untapped resource 
 for early identification. Using natural language processing (NLP), we 
 investigated the idea that concepts related to homelessness written in the free 
 text of the medical record precede the identification of homelessness by 
 administrative data. We found that homeless Veterans were much higher utilizers 
 of VA resources producing approximately 12 times as many documents as 
 non-homeless Veterans. NLP detected mentions of either direct or indirect 
 evidence of homelessness in a significant portion of Veterans earlier than 
 structured data.
",,,,
25160348,Does SNOMED CT post-coordination scale?,"Karlsson D, Nyström M, Cornet R.",Stud Health Technol Inform. 2014;205:1048-52.,Karlsson D,Stud Health Technol Inform,2014,2014-08-28,,,,"SNOMED CT is a compositional terminology. Construction of post-coordinated 
 expressions allows users to specify new meaning by referencing existing SNOMED 
 CT concepts. The use of post-coordinated expressions in information systems 
 requires special software, a reasoner, to give the exact relations between 
 post-coordinated expressions and existing SNOMED CT content. Thus, the 
 performance characteristics of reasoners are important for implementation of 
 post-coordination in information systems. This study aims to test how reasoners 
 perform when a large number of post-coordinated expressions are added to SNOMED 
 CT. The time needed to classify an ontology consisting of SNOMED CT plus an 
 increasing number of post-coordinated expressions is measured. The best 
 performing reasoner in this test classifies SNOMED CT plus 1 million 
 post-coordinated expressions in 42 seconds. The time to classify grows a little 
 less than quadratic as the size of the ontology increases. In conclusion, 
 classification time is not a problem using current reasoners and current SNOMED 
 CT releases even if a large number of post-coordinated expressions are added.
",,,,
25160164,Semantic Krippendorff's α for measuring inter-rater agreement in SNOMED CT coding studies,"Karlsson D, Gøeg KR, Örman H, Højen AR.",Stud Health Technol Inform. 2014;205:151-5.,Karlsson D,Stud Health Technol Inform,2014,2014-08-28,,,,"Semantic interoperability requires consistency in use of terminologies such as 
 SNOMED CT. Inter-rater agreement measurement can be used to quantify this 
 consistency among terminology users. Increasingly, studies of SNOMED CT include 
 inter-rater agreement measures. However, published studies do not consider 
 distance between concepts when calculating the inter-rater agreement measures. 
 In this paper we propose a semantic inter-rater agreement measure for use with 
 SNOMED CT encoded data. A semantic Krippendorff's α measure is implemented using 
 a path-length based difference function. The measure is tested using three 
 different datasets. Results show that the proposed semantic measure is sensitive 
 to seriousness of coding differences whereas a nominal measure is not. The 
 proposed measure reflects the intuition that distance matters when comparing 
 uses of SNOMED CT.
",,,,
25160335,Protocol feasibility workflow using an automated multi-country patient cohort system,"Soto-Rey I, Trinczek B, Karakoyun T, Dugas M, Fritz F.",Stud Health Technol Inform. 2014;205:985-9.,Soto-Rey I,Stud Health Technol Inform,2014,2014-08-28,,,,"The Electronic Health Record for Clinical Research (EHR4CR) project aims to 
 improve the current process of clinical trials, providing a technological 
 platform that supports the design and execution of trials. For the protocol 
 feasibility scenario, the system currently allows the user to create a set of 
 in-/exclusion criteria to find patients matching these criteria across sites 
 located in several countries. The automated multi-country patient cohort system 
 developed in EHR4CR implies substantial changes on the current protocol 
 feasibility process, which will be reflected in this study.
",,,,
25160280,Automatic variance analysis of multistage care pathways,"Li X, Liu H, Zhang S, Mei J, Xie G, Yu Y, Li J, Lakshmanan GT.",Stud Health Technol Inform. 2014;205:715-9.,Li X,Stud Health Technol Inform,2014,2014-08-28,,,,"A care pathway (CP) is a standardized process that consists of multiple care 
 stages, clinical activities and their relations, aimed at ensuring and enhancing 
 the quality of care. However, actual care may deviate from the planned CP, and 
 analysis of these deviations can help clinicians refine the CP and reduce 
 medical errors. In this paper, we propose a CP variance analysis method to 
 automatically identify the deviations between actual patient traces in 
 electronic medical records (EMR) and a multistage CP. As the care stage 
 information is usually unavailable in EMR, we first align every trace with the 
 CP using a hidden Markov model. From the aligned traces, we report three types 
 of deviations for every care stage: additional activities, absent activities and 
 violated constraints, which are identified by using the techniques of temporal 
 logic and binomial tests. The method has been applied to a CP for the management 
 of congestive heart failure and real world EMR, providing meaningful evidence 
 for the further improvement of care quality.
",,,,
25160257,Real-time monitoring of clinical processes using complex event processing and transition systems,Meinecke S.,Stud Health Technol Inform. 2014;205:604-8.,Meinecke S,Stud Health Technol Inform,2014,2014-08-28,,,,"Dependencies between tasks in clinical processes are often complex and 
 error-prone. Our aim is to describe a new approach for the automatic derivation 
 of clinical events identified via the behaviour of IT systems using Complex 
 Event Processing. Furthermore we map these events on transition systems to 
 monitor crucial clinical processes in real-time for preventing and detecting 
 erroneous situations.
",,,,
25160156,Adverse drug event notification on a semantic interoperability framework,"Krahn T, Eichelberg M, Müller F, Gönül S, Laleci Erturkmen GB, Sinaci AA, Appelrath HJ.",Stud Health Technol Inform. 2014;205:111-5.,Krahn T,Stud Health Technol Inform,2014,2014-08-28,,,,"Adverse drug events (ADEs) are common, costly and one of the most important 
 issues in contemporary pharmacotherapy. Current drug safety surveillance methods 
 are largely based on spontaneous reports. However, this is known to be rather 
 ineffective. There is a lack of automated systems checking potential ADEs on 
 routine data captured in electronic health records (EHRs); present systems are 
 usually built directly on top of specific clinical information systems through 
 proprietary interfaces. In the context of the European project ""SALUS"", we aim 
 to provide an infrastructure as well as a tool-set for accessing and analyzing 
 clinical patient data of heterogeneous clinical information systems utilizing 
 standard methods. This paper focuses on two components of the SALUS 
 architecture: The ""Semantic Interoperability Layer"" (SIL) enables an access to 
 disparate EHR sources in order to provide the patient data in a common data 
 model for ADE detection within the ""ADE Detection and Notification Tool"" (ANT). 
 The SIL in combination with the ANT can be used in different clinical 
 environments to increase ADE detection and reporting rates. Thus, our approach 
 promises a profound impact in the domain of pharmacovigilance.
",,,,
24943581,Automatic generation of nursing narratives from entity-attribute-value triplet for electronic nursing records system,"Min YH, Park HA, Lee JY, Jo SJ, Jeon E, Byeon N, Choi SY, Chung E.",Stud Health Technol Inform. 2014;201:452-60.,Min YH,Stud Health Technol Inform,2014,2014-06-20,,,,"The aim of this study is to develop and evaluate a natural language generation 
 system to populate nursing narratives using detailed clinical models. Semantic, 
 contextual, and syntactical knowledges were extracted. A natural language 
 generation system linking these knowledges was developed. The quality of 
 generated nursing narratives was evaluated by the three nurse experts using a 
 five-point rating scale. With 82 detailed clinical models, in total 66,888 
 nursing narratives in four different types of statement were generated. The mean 
 scores for overall quality was 4.66, for content 4.60, for grammaticality 4.40, 
 for writing style 4.13, and for correctness 4.60. The system developed in this 
 study generated nursing narratives with different levels of granularity. The 
 generated nursing narratives can improve semantic interoperability of nursing 
 data documented in nursing records.
",,,,
25160351,A framework for integrating heterogeneous clinical data for a disease area into a central data warehouse,"Karmen C, Ganzinger M, Kohl CD, Firnkorn D, Knaup-Gregori P.",Stud Health Technol Inform. 2014;205:1060-4.,Karmen C,Stud Health Technol Inform,2014,2014-08-28,,,,"Structured collection of clinical facts is a common approach in clinical 
 research. Especially in the analysis of rare diseases it is often necessary to 
 aggregate study data from several sites in order to achieve a statistically 
 significant cohort size. In this paper we describe a framework how to approach 
 an integration of heterogeneous clinical data into a central register. This 
 enables site-spanning queries for the occurrence of specific clinical facts and 
 thus supports clinical research. The framework consists of three sequential 
 steps, starting from a formal data harmonization process, to the data 
 transformation methods and finally the integration into a proper data warehouse. 
 We implemented reusable software templates that are based on our best practices 
 in several projects in integrating heterogeneous clinical data. Our methods 
 potentially increase the efficiency and quality for future data integration 
 projects by reducing the implementation effort as well as the project management 
 effort by usage of our approaches as a guideline.
",,,,
24743069,Arranging ISO 13606 archetypes into a knowledge base using UML connectors,Kopanitsa G.,Stud Health Technol Inform. 2014;197:9-13.,Kopanitsa G,Stud Health Technol Inform,2014,2014-04-19,,,,"To enable the efficient reuse of standard based medical data we propose to 
 develop a higher-level information model that will complement the archetype 
 model of ISO 13606. This model will make use of the relationships that are 
 specified in UML to connect medical archetypes into a knowledge base within a 
 repository. UML connectors were analysed for their ability to be applied in the 
 implementation of a higher-level model that will establish relationships between 
 archetypes. An information model was developed using XML Schema notation. The 
 model allows linking different archetypes of one repository into a knowledge 
 base. Presently it supports several relationships and will be advanced in 
 future.
",,,,
25160191,Formalizing mappings to optimize automated schema alignment: application to rare diseases,"Maaroufi M, Choquet R, Landais P, Jaulent MC.",Stud Health Technol Inform. 2014;205:283-7.,Maaroufi M,Stud Health Technol Inform,2014,2014-08-28,,,,"In the era of data sharing and systems interoperability, the automation of data 
 schema alignment has become a priority. Discovering data mappings is the aim of 
 many alignment approaches that have been described in the literature and the 
 effectiveness of which depends on data specifications. In this context, we 
 propose a method for mappings formalization that allows automated data 
 integration processes optimization. This method, involving both data element 
 level and value element level, allows an automated inference of mappings 
 expressed by rules. In this paper, we start by describing the methods used to 
 achieve this mappings formalization. Then, we explain how it has been validated 
 by characterizing data from two use cases. We end up by discussing the 
 objectives of the proposed formalization.
",,,,
25160343,Describing localized diseases in medical ontology: an FMA-based algorithm,"Charlet J, Mazuel L, Declerck G, Miroux P, Gayet P.",Stud Health Technol Inform. 2014;205:1023-7.,Charlet J,Stud Health Technol Inform,2014,2014-08-28,,,,"OntolUrgences is a termino-ontological resource developed to index and retrieve 
 information in electronic Emergency Medical Record. In this project, we improved 
 the ontology coverage to accommodate both anatomical and pathophysiological 
 concepts in emergency medicine. This work lead to the automatic addition of 
 3,470 concepts and their underlying semantic formalization. In our method, we 
 reuse and select the anatomical concepts relevant to emergency from FMA: To 
 capture the anatomical specific concepts, (i) we involved Emergency 
 practitioners and identified the key concepts from this domain; (ii) we applied 
 an automatic algorithm to define the semantic relationships and integrated the 
 result in the existing ontology.
",,,,
25160309,Towards an automatic harmonization of the representation of medical reports to assess their similarities,"Parès Y, Aimé X, Charlet J, Jaulent MC.",Stud Health Technol Inform. 2014;205:858-62.,Parès Y,Stud Health Technol Inform,2014,2014-08-28,,,,"Numerous hospitals contain unexploited knowledge deposits. These often take the 
 form of unstructured records with heterogeneous content, which, at various 
 levels of those organizations, register past cases. Those records are for 
 instance patient medical records. Accessing the knowledge and experience they 
 gather would help us to handle present cases. We present here a method to 
 normalize textual reports in foetopathology in order to constitute a proper case 
 base that will be the target of case-based reasoning techniques. Statistics of 
 noise and silence generated by this method on 10 cases are presented.
",,,,
24943572,Applied nursing informatics research - state-of-the-art methodologies using electronic health record data,"Park JI, Pruinelli L, Westra BL, Delaney CW.",Stud Health Technol Inform. 2014;201:395-400.,Park JI,Stud Health Technol Inform,2014,2014-06-20,,,,"With the pervasive implementation of electronic health records (EHR), new 
 opportunities arise for nursing research through use of EHR data. Increasingly, 
 comparative effectiveness research within and across health systems is conducted 
 to identify the impact of nursing for improving health, health care, and 
 lowering costs of care. Use of EHR data for this type of research requires use 
 of national and internationally recognized nursing terminologies to normalize 
 data. Research methods are evolving as large data sets become available through 
 EHRs. Little is known about the types of research and analytic methods for 
 applied to nursing research using EHR data normalized with nursing 
 terminologies. The purpose of this paper is to report on a subset of a 
 systematic review of peer reviewed studies related to applied nursing 
 informatics research involving EHR data using standardized nursing 
 terminologies.
",,,,
25160345,Effective ways for the transmission of infection prevention data according to German legal specifications via the medical terminology SNOMED CT used with HL7 CDA templates,"Dewenter H, Heitmann KU, Treinat L, Thun S.",Stud Health Technol Inform. 2014;205:1033-7.,Dewenter H,Stud Health Technol Inform,2014,2014-08-28,,,,"According to German legal specifications each national federal state is obliged 
 to transmit infection prevention data to the relevant health authority. In case 
 of reasonable suspicion, affection or death by infectious diseases specific 
 information is differently communicated by laboratories and physicians. 
 Proprietary ways of transmission inherit threats like deficient or incomplete 
 availability of data. At least these circumstances imply non-predictable 
 health-related hazards for the population. The international established medical 
 terminology SNOMED CT can contribute semantic interoperability and a highly 
 specific description of diagnoses and procedures. The applicability of SNOMED CT 
 shall be tested in the domain of diagnostic findings respective notifiable 
 infectious agents. In addition, specific hierarchical links from the agents to 
 the associated infectious diseases inside the terminology are expected and 
 verified. As the carrier of the information, HL7's Clinical Document 
 Architecture (CDA) is used by designing appropriate CDA templates to define the 
 contents of the notifiable disease documentation. The results demonstrate that 
 the entirety of the notifiable infectious agents is displayed in the terminology 
 SNOMED CT by relating codes at 100 percent. Furthermore, each single term is 
 hierarchically connected to the relating infectious diseases. The use of SNOMED 
 CT for the purpose of infection prevention in Germany is tied to licensing and 
 license costs. Irrespective of these facts, the use of SNOMED CT shows obvious 
 advantages in this field and an implementation of the terminology can be 
 recommended.
",,,,
24825691,Validating EHR documents: automatic schematron generation using archetypes,"Pfeiffer K, Duftschmid G, Rinner C.",Stud Health Technol Inform. 2014;198:101-7.,Pfeiffer K,Stud Health Technol Inform,2014,2014-05-15,,,,"The goal of this study was to examine whether Schematron schemas can be 
 generated from archetypes. The openEHR Java reference API was used to transform 
 an archetype into an object model, which was then extended with context 
 elements. The model was processed and the constraints were transformed into 
 corresponding Schematron assertions. A prototype of the generator for the 
 reference model HL7 v3 CDA R2 was developed and successfully tested. 
 Preconditions for its reusability with other reference models were set. Our 
 results indicate that an automated generation of Schematron schemas is possible 
 with some limitations.
",,,,
25160371,Visualizing unstructured patient data for assessing diagnostic and therapeutic history,"Deng Y, Denecke K.",Stud Health Technol Inform. 2014;205:1158-62.,Deng Y,Stud Health Technol Inform,2014,2014-08-28,,,,"Having access to relevant patient data is crucial for clinical decision making. 
 The data is often documented in unstructured texts and collected in the 
 electronic health record. In this paper, we evaluate an approach to visualize 
 information extracted from clinical documents by means of tag cloud. Tag clouds 
 will be generated using a bag of word approach and by exploiting part of speech 
 tags. For a real word data set comprising radiological reports, pathological 
 reports and surgical operation reports, tag clouds are generated and a 
 questionnaire-based study is conducted as evaluation. Feedback from the 
 physicians shows that the tag cloud visualization is an effective and rapid 
 approach to represent relevant parts of unstructured patient data. To handle the 
 different medical narratives, we have summarized several possible improvements 
 according to the user feedback and evaluation results.
",,,,
24825707,Generation of ELGA-compatible radiology reports from the Vienna Hospital Association's EHR system,"Haider J, Hölzl K, Toth H, Duftschmid G.",Stud Health Technol Inform. 2014;198:226-31.,Haider J,Stud Health Technol Inform,2014,2014-05-15,,,,"In the course of setting up the upcoming Austrian national shared EHR system 
 ELGA, adaptors will have to be implemented for the local EHR systems of all 
 participating healthcare providers. These adaptors must be able to transform EHR 
 data from the internal format of the particular local EHR system to the 
 specified format of the ELGA document types and vice versa. In the course of an 
 ongoing diploma thesis we are currently developing a transformation application 
 that shall allow the generation of ELGA-compatible radiology reports from the 
 local EHR system of the Vienna Hospital Association. Up to now a first prototype 
 has been developed that was tested with six radiology reports. It generates 
 technically valid ELGA radiology reports apart from two errors yielded by the 
 ELGA online validator that rather seem to be bugs of the validator. A medical 
 validation of the reports remains to be done.
",,,,
25160350,Towards a light-weight query engine for accessing health sensor data in a fall prevention system,"Kreiner K, Gossy C, Drobics M.",Stud Health Technol Inform. 2014;205:1055-9.,Kreiner K,Stud Health Technol Inform,2014,2014-08-28,,,,"Connecting various sensors in sensor networks has become popular during the last 
 decade. An important aspect next to storing and creating data is information 
 access by domain experts, such as researchers, caretakers and physicians. In 
 this work we present the design and prototypic implementation of a light-weight 
 query engine using natural language processing for accessing health-related 
 sensor data in a fall prevention system.
",,,,
25160165,Preservation of information in terminology transcoding,"Griffon N, Merabti T, Cormont S, Tariel-Laurent S, Massari P, Lepage E, Chniti A, Daniel C, Darmoni SJ.",Stud Health Technol Inform. 2014;205:156-60.,Griffon N,Stud Health Technol Inform,2014,2014-08-28,,,,"Linking interface terminologies (IT) to reference terminologies (RT) in flow of 
 terminologies may allow health information system to be both usable and 
 interoperable. Two French university hospitals worked independently on such a 
 flow from the prescription of lab-test to the display of the corresponding 
 results. The aim of this study was to evaluate the transmission of information 
 in these two hospitals communication. An expert, supported by natural language 
 processing tool, created the gold standard link between the 2 prescription ITs 
 i.e. the terms that share the same meaning. A semantic pathway was defined to 
 allow the mapping of one prescription IT to the other, through LOINC® and 
 SNOMED®, the RT chosen by each hospital, respectively. The capacity of the 
 semantic pathway to identify the correct links was computed. The expert found 
 218 links between the 2 prescription ITs (containing 580 and 374 terms that are 
 linked to RT). The semantic pathway correctly identifies 96 of these links 
 (44.0% [37.4-50.6]). The recall was not as good as expected, even though the 
 semantic pathway was created in order to maximize it. Using different RT in 
 different hospitals is not an efficient solution. The use of LOINC® seems to be 
 preferable as a RT for prescription.
",,,,
25160344,Implementing reusable software components for SNOMED CT diagram and expression concept representations,"Bánfai B, Porció R, Kovács T.",Stud Health Technol Inform. 2014;205:1028-32.,Bánfai B,Stud Health Technol Inform,2014,2014-08-28,,,,"SNOMED CT is a vital component in the future of semantic interoperability in 
 healthcare as it provides the meaning to EHRs via its semantically rich, 
 controlled terminology. Communicating the concepts of this terminology to both 
 humans and machines is crucial therefore formal guidelines for diagram and 
 expression representations have been developed by the curators of SNOMED CT. 
 This paper presents a novel, model-based approach to implementing these 
 guidelines that allows simultaneous editing of a concept via both diagram and 
 expression editors. The implemented extensible software component can be 
 embedded both both desktop and web applications.
",,,,
25000025,From Computer-interpretable Guidelines to Computer-interpretable Quality Indicators: A Case for an Ontology,"White P, Roudsari A.",Stud Health Technol Inform. 2014;202:99-102.,White P,Stud Health Technol Inform,2014,2014-07-08,,,,"In the United Kingdom's National Health Service, quality indicators are 
 generally measured electronically by using queries and data extraction, 
 resulting in overlap and duplication of query components. Electronic measurement 
 of health care quality indicators could be improved through an ontology intended 
 to reduce duplication of effort during healthcare quality monitoring. While much 
 research has been published on ontologies for computer-interpretable guidelines, 
 quality indicators have lagged behind. We aimed to determine progress on the use 
 of ontologies to facilitate computer-interpretable healthcare quality 
 indicators. We assessed potential for improvements to computer-interpretable 
 healthcare quality indicators in England. We concluded that an ontology for a 
 large, diverse set of healthcare quality indicators could benefit the NHS and 
 reduce workload, with potential lessons for other countries.
",,,,
25160190,A conceptual framework to design a dimensional model based on the HL7 Clinical Document Architecture,"Pecoraro F, Luzi D, Ricci FL.",Stud Health Technol Inform. 2014;205:278-82.,Pecoraro F,Stud Health Technol Inform,2014,2014-08-28,,,,"This paper proposes a conceptual framework to design a dimensional model based 
 on the HL7 Clinical Document Architecture (CDA) standard. The adoption of this 
 framework can represent a possible solution to facilitate the integration of 
 heterogeneous information systems in a clinical data warehouse. This can 
 simplify the Extract, Transform and Load (ETL) procedures that are considered 
 the most time-consuming and expensive part of the data warehouse development 
 process. The paper describes the main activities to be carried out to design the 
 dimensional model outlining the main advantages in the application of the 
 proposed framework. The feasibility of our approach is also demonstrated 
 providing a case study to define clinical indicators for quality assessment.
",,,,
24743074,Automated detection of ambiguity in BI-RADS assessment categories in mammography reports,"Bozkurt S, Rubin D.",Stud Health Technol Inform. 2014;197:35-9.,Bozkurt S,Stud Health Technol Inform,2014,2014-04-19,,,,"An unsolved challenge in biomedical natural language processing (NLP) is 
 detecting ambiguities in the reports that can help physicians to improve report 
 clarity. Our goal was to develop NLP methods to tackle the challenges of 
 identifying ambiguous descriptions of the laterality of BI-RADS Final Assessment 
 Categories in mammography radiology reports. We developed a text processing 
 system that uses a BI-RADS ontology we built as a knowledge source for automatic 
 annotation of the entities in mammography reports relevant to this problem. We 
 used the GATE NLP toolkit and developed customized processing resources for 
 report segmentation, named entity recognition, and detection of mismatches 
 between BI-RADS Final Assessment Categories and mammogram laterality. Our system 
 detected 55 mismatched cases in 190 reports and the accuracy rate was 81%. We 
 conclude that such NLP techniques can detect ambiguities in mammography reports 
 and may reduce discrepancy and variability in reporting.
",,,,
25160229,Development of temporal context-based feature abstractions for enabling monitoring and managing of interventions,"Hsueh PY, Ramakrishnan S, Yu K, Akushevich M, Sharma S, Mooiweer P.",Stud Health Technol Inform. 2014;205:471-5.,Hsueh PY,Stud Health Technol Inform,2014,2014-08-28,,,,"Disease self-management programs and intervention/care plan monitoring are often 
 unable to systematically leverage patient-generated information, especially 
 those requiring interpretation of the temporal contexts of the measurement. 
 While existing techniques help in capturing and storing the relevant data, their 
 ability to determine appropriate metrics most sensitive to that individual is 
 limited or non-existent. This is attributable to the lack of unifying models for 
 enabling such interpretations and the non-trivial process required to generate 
 meaningful feature abstractions to support individualized prognosis. To address 
 these issues, a data-driven approach designed to identify the right abstractions 
 for key features relevant to personalization and monitoring of care is 
 discussed.
",,,,
24825690,Visualization of CDA laboratory reports and long term trends as a possible EHR application for patients and physicians,"Obenaus M, Burgsteiner H.",Stud Health Technol Inform. 2014;198:93-100.,Obenaus M,Stud Health Technol Inform,2014,2014-05-15,,,,"To increase the patient's acceptance of electronic health records and 
 understanding for their laboratory findings a web application was developed 
 which presents all parameters and possible deviations of standard values in a 
 clear way and visualizes the time based trend of all recorded parameters 
 graphically. Documents corresponding to the Clinical document architecture (CDA) 
 R2 laboratory reports standard and a rapid prototyping framework called Groovy 
 on Grails were used. This work shows, that it is possible to create a useful, 
 standards based tool for patients and physicians with comparatively few 
 resources - an application that could be in similar form a part of an electronic 
 Health Record (EHR) system like the Austrian electronic Health Record (ELGA).
",,,,
25160358,Pediatric emergency department crowding: survival tree clustering for length of patient stay,"Windal F, Jeribi K, Ficheur G, Degoul S, Martinot A, Beuscart R, Renard JM.",Stud Health Technol Inform. 2014;205:1095-9.,Windal F,Stud Health Technol Inform,2014,2014-08-28,,,,"The objective of this study is to analyse the length of patient stay in 
 Pediatric emergency department according to diagnosis and the number of patients 
 over a 3 year-period. A survival tree was used, to explore the underlying 
 construct of overcrowding depending of the length of patient stay. The tree was 
 used to cluster 55.183 patients with respect to length of stay where 
 partitioning is based on covariates such as the number of patients, the 
 diagnosis and existence of complementary exams. The hazard ratio test was used 
 to determine optimal partition. The approach is illustrated using Electronic 
 Medical Record Software database available at the Pediatric Emergency Department 
 of Lille University Hospital.
",,,,
24743073,Practical implementation of a bridge between legacy EHR system and a clinical research environment,"Vishnyakova D, Bottone S, Pasche E, Lovis C.",Stud Health Technol Inform. 2014;197:29-33.,Vishnyakova D,Stud Health Technol Inform,2014,2014-04-19,,,,"Employing the bridge between Clinical Information System (CIS) and Clinical 
 Research Environment (CRE) can provide functionality, which is not easily, 
 implemented by traditional legacy EHR system. In this paper, the experience of 
 such implementation at the University Hospitals of Geneva is described. General 
 overview of the mapping of extracted from CIS data to the i2b2 Clinical Data 
 Warehouse is provided. The defined implementation manages to provide the 
 interoperability for the CRE.
",,,,
25160140,Arranging ISO 13606 archetypes into a knowledge base,Kopanitsa G.,Stud Health Technol Inform. 2014;205:33-7.,Kopanitsa G,Stud Health Technol Inform,2014,2014-08-28,,,,"To enable the efficient reuse of standard based medical data we propose to 
 develop a higher level information model that will complement the archetype 
 model of ISO 13606. This model will make use of the relationships that are 
 specified in UML to connect medical archetypes into a knowledge base within a 
 repository. UML connectors were analyzed for their ability to be applied in the 
 implementation of a higher level model that will establish relationships between 
 archetypes. An information model was developed using XML Schema notation. The 
 model allows linking different archetypes of one repository into a knowledge 
 base. Presently it supports several relationships and will be advanced in 
 future.
",,,,
25160218,HTML5 microdata as a semantic container for medical information exchange,"Kimura E, Kobayashi S, Ishihara K.",Stud Health Technol Inform. 2014;205:418-22.,Kimura E,Stud Health Technol Inform,2014,2014-08-28,,,,"Achieving interoperability between clinical electronic medical records (EMR) 
 systems and cloud computing systems is challenging because of the lack of a 
 universal reference method as a standard for information exchange with a secure 
 connection. Here we describe an information exchange scheme using HTML5 
 microdata, where the standard semantic container is an HTML document. We embed 
 HL7 messages describing laboratory test results in the microdata. We also 
 annotate items in the clinical research report with the microdata. We mapped the 
 laboratory test result data into the clinical research report using an HL7 
 selector specified in the microdata. This scheme can provide secure cooperation 
 between the cloud-based service and the EMR system.
",,,,
25160208,A reference data model of a metadata registry preserving semantics and representations of data elements,"Löpprich M, Jones J, Meinecke MC, Goldschmidt H, Knaup P.",Stud Health Technol Inform. 2014;205:368-72.,Löpprich M,Stud Health Technol Inform,2014,2014-08-28,,,,"Integration and analysis of clinical data collected in multiple data sources 
 over a long period of time is a major challenge even when data warehouses and 
 metadata registries are used. Since most metadata registries focus on describing 
 data elements to establish domain consistent data definition and providing item 
 libraries, hierarchical and temporal dependencies cannot be mapped. Therefore we 
 developed and validated a reference data model, based on ISO/IEC 11179, which 
 allows revision and branching control of conceptually similar data elements with 
 heterogeneous definitions and representations.
",,,,
24943528,From capturing nursing knowledge to retrieval of data from a data warehouse,"Thoroddsen A, Guðjónsdóttir HK, Guðjónsdóttir E.",Stud Health Technol Inform. 2014;201:79-86.,Thoroddsen A,Stud Health Technol Inform,2014,2014-06-20,,,,"The purpose of the project was to capture nursing data and knowledge, represent 
 it for use and re-use by retrieval from a data warehouse, which contains both 
 clinical and financial hospital data. Today nurses at LUH use standardized 
 nursing terminologies to document information related to patients and the 
 nursing care in the EHR at all times. Pre-defined order sets for nursing care 
 have been developed using best practice where available and tacit nursing 
 knowledge has been captured and coded with standardized nursing terminologies 
 and made explicit for dissemination in the EHR. All patient-nursing data is 
 permanently stored in a data repository. Core nursing data elements have been 
 selected for transfer and storage in the data warehouse and patient-nursing data 
 are now captured, stored, can be related to other data elements from the 
 warehouse and be retrieved for use and re-use.
",,,,
25160308,Analysis of eligibility criteria from ClinicalTrials.gov,"Doods J, Dugas M, Fritz F.",Stud Health Technol Inform. 2014;205:853-7.,Doods J,Stud Health Technol Inform,2014,2014-08-28,,,,"Electronic health care records are being used more and more for patient 
 documentation. This electronic data can be used for secondary purposes, for 
 example through systems that support clinical research. Eligibility criteria 
 have to be processable for such systems to work, but criteria published on 
 ClinicalTrials.gov have been shown to be complex, making them challenging to 
 re-use. We analysed the eligibility criteria on ClinicalTrials.gov using 
 automatic methods to determine whether the criteria definition and number 
 changed over time. From 1998 to 2012 the average number of words used to 
 describe eligibility criteria per year increased by 46%, while the average 
 number of lines used per year only slightly increases until 2000 and stabilizes 
 afterwards. Whether the increase of words resulted in increased criteria 
 complexity or whether more data elements are used to describe eligibility needs 
 further investigation.
",,,,
25160168,EHR-based disease registries to support integrated care in a health neighbourhood: an ontology-based methodology,"Liaw ST, Taggart J, Yu H.",Stud Health Technol Inform. 2014;205:171-5.,Liaw ST,Stud Health Technol Inform,2014,2014-08-28,,,,"Disease registries derived from Electronic Health Records (EHRs) are widely used 
 for chronic disease management. We approached registries from the perspective of 
 integrated care in a health neighbourhood, considering data quality issues such 
 as semantic interoperability (consistency), accuracy, completeness and 
 duplication. Our proposition is that a realist ontological approach is required 
 to accurately identify patients in an EHR or data repository, assess data 
 quality and fitness for use by the multidisciplinary integrated care team. We 
 report on this approach with routinely collected data in a practice based 
 research network in Australia.
",,,,
25160157,Ci4SeR--curation interface for semantic resources--evaluation with adverse drug reactions,"Souvignet J, Asfari H, Declerck G, Lardon J, Trombert-Paviot B, Jaulent MC, Bousquet C.",Stud Health Technol Inform. 2014;205:116-20.,Souvignet J,Stud Health Technol Inform,2014,2014-08-28,,,,"Evaluation and validation have become a crucial problem for the development of 
 semantic resources. We developed Ci4SeR, a Graphical User Interface to optimize 
 the curation work (not taking into account structural aspects), suitable for any 
 type of resource with lightweight description logic. We tested it on OntoADR, an 
 ontology of adverse drug reactions. A single curator has reviewed 326 terms 
 (1020 axioms) in an estimated time of 120 hours (2.71 concepts and 8.5 axioms 
 reviewed per hour) and added 1874 new axioms (15.6 axioms per hour). Compared 
 with previous manual endeavours, the interface allows increasing the speed-rate 
 of reviewed concepts by 68% and axiom addition by 486%. A wider use of Ci4SeR 
 would help semantic resources curation and improve completeness of knowledge 
 modelling.
",,,,
25160204,Integrating personalized health information from MedlinePlus in a patient portal,"Borbolla D, Del Fiol G, Taliercio V, Otero C, Campos F, Martinez M, Luna D, Quiros F.",Stud Health Technol Inform. 2014;205:348-52.,Borbolla D,Stud Health Technol Inform,2014,2014-08-28,,,,"The objective of this paper is to describe the implementation and use of context 
 aware information in Spanish from MedlinePlus embedded in a Patient Portal. 
 Personalized information can help patients solve problems, make treatment 
 decisions, gain confidence in their ability to care for themselves and 
 communicate with providers. To integrate MedlinePlus information in our 
 institutional PHR we used the HL7 Context-Aware Knowledge Retrieval Standard, 
 also known as the Infobutton Standard. After analysing one year of use, patients 
 accessed MedlinePlus information in Spanish in a similar rate to other 
 personalized information generated locally. Infobuttons associated to laboratory 
 test results were used in approximately 10% of patients portal sessions when 
 reviewing lab results.
",,,,
24943558,The use of standardized terminology to represent nursing knowledge: nursing interventions relevant to safety for patients with cancer,"Tseng H, Moorhead S.",Stud Health Technol Inform. 2014;201:298-303.,Tseng H,Stud Health Technol Inform,2014,2014-06-20,,,,"The study is to represent knowledge by identifying frequently used nursing 
 interventions in term of standardized nursing terminology (SNT) in the 
 Electronic Health Records (EHRs) relevant to Safety for Patients with Cancer. We 
 include 2,237 patients and found 11,804 nursing interventions in total. There 
 are 100 identical interventions in the study. We identify eleven nursing 
 interventions from four oncology units over 7 month observation. For the most 
 four frequent nursing interventions (Fall Prevention, Infection Control, 
 Infection Protection, and Pressure Management), we also report the mean of age, 
 the mean of length of stay, and their frequency of outcome rating , outcome 
 rating at admission and at discharge that link to outcome. These studies 
 demonstrate the strengths of SNT in clinical practice. The findings are valuable 
 to clinical practice, education and future research.
",,,,
25160364,Addressing the challenge of encoding causal epidemiological knowledge in formal ontologies: a practical perspective,"Okhmatovskaia A, Shaban-Nejad A, Lavigne M, Buckeridge DL.",Stud Health Technol Inform. 2014;205:1125-9.,Okhmatovskaia A,Stud Health Technol Inform,2014,2014-08-28,,,,"The paper presents an overview of approaches to encoding uncertain causal 
 knowledge in formal ontologies and demonstrates how these approaches can be used 
 in a semantic-driven application for public health using the Population Health 
 Record (PopHR) platform as an example.
",,,,
25160209,Longitudinal data driven study design,"Hund H, Gerth S, Lossnitzer D, Fegeler C.",Stud Health Technol Inform. 2014;205:373-7.,Hund H,Stud Health Technol Inform,2014,2014-08-28,,,,"In this paper we present a method for processing EHR data into a longitudinal 
 data model and examples for using this model to identify patients 
 cross-sectionally and longitudinally as well as testing study designs 
 retrospectively. Our data model describes measurements on four dimensions: the 
 associated patient, observed feature, data source and time of survey. The 
 transformation of structured source data into our model is defined by rules 
 written in XML. To showcase the flexibility of the proposed longitudinal data 
 model, we present an evolution of a retrospective study design as well as an 
 example for interpreting biomarkers in emergency situations. With the proposed 
 longitudinal data model complex queries can be performed, study designs tested 
 and optimized.
",,,,
25000001,Semantic interoperability in healthcare,Arvanitis TN.,Stud Health Technol Inform. 2014;202:5-8.,Arvanitis TN,Stud Health Technol Inform,2014,2014-07-08,,,,"The improved understanding of the whole healthcare and wellbeing pathway for 
 individuals depends on the power of healthcare information, being made readily 
 available and easily interpretable by both humans and machines. In the centre of 
 this challenge lies the concept of interoperability, as a way to provide 
 fundamental linkage, integration and meaningful use of healthcare data between 
 systems, organisations and users. In particular, semantic interoperability can 
 offer a way of enriching healthcare data with context and meaning, in order to 
 achieve enhanced understanding and better evidence-based interpretation of 
 disease and wellbeing for an individual, within the context of healthcare 
 provision and clinical research. In this keynote paper, the concept of semantic 
 interoperability, for healthcare data linkage and exchange, is critically 
 discussed. An emphasis is given on the importance of clinical terminologies and 
 associated services, as means for adding meaning to routinely collected clinical 
 data.
",,,,
24743070,Ontologies to capture adverse events following immunisation (AEFI) from real world health data,"Liyanage H, de Lusignan S.",Stud Health Technol Inform. 2014;197:15-9.,Liyanage H,Stud Health Technol Inform,2014,2014-04-19,,,,"Immunisation is an important part of health care and adverse events following 
 immunisation (AEFI) are relatively rare. AEFI can be detected through long term 
 follow up of a cohort or from looking for signals from real world, routine data; 
 from different health systems using a variety of clinical coding systems. 
 Mapping these is a challenging aspect of integrating data across borders. 
 Ontological representations of clinical concepts provide a method to map similar 
 concepts, in this case AEFI across different coding systems. We describe a 
 method using ontologies to be flag definite, probable or possible cases. We use 
 Guillain-Barre syndrome (GBS) as an AEFI to illustrate this method, and the 
 Brighton collaboration's case definition of GBS as the gold standard. Our method 
 can be used to flag definite, probable or possible cases of GBS. Whilst there 
 has been much research into the use of ontologies in immunisation these have 
 focussed on database interrogation; where ours looks to identify varying signal 
 strength.
",,,,
25160154,Plug-and-play Integration of dual-model based Knowledge Artefacts into an Open Source Ehr System,"Krexner R, Duftschmid G.",Stud Health Technol Inform. 2014;205:101-5.,Krexner R,Stud Health Technol Inform,2014,2014-08-28,,,,"In this paper we present our experiences with extending an existing approach for 
 an archetype-compliant collection and export of data according to the openEHR 
 specifications within the open source EHR system OpenMRS. It allows an automatic 
 generation of forms from templates, which were introduced by openEHR as an 
 extension of the dual-model approach. Data entered in these forms can be 
 exported in form of standardized EHR extracts. The use of templates allowed us 
 to solve problems reported for the original archetype-based version of the 
 approach, which were caused by the high optionality within archetypes.
",,,,
25160353,Breast cancer and quality of life: medical information extraction from health forums,"Opitz T, Aze J, Bringay S, Joutard C, Lavergne C, Mollevi C.",Stud Health Technol Inform. 2014;205:1070-4.,Opitz T,Stud Health Technol Inform,2014,2014-08-28,,,,"Internet health forums are a rich textual resource with content generated 
 through free exchanges among patients and, in certain cases, health 
 professionals. We tackle the problem of retrieving clinically relevant 
 information from such forums, with relevant topics being defined from clinical 
 auto-questionnaires. Texts in forums are largely unstructured and noisy, calling 
 for adapted preprocessing and query methods. We minimize the number of false 
 negatives in queries by using a synonym tool to achieve query expansion of 
 initial topic keywords. To avoid false positives, we propose a new measure based 
 on a statistical comparison of frequent co-occurrences in a large reference 
 corpus (Web) to keep only relevant expansions. Our work is motivated by a study 
 of breast cancer patients' health-related quality of life (QoL). We consider 
 topics defined from a breast-cancer specific QoL-questionnaire. We quantify and 
 structure occurrences in posts of a specialized French forum and outline 
 important future developments.
",,,,
24825695,Case-based visualization of a patient cohort using SEER epidemiologic data,"Maier C, Bürkle T, Prokosch HU, Ganslandt T.",Stud Health Technol Inform. 2014;198:133-40.,Maier C,Stud Health Technol Inform,2014,2014-05-15,,,,"Data from cancer registries can be used to track the epidemiology of cancer and 
 can potentially serve to guide individual diagnostic and treatment decisions. 
 Even though some cancer registry datasets have been made publicly available for 
 scientific and clinical use, few applications have so far provided direct access 
 to these data from within the patient context of an electronic patient record. 
 The goal of this project was to implement a proof-of-concept integration of the 
 public SEER (Surveillance, Epidemiology and End Results) cancer registry dataset 
 with a digital breast cancer tumor board at a German university hospital and to 
 determine its utility in the clinical settings. The integration was successfully 
 established, using data from routine documentation to provide dynamic 
 visualizations of cohort composition and Kaplan-Meier survival plots. Evaluation 
 feedback was favorable regarding the concept and implementation, but highlighted 
 that important data elements, e.g. receptor status data, were missing in the 
 SEER dataset, limiting clinical value of the system.
",,,,
25087545,Cluster analysis of medication adherence in Pacific patients with high cardiovascular risk,"Warren J, Gu Y, Kennelly J.",Stud Health Technol Inform. 2014;204:169-75.,Warren J,Stud Health Technol Inform,2014,2014-08-05,,,,"INTRODUCTION: The Caring Does Matter (CDM) programme aimed to improve 
 cardiovascular disease risk (CVR) management in Pacific people, targeting 
 medication adherence problems. This paper presents cluster analysis of CDM data 
 to model medication adherence and cardiovascular risk factors in high-CVR 
 patients.
 METHODS: Changes in cardiovascular medication adherence status and in 
 physiological measures of high-CVR Pacific patients, as well as their baseline 
 physiological measures, demographics and other risk factors are included in the 
 analysis. Differences in resulting clusters are described to provide insight 
 into the population.
 RESULTS: 1786 Pacific patients were identified with high CVR (≥ 10%, 5 year 
 event risk) at baseline and were still enrolled with the thirteen participating 
 general practices at CDM end. Two of three models attempted produced significant 
 clusters: a two-cluster model indicating patients who failed to improve 
 adherence during the programme had higher prevalence of diabetes; and a 
 three-cluster model where one cluster was characterised by higher but improving 
 blood pressure, and another characterised by higher but improving HbA1c.
 DISCUSSION AND CONCLUSION: Cluster analysis reveals statistically distinct 
 patient groups, including differences in characteristics of patients less 
 responsive to the programme intervention. This provides a basis for further 
 efforts to understand the population and better tailor interventions.
",,,,
25488239,Detection of healthcare-associated urinary tract infection in Swedish electronic health records,"Tanushi H, Kvist M, Sparrelid E.",Stud Health Technol Inform. 2014;207:330-9.,Tanushi H,Stud Health Technol Inform,2014,2014-12-10,,,,"The prevalence of healthcare-associated infections (HAI) stresses the need for 
 automatic surveillance in order to follow the effect of preventive measures. A 
 number of detection systems have been set up for several languages, but none is 
 known for Swedish hospitals. We plan a series of infection type specific 
 programs for detection of HAI in electronic health records at a Swedish 
 university hospital. Also, we aim at detecting HAI for patients entering 
 hospital with HAI from previous care, a task that is not often addressed. This 
 first study aims at surveillance of healthcare-associated urinary tract 
 infections. The created rule-based system depends on acquiring the essential 
 clinical information, and a combination of data and text mining is used. The 
 wide range of diverse clinics with different traditions of documentation poses 
 difficulties for detection. Results from evaluation on 1,867 care episodes from 
 Oncology and Surgery show high precision (0.98), specificity (0.99) and negative 
 predictive value (0.99), but an intermediate recall (0.60). An error analysis of 
 the evaluation is presented and discussed.
",,,,
26262366,Annotation methods to develop and evaluate an expert system based on natural language processing in electronic medical records,"Gicquel Q, Tvardik N, Bouvry C, Kergourlay I, Bittar A, Segond F, Darmoni S, Metzger MH.",Stud Health Technol Inform. 2015;216:1067.,Gicquel Q,Stud Health Technol Inform,2015,2015-08-12,,,,"The objective of the SYNODOS collaborative project was to develop a generic IT 
 solution, combining a medical terminology server, a semantic analyser and a 
 knowledge base. The goal of the project was to generate meaningful 
 epidemiological data for various medical domains from the textual content of 
 French medical records. In the context of this project, we built a care pathway 
 oriented conceptual model and corresponding annotation method to develop and 
 evaluate an expert system's knowledge base. The annotation method is based on a 
 semi-automatic process, using a software application (MedIndex). This 
 application exchanges with a cross-lingual multi-termino-ontology portal. The 
 annotator selects the most appropriate medical code proposed for the medical 
 concept in question by the multi-termino-ontology portal and temporally labels 
 the medical concept according to the course of the medical event. This choice of 
 conceptual model and annotation method aims to create a generic database of 
 facts for the secondary use of electronic health records data.
",,,,
26262006,Using EHRs and Machine Learning for Heart Failure Survival Analysis,"Panahiazar M, Taslimitehrani V, Pereira N, Pathak J.",Stud Health Technol Inform. 2015;216:40-4.,Panahiazar M,Stud Health Technol Inform,2015,2015-08-12,PMC4905764,NIHMS791406,,"""Heart failure (HF) is a frequent health problem with high morbidity and 
 mortality, increasing prevalence and escalating healthcare costs"" [1]. By 
 calculating a HF survival risk score based on patient-specific characteristics 
 from Electronic Health Records (EHRs), we can identify high-risk patients and 
 apply individualized treatment and healthy living choices to potentially reduce 
 their mortality risk. The Seattle Heart Failure Model (SHFM) is one of the most 
 popular models to calculate HF survival risk that uses multiple clinical 
 variables to predict HF prognosis and also incorporates impact of HF therapy on 
 patient outcomes. Although the SHFM has been validated across multiple cohorts 
 [1-5], these studies were primarily done using clinical trials databases that do 
 not reflect routine clinical care in the community. Further, the impact of 
 contemporary therapeutic interventions, such as beta-blockers or defibrillators, 
 was incorporated in SHFM by extrapolation from external trials. In this study, 
 we assess the performance of SHFM using EHRs at Mayo Clinic, and sought to 
 develop a risk prediction model using machine learning techiniques that applies 
 routine clinical care data. Our results shows the models which were built using 
 EHR data are more accurate (11% improvement in AUC) with the convenience of 
 being more readily applicable in routine clinical care. Furthermore, we 
 demonstrate that new predictive markers (such as co-morbidities) when 
 incorporated into our models improve prognostic performance significantly (8% 
 improvement in AUC).
",,,,
26262372,Interpreting Medical Information Using Machine Learning and Individual Conditional Expectation,"Nohara Y, Wakata Y, Nakashima N.",Stud Health Technol Inform. 2015;216:1073.,Nohara Y,Stud Health Technol Inform,2015,2015-08-12,,,,"Recently, machine-learning techniques have spread many fields. However, 
 machine-learning is still not popular in medical research field due to 
 difficulty of interpreting. In this paper, we introduce a method of interpreting 
 medical information using machine learning technique. The method gave new 
 explanation of partial dependence plot and individual conditional expectation 
 plot from medical research field.
",,,,
25991106,Health consumer-oriented information retrieval,"Claveau V, Hamon T, Le Maguer S, Grabar N.",Stud Health Technol Inform. 2015;210:80-4.,Claveau V,Stud Health Technol Inform,2015,2015-05-21,,,,"While patients can freely access their Electronic Health Records or online 
 health information, they may not be able to correctly understand the content of 
 these documents. One of the challenges is related to the difference between 
 expert and non-expert languages. We propose to investigate this issue within the 
 Information Retrieval field. The patient queries have to be associated with the 
 corresponding expert documents, that provide trustworthy information. Our 
 approach relies on a state-of-the-art IR system called Indri and on semantic 
 resources. Different query expansion strategies are explored. Our system shows 
 up to 0.6740 P@10, up to 0.7610 R@10, and up to 0.6793 NDCG@10.
",,,,
26262120,Generation of Natural-Language Textual Summaries from Longitudinal Clinical Records,"Goldstein A, Shahar Y.",Stud Health Technol Inform. 2015;216:594-8.,Goldstein A,Stud Health Technol Inform,2015,2015-08-12,,,,"Physicians are required to interpret, abstract and present in free-text large 
 amounts of clinical data in their daily tasks. This is especially true for 
 chronic-disease domains, but holds also in other clinical domains. We have 
 recently developed a prototype system, CliniText, which, given a time-oriented 
 clinical database, and appropriate formal abstraction and summarization 
 knowledge, combines the computational mechanisms of knowledge-based temporal 
 data abstraction, textual summarization, abduction, and natural-language 
 generation techniques, to generate an intelligent textual summary of 
 longitudinal clinical data. We demonstrate our methodology, and the feasibility 
 of providing a free-text summary of longitudinal electronic patient records, by 
 generating summaries in two very different domains - Diabetes Management and 
 Cardiothoracic surgery. In particular, we explain the process of generating a 
 discharge summary of a patient who had undergone a Coronary Artery Bypass Graft 
 operation, and a brief summary of the treatment of a diabetes patient for five 
 years.
",,,,
26262005,Fast Model Adaptation for Automated Section Classification in Electronic Medical Records,"Ni J, Delaney B, Florian R.",Stud Health Technol Inform. 2015;216:35-9.,Ni J,Stud Health Technol Inform,2015,2015-08-12,,,,"Medical information extraction is the automatic extraction of structured 
 information from electronic medical records, where such information can be used 
 for improving healthcare processes and medical decision making. In this paper, 
 we study one important medical information extraction task called section 
 classification. The objective of section classification is to automatically 
 identify sections in a medical document and classify them into one of the 
 pre-defined section types. Training section classification models typically 
 requires large amounts of human labeled training data to achieve high accuracy. 
 Annotating institution-specific data, however, can be both expensive and 
 time-consuming; which poses a big hurdle for adapting a section classification 
 model to new medical institutions. In this paper, we apply two advanced machine 
 learning techniques, active learning and distant supervision, to reduce 
 annotation cost and achieve fast model adaptation for automated section 
 classification in electronic medical records. Our experiment results show that 
 active learning reduces the annotation cost and time by more than 50%, and 
 distant supervision can achieve good model accuracy using weakly labeled 
 training data only.
",,,,
26262181,Development of Markup Language for Medical Record Charting: A Charting Language,"Jung WM, Chae Y, Jang BH.",Stud Health Technol Inform. 2015;216:879.,Jung WM,Stud Health Technol Inform,2015,2015-08-12,,,,"Nowadays a lot of trials for collecting electronic medical records (EMRs) exist. 
 However, structuring data format for EMR is an especially labour-intensive task 
 for practitioners. Here we propose a new mark-up language for medical record 
 charting (called Charting Language), which borrows useful properties from 
 programming languages. Thus, with Charting Language, the text data described in 
 dynamic situation can be easily used to extract information.
",,,,
26210421,Automatic Detection of Skin and Subcutaneous Tissue Infections from Primary Care Electronic Medical Records,"Gu Y, Kennelly J, Warren J, Nathani P, Boyce T.",Stud Health Technol Inform. 2015;214:74-80.,Gu Y,Stud Health Technol Inform,2015,2015-07-27,,,,"INTRODUCTION: Skin and subcutaneous tissue infections (SSTI) are common 
 conditions that cause avoidable hospitalisation in New Zealand. As part of a 
 program to improve the management of SSTI in primary care, electronic medical 
 records (EMR) of four Auckland general practices were analysed to identify SSTI 
 occurrences in the last three years.
 METHODS: An ontology for SSTI risks, manifestation and treatment was created 
 based on literature and guidelines. An SSTI identification algorithm was 
 developed examining EMR data for skin swab tests, diagnoses (READ codes) and 
 textual clinical notes.
 RESULTS: High occurrence and recurrence rates in those aged 20 or younger were 
 found. Due to low usage of READ coding and laboratory tests, 65% of SSTI 
 occurrences were identified by notes. However, 91% of all identified SSTI 
 occurrences were appropriately treated with oral/topical antibiotics according 
 to prescription records in the EMR. The F1 score of the analysis algorithm is 
 0.76 using manual review as gold standard.
 DISCUSSION AND CONCLUSION: The SSTI identification algorithm shows a reasonable 
 accuracy suggesting the feasibility of automatic detecting SSTI occurrences 
 using clinical data that are routinely collected in healthcare delivery.
",,,,
26063251,Semantic retrieval and navigation in clinical document collections,"Kreuzthaler M, Daumke P, Schulz S.",Stud Health Technol Inform. 2015;212:9-14.,Kreuzthaler M,Stud Health Technol Inform,2015,2015-06-12,,,,"Patients with chronic diseases undergo numerous in- and outpatient treatment 
 periods, and therefore many documents accumulate in their electronic records. We 
 report on an on-going project focussing on the semantic enrichment of medical 
 texts, in order to support recall-oriented navigation across a patient's 
 complete documentation. A document pool of 1,696 de-identified discharge 
 summaries was used for prototyping. A natural language processing toolset for 
 document annotation (based on the text-mining framework UIMA) and indexing 
 (Solr) was used to support a browser-based platform for document import, search 
 and navigation. The integrated search engine combines free text and 
 concept-based querying, supported by dynamically generated facets (diagnoses, 
 procedures, medications, lab values, and body parts). The prototype demonstrates 
 the feasibility of semantic document enrichment within document collections of a 
 single patient. Originally conceived as an add-on for the clinical workplace, 
 this technology could also be adapted to support personalised health record 
 platforms, as well as cross-patient search for cohort building and other 
 secondary use scenarios.
",,,,
25991241,Analysis of care pathway variation patterns in patient records,"Li X, Mei J, Liu H, Yu Y, Xie G, Hu J, Wang F.",Stud Health Technol Inform. 2015;210:692-6.,Li X,Stud Health Technol Inform,2015,2015-05-21,,,,"A care/clinical pathway (CP) is a standardized care process where temporal and 
 data constraints of clinical activities are defined to ensure quality of care. 
 In actual care practice, various situations of compliance and non-compliance 
 with CPs can be observed. Analysis of these CP variation patterns (CPVPs) can 
 help improve care quality and enhance decision support. In this paper, we 
 propose an automatic method to detect CPVPs in electronic medical records (EMR), 
 and statistically examine their correlation with patient outcomes. From each CP 
 constraint, we first derive a CPVP tree, where each pattern is represented using 
 first-order linear temporal logic and translated into a Büchi automaton for 
 pattern detection. Then we identify the CPVPs that are evidently correlated with 
 a patient outcome by examining the odds ratios. The method has been applied to a 
 CP for congestive heart failure and real world EMR to demonstrate the 
 effectiveness.
",,,,
26262059,A Decision Fusion Framework for Treatment Recommendation Systems,"Mei J, Liu H, Li X, Xie G, Yu Y.",Stud Health Technol Inform. 2015;216:300-4.,Mei J,Stud Health Technol Inform,2015,2015-08-12,,,,"Treatment recommendation is a nontrivial task--it requires not only domain 
 knowledge from evidence-based medicine, but also data insights from descriptive, 
 predictive and prescriptive analysis. A single treatment recommendation system 
 is usually trained or modeled with a limited (size or quality) source. This 
 paper proposes a decision fusion framework, combining both knowledge-driven and 
 data-driven decision engines for treatment recommendation. End users (e.g. using 
 the clinician workstation or mobile apps) could have a comprehensive view of 
 various engines' opinions, as well as the final decision after fusion. For 
 implementation, we leverage several well-known fusion algorithms, such as 
 decision templates and meta classifiers (of logistic and SVM, etc.). Using an 
 outcome-driven evaluation metric, we compare the fusion engine with base 
 engines, and our experimental results show that decision fusion is a promising 
 way towards a more valuable treatment recommendation.
",,,,
26262384,A Statistical Analysis of Term Occurrences in Radiology Reporting,"Hong Y, Zhang J, Zhu Y, Zhou X.",Stud Health Technol Inform. 2015;216:1085.,Hong Y,Stud Health Technol Inform,2015,2015-08-12,,,,"To compare term occurrences in free-text radiology reports and RSNA reporting 
 templates, we selected five templates from an RSNA reporting template library 
 and their corresponding free-text reports as a test set, and employed the 
 Wilcoxon signed-rank test to find out whether the terms in RSNA reporting 
 templates match those terms appearing in corresponding free-text radiology 
 reports. The results show that most terms in free-text radiology reports are 
 covered by RSNA reporting templates. By assessing the terminology coverage of 
 existing templates, this study may benefit the growth of the RSNA reporting 
 template library.
",,,,
26262123,Heart Failure Medications Detection and Prescription Status Classification in Clinical Narrative Documents,"Meystre SM, Kim Y, Heavirland J, Williams J, Bray BE, Garvin J.",Stud Health Technol Inform. 2015;216:609-13.,Meystre SM,Stud Health Technol Inform,2015,2015-08-12,PMC5009609,NIHMS809785,,"Angiotensin Converting Enzyme Inhibitors (ACEI) and Angiotensin II Receptor 
 Blockers (ARB) are two common medication classes used for heart failure 
 treatment. The ADAHF (Automated Data Acquisition for Heart Failure) project 
 aimed at automatically extracting heart failure treatment performance metrics 
 from clinical narrative documents, and these medications are an important 
 component of the performance metrics. We developed two different systems to 
 detect these medications, rule-based and machine learning-based. The rule-based 
 system used dictionary lookups with fuzzy string searching and showed successful 
 performance even if our corpus contains various misspelled medications. The 
 machine learning-based system uses lexical and morphological features and 
 produced similar results. The best performance was achieved when combining the 
 two methods, reaching 99.3% recall and 98.8% precision. To determine the 
 prescription status of each medication (i.e., active, discontinued, or 
 negative), we implemented a SVM classifier with lexical features and achieved 
 good performance, reaching 95.49% accuracy, in a five-fold cross-validation 
 evaluation.
",,,,
25991107,A methodology for mining clinical data: experiences from TRANSFoRm project,"Danger R, Corrigan D, Soler JK, Kazienko P, Kajdanowicz T, Majeed A, Curcin V.",Stud Health Technol Inform. 2015;210:85-9.,Danger R,Stud Health Technol Inform,2015,2015-05-21,,,,"Data mining of electronic health records (eHRs) allows us to identify patterns 
 of patient data that characterize diseases and their progress and learn best 
 practices for treatment and diagnosis. Clinical Prediction Rules (CPRs) are a 
 form of clinical evidence that quantifies the contribution of different clinical 
 data to a particular clinical outcome and help clinicians to decide the 
 diagnosis, prognosis or therapeutic conduct for any given patient. The TRANSFoRm 
 diagnostic support system (DSS) is based on the construction of an ontological 
 repository of CPRs for diagnosis prediction in which clinical evidence is 
 expressed using a unified vocabulary. This paper explains the proposed 
 methodology for constructing this CPR repository, addressing algorithms and 
 quality measures for filtering relevant rules. Some preliminary application 
 results are also presented.
",,,,
26262110,InfoRoute: the CISMeF Context-specific Search Algorithm,"Merabti T, Lelong R, Darmoni S.",Stud Health Technol Inform. 2015;216:544-8.,Merabti T,Stud Health Technol Inform,2015,2015-08-12,,,,"OBJECTIVE: The aim of this paper was to present a practical InfoRoute algorithm 
 and applications developed by CISMeF to perform a contextual information 
 retrieval across multiple medical websites in different health domains.
 METHODS: The algorithm was developed to treat multiple types of queries: 
 natural, Boolean and advanced. The algorithm also generates multiple types of 
 queries: Boolean query, PubMed query or Advanced query. Each query can be 
 extended via an inter alignments relationship from UMLS and HeTOP portal.
 RESULTS: A web service and two web applications have been developed based on the 
 InfoRoute algorithm to generate links-query across multiple websites, i.e.: 
 ""PubMed"" or ""ClinicalTrials.org"".
 CONCLUSION: The InfoRoute algorithm is a useful tool to perform contextual 
 information retrieval across multiple medical websites in both English and 
 French.
",,,,
25991100,Automatic extraction of numerical values from unstructured data in EHRs,"Bigeard E, Jouhet V, Mougin F, Thiessard F, Grabar N.",Stud Health Technol Inform. 2015;210:50-4.,Bigeard E,Stud Health Technol Inform,2015,2015-05-21,,,,"Clinical data recorded in modern EHRs are very rich, although their secondary 
 use research and medical decision may be complicated (eg, missing and incorrect 
 data, data spread over several clinical databases, information available only 
 within unstructured narrative documents). We propose to address the issue 
 related to the processing of narrative documents in order to detect and extract 
 numerical values and to associate them with the corresponding concepts (or 
 themes) and units. We propose to use a CRF supervised categorisation for the 
 detection of segments (themes, numerical sequences and units) and a rules-based 
 system for the association of these segments among them in order to build 
 semantically meaningful sequences. The average results obtained are competitive 
 (0.96 precision, 0.78 recall, and 0.86 F-measure) and we plan to use the system 
 with larger clinical data.
",,,,
26262334,Extraction of Vital Signs from Clinical Notes,"Patterson OV, Jones M, Yao Y, Viernes B, Alba PR, Iwashyna TJ, DuVall SL.",Stud Health Technol Inform. 2015;216:1035.,Patterson OV,Stud Health Technol Inform,2015,2015-08-12,,,,"Assessment of vital signs is an essential part of surveillance of critically ill 
 patients to detect condition changes and clinical deterioration. While most 
 modern electronic medical records allow for vitals to be recorded in a 
 structured format, the frequency and quality of what is electronically stored 
 may differ from how often these measures are actually recorded. We created a 
 tool that extracts blood pressure, heart rate, temperature, respiratory rate, 
 blood oxygen saturation, and pain level from nursing and other clinical notes 
 recorded in the course of inpatient care to supplement structured vital sign 
 data.
",,,,
26262127,Identifying Patients with Depression Using Free-text Clinical Documents,"Zhou L, Baughman AW, Lei VJ, Lai KH, Navathe AS, Chang F, Sordo M, Topaz M, Zhong F, Murrali M, Navathe S, Rocha RA.",Stud Health Technol Inform. 2015;216:629-33.,Zhou L,Stud Health Technol Inform,2015,2015-08-12,,,,"About 1 in 10 adults are reported to exhibit clinical depression and the 
 associated personal, societal, and economic costs are significant. In this 
 study, we applied the MTERMS NLP system and machine learning classification 
 algorithms to identify patients with depression using discharge summaries. 
 Domain experts reviewed both the training and test cases, and classified these 
 cases as depression with a high, intermediate, and low confidence. For 
 depression cases with high confidence, all of the algorithms we tested performed 
 similarly, with MTERMS' knowledge-based decision tree slightly better than the 
 machine learning classifiers, achieving an F-measure of 89.6%. MTERMS also 
 achieved the highest F-measure (70.6%) on intermediate confidence cases. The 
 RIPPER rule learner was the best performing machine learning method, with an 
 F-measure of 70.0%, and a higher precision but lower recall than MTERMS. The 
 proposed NLP-based approach was able to identify a significant portion of the 
 depression cases (about 20%) that were not on the coded diagnosis list.
",,,,
25991104,Synthesizing analytic evidence to refine care pathways,"Liu H, Li X, Yu Y, Mei J, Xie G, Perer A, Wang F, Hu J.",Stud Health Technol Inform. 2015;210:70-4.,Liu H,Stud Health Technol Inform,2015,2015-05-21,,,,"Care pathways play significant roles in delivering evidence-based and 
 coordinated care to patients with specific conditions. In order to put care 
 pathways into practice, clinical institutions always need to adapt them based on 
 local care settings so that the best local practices can be incorporated and 
 used to develop refined pathways. However, it is knowledge-intensive and 
 error-prone to incorporate various analytic insights from local data sets. In 
 order to assist care pathway developers in working effectively and efficiently, 
 we propose to automatically synthesize the analytical evidences derived from 
 multiple analysis methods, and recommend modelling operations accordingly to 
 derive a refined care pathway for a specific patient cohort. We validated our 
 method by adapting a Congestive Heart Failure (CHF) Ambulatory Care Pathway for 
 patients with additional condition of COPD through synthesizing the results of 
 variation analysis and frequent pattern mining against patient records.
",,,,
26262111,A Baseline Patient Model to Support Testing of Medical Cyber-Physical Systems,"Silva LC, Perkusich M, Almeida HO, Perkusich A, Lima MA, Gorgônio KC.",Stud Health Technol Inform. 2015;216:549-53.,Silva LC,Stud Health Technol Inform,2015,2015-08-12,,,,"Medical Cyber-Physical Systems (MCPS) are currently a trending topic of 
 research. The main challenges are related to the integration and 
 interoperability of connected medical devices, patient safety, physiologic 
 closed-loop control, and the verification and validation of these systems. In 
 this paper, we focus on patient safety and MCPS validation. We present a formal 
 patient model to be used in health care systems validation without jeopardizing 
 the patient's health. To determine the basic patient conditions, our model 
 considers the four main vital signs: heart rate, respiratory rate, blood 
 pressure and body temperature. To generate the vital signs we used regression 
 models based on statistical analysis of a clinical database. Our solution should 
 be used as a starting point for a behavioral patient model and adapted to 
 specific clinical scenarios. We present the modeling process of the baseline 
 patient model and show its evaluation. The conception process may be used to 
 build different patient models. The results show the feasibility of the proposed 
 model as an alternative to the immediate need for clinical trials to test these 
 medical systems.
",,,,
26262056,INITIATE: An Intelligent Adaptive Alert Environment,"Jafarpour B, Abidi SR, Ahmad AM, Abidi SS.",Stud Health Technol Inform. 2015;216:285-9.,Jafarpour B,Stud Health Technol Inform,2015,2015-08-12,,,,"Exposure to a large volume of alerts generated by medical Alert Generating 
 Systems (AGS) such as drug-drug interaction softwares or clinical decision 
 support systems over-whelms users and causes alert fatigue in them. Some of 
 alert fatigue effects are ignoring crucial alerts and longer response times. A 
 common approach to avoid alert fatigue is to devise mechanisms in AGS to stop 
 them from generating alerts that are deemed irrelevant. In this paper, we 
 present a novel framework called INITIATE: an INtellIgent adapTIve AlerT 
 Environment to avoid alert fatigue by managing alerts generated by one or more 
 AGS. We have identified and categories the lifecycle of different alerts and 
 have developed alert management logic as per the alerts' lifecycle. Our 
 framework incorporates an ontology that represents the alert management strategy 
 and an alert management engine that executes this strategy. Our alert management 
 framework offers the following features: (1) Adaptability based on users' 
 feedback; (2) Personalization and aggregation of messages; and (3) Connection to 
 Electronic Medical Records by implementing a HL7 Clinical Document Architecture 
 parser.
",,,,
26262042,Building a Semantic Interoperability Framework for Care and Research in Fibromuscular Dysplasia,"Jaulent MC, Assélé-Kama A, Savard S, Giavarini A, Touzé E, Jeunemaître X, Ugon A, Plouin PF, Toubiana L.",Stud Health Technol Inform. 2015;216:217-21.,Jaulent MC,Stud Health Technol Inform,2015,2015-08-12,,,,"Identifying patients with Fibromuscular Dysplasia (FMD) at the international 
 level will have considerable value for understanding the epidemiology, clinical 
 manifestations and susceptible genes in this arterial disease, but also for 
 identifying eligible patients in clinical trials or cohorts. We present a 
 two-step methodology to create a general semantic interoperability framework 
 allowing access and comparison of distributed data over various nations, 
 languages, formats and databases.
 METHODS: The first step is to develop a pivot multidimensional model based on a 
 core dataset to harmonize existing heterogeneous data sources. The second step 
 is to align the model to additional data, semantically related to FMD and 
 collected currently in various registries. We present the results of the first 
 step that has been fully completed with the validation and implementation of the 
 model in a dedicated information system (SIR-FMD). We discuss the current 
 achievements for step 2 and the extensibility of the methodology in the context 
 of other rare diseases.
",,,,
26063258,Textual analysis of collaboration notes of the telemedical heart failure network HerzMobil Tirol,"Modre-Osprian R, Gruber K, Kreiner K, Schreier G, Poelzl G, Kastner P.",Stud Health Technol Inform. 2015;212:57-64.,Modre-Osprian R,Stud Health Technol Inform,2015,2015-06-12,,,,"Management of heart failure is usually multidisciplinary and collaboration 
 between stakeholders in a dedicated HI network like the HerzMobil Tirol can be 
 supported by a mHealth-based telemedicine approach. The aim is to gain insights 
 through textual analysis of collaboration notes that might trigger further 
 developments and improvements of the HI network. A reusable pipeline for textual 
 analysis of unstructured textual notes was implemented using the open source 
 analytics software KNIME. After preprocessing, a keyword analysis was performed 
 resulting in a classification of all notes in predefined categories.
 RESULTS: Medical and organizational issues dominate the communication with 
 health status and therapy aspects as well as clinical treatment, discharge 
 letter and home visits. Beside aspects of data transmission and mobile phone, 
 technological issues are minor topics during the collaboration. It is possible 
 to gain new insights with respect to technology like additional control Apps for 
 mobile phone settings and to the HI network like clinical experts and technical 
 help desk involvement.
",,,,
25991121,Biomarkers in the ontology for general medical science,"Ceusters W, Smith B.",Stud Health Technol Inform. 2015;210:155-9.,Ceusters W,Stud Health Technol Inform,2015,2015-05-21,,,,"A great deal of recent work has been devoted to the topic of biomarkers as aids 
 to diagnosis, prognosis and treatment evaluation. Basing our work on the 
 Ontology for General Medical Science (OGMS) and on the specifications provided 
 by the Institute of Medicine (IOM), we propose definitions for biomarkers of 
 various types. These definitions provide a formal representation of what 
 biomarkers are in a way that allows us to remove certain ambiguities and 
 inconsistencies in the documentation provided by the IOM.
",,,,
26262121,Classification of Contextual Use of Left Ventricular Ejection Fraction Assessments,"Kim Y, Garvin J, Goldstein MK, Meystre SM.",Stud Health Technol Inform. 2015;216:599-603.,Kim Y,Stud Health Technol Inform,2015,2015-08-12,PMC5055832,NIHMS820992,,"Knowledge of the left ventricular ejection fraction is critical for the optimal 
 care of patients with heart failure. When a document contains multiple ejection 
 fraction assessments, accurate classification of their contextual use is 
 necessary to filter out historical findings or recommendations and prioritize 
 the assessments for selection of document level ejection fraction information. 
 We present a natural language processing system that classifies the contextual 
 use of both quantitative and qualitative left ventricular ejection fraction 
 assessments in clinical narrative documents. We created support vector machine 
 classifiers with a variety of features extracted from the target assessment, 
 associated concepts, and document section information. The experimental results 
 showed that our classifiers achieved good performance, reaching 95.6% F1-measure 
 for quantitative assessments and 94.2% F1-measure for qualitative assessments in 
 a five-fold cross-validation evaluation.
",,,,
26262129,Automated Learning of Temporal Expressions,"Redd D, Shaoa Y, Yang J, Divita G, Zeng-Treitler Q.",Stud Health Technol Inform. 2015;216:639-42.,Redd D,Stud Health Technol Inform,2015,2015-08-12,,,,"Clinical notes contain important temporal information that are critical for 
 making clinical diagnosis and treatment as well as for retrospective analyses. 
 Manually created regular expressions are commonly used for the extraction of 
 temporal information; however, this can be a time consuming and brittle 
 approach. We describe a novel algorithm for automatic learning of regular 
 expressions in recognizing temporal expressions. Five classes of temporal 
 expressions are identified. Keywords specific to those classes are used to 
 retrieve snippets of text representing the same keywords in context. Those 
 snippets are used for Regular Expression Discovery Extraction (REDEx). These 
 learned regular expressions are then evaluated using 10-fold cross validation. 
 Precision and recall are very high, above 0.95 for most classes.
",,,,
26152985,Taming Big Data: An Information Extraction Strategy for Large Clinical Text Corpora,"Gundlapalli AV, Divita G, Carter ME, Redd A, Samore MH, Gupta K, Trautner B.",Stud Health Technol Inform. 2015;213:175-8.,Gundlapalli AV,Stud Health Technol Inform,2015,2015-07-09,,,,"Concepts of interest for clinical and research purposes are not uniformly 
 distributed in clinical text available in electronic medical records. The 
 purpose of our study was to identify filtering techniques to select 'high yield' 
 documents for increased efficacy and throughput. Using two large corpora of 
 clinical text, we demonstrate the identification of 'high yield' document sets 
 in two unrelated domains: homelessness and indwelling urinary catheters. For 
 homelessness, the high yield set includes homeless program and social work 
 notes. For urinary catheters, concepts were more prevalent in notes from 
 hospitalized patients; nursing notes accounted for a majority of the high yield 
 set. This filtering will enable customization and refining of information 
 extraction pipelines to facilitate extraction of relevant concepts for clinical 
 decision support and other uses.
",,,,
26262369,Evaluating Methods for Identifying Cancer in Free-Text Pathology Reports Using Various Machine Learning and Data Preprocessing Approaches,"Kasthurirathne SN, Dixon BE, Grannis SJ.",Stud Health Technol Inform. 2015;216:1070.,Kasthurirathne SN,Stud Health Technol Inform,2015,2015-08-12,,,,"Automated detection methods can address delays and incompleteness in cancer case 
 reporting. Existing automated efforts are largely dependent on complex 
 dictionaries and coded data. Using a gold standard of manually reviewed 
 pathology reports, we evaluated the performance of alternative input formats and 
 decision models on a convenience sample of free-text pathology reports. Results 
 showed that the input format significantly impacted performance, and specific 
 algorithms yielded better results for presicion, recall and accuracy. We 
 conclude that our approach is sufficiently accurate for practical purposes and 
 represents a generalized process.
",,,,
26262383,Cohort Discovery Query Optimization via Computable Controlled Vocabulary Versioning,"Ferris TA, Podchiyska T.",Stud Health Technol Inform. 2015;216:1084.,Ferris TA,Stud Health Technol Inform,2015,2015-08-12,,,,"Self-service cohort discovery tools strive to provide intuitive interfaces to 
 large Clinical Data Warehouses that contain extensive historic information. In 
 those tools, controlled vocabulary (e.g., ICD-9-CM, CPT) coded clinical 
 information is often the main search criteria used because of its ubiquity in 
 billing processes. These tools generally require a researcher to pick specific 
 terms from the controlled vocabulary. However, controlled vocabularies evolve 
 over time as medical knowledge changes and can even be replaced with new 
 versions (e.g., ICD-9 to ICD-10). These tools generally only display the current 
 version of the controlled vocabulary. Researchers should not be expected to 
 understand the underlying controlled vocabulary versioning issues. We propose a 
 computable controlled vocabulary versioning system that allows cohort discovery 
 tools to automatically expand queries to account for terminology changes.
",,,,
26262058,Advances In Infection Surveillance and Clinical Decision Support With Fuzzy Sets and Fuzzy Logic,"Koller W, de Bruin JS, Rappelsberger A, Adlassnig KP.",Stud Health Technol Inform. 2015;216:295-9.,Koller W,Stud Health Technol Inform,2015,2015-08-12,,,,"By the use of extended intelligent information technology tools for fully 
 automated healthcare-associated infection (HAI) surveillance, clinicians can be 
 informed and alerted about the emergence of infection-related conditions in 
 their patients. Moni--a system for monitoring nosocomial infections in intensive 
 care units for adult and neonatal patients--employs knowledge bases that were 
 written with extensive use of fuzzy sets and fuzzy logic, allowing the inherent 
 un-sharpness of clinical terms and the inherent uncertainty of clinical 
 conclusions to be a part of Moni's output. Thus, linguistic as well as 
 propositional uncertainty became a part of Moni, which can now report 
 retrospectively on HAIs according to traditional crisp HAI surveillance 
 definitions, as well as support clinical bedside work by more complex crisp and 
 fuzzy alerts and reminders. This improved approach can bridge the gap between 
 classical retrospective surveillance of HAIs and ongoing prospective 
 clinical-decision-oriented HAI support.
",,,,
26262330,Extraction Of Adverse Events From Clinical Documents To Support Decision Making Using Semantic Preprocessing,"Gaebel J, Kolter T, Arlt F, Denecke K.",Stud Health Technol Inform. 2015;216:1030.,Gaebel J,Stud Health Technol Inform,2015,2015-08-12,,,,"Clinical documentation is usually stored in unstructured format in electronic 
 health records (EHR). Processing the information is inconvenient and time 
 consuming and should be enhanced by computer systems. In this paper, a 
 rule-based method is introduced that identifies adverse events documented in the 
 EHR that occurred during treatment. For this purpose, clinical documents are 
 transformed into a semantic structure from which adverse events are extracted. 
 The method is evaluated in a user study with neurosurgeons. In comparison to a 
 bag of word classification using support vector machines, our approach achieved 
 comparably good results of 65% recall and 78% precision. In conclusion, the 
 rule-based method generates promising results that can support physicians' 
 decision making. Because of the structured format the data can be reused for 
 other purposes as well.
",,,,
26262322,Ontology-Driven Semantic Search for Brazilian Portuguese Clinical Notes,"Hasan SA, Zhu X, Liu J, Barra CM, Oliveira L, Farri O.",Stud Health Technol Inform. 2015;216:1022.,Hasan SA,Stud Health Technol Inform,2015,2015-08-12,,,,"The emerging penetration of Health IT in Latin America (especially in Brazil) 
 has exacerbated the ever-increasing amount of Electronic Health Record (EHR) 
 clinical free text documents.This imposes a workflow efficiency challenge on 
 clinicians who need to synthesize such documents during the typically 
 time-constrained patient care. We propose an ontology-driven semantic search 
 framework that effectively supports clinicians' information synthesis at the 
 point of care.
",,,,
26262321,Proposal of Local Automatic Weighing Attribute in CBIR,"Jones Ferreira de Lucena D, Costa Oliviera M, Pamponet Machado A.",Stud Health Technol Inform. 2015;216:1020-1.,Jones Ferreira de Lucena D,Stud Health Technol Inform,2015,2015-08-12,,,,"Lung cancer is the most common malignant lesion and the principal cause of 
 cancer-related death worldwide. This problem encourages researchers to build 
 computer-aided solutions to help diagnose lung cancer. Content-based image 
 retrieval (CBIR) systems are very promising in this context due to a large 
 number of image generated everyday. However, semantic gaps have limited CBIR 
 applicability. This work proposes a new approach to automatically adjust CBIR 
 attribute weights to reflect users' semantic interpretation on retrieval 
 process, minimizing the semantic gap problem and improving retrieval accuracy.
",,,,
26262167,A Process for the Representation of openEHR ADL Archetypes in OWL Ontologies,"Porn AM, Peres LM, Didonet Del Fabro M.",Stud Health Technol Inform. 2015;216:827-31.,Porn AM,Stud Health Technol Inform,2015,2015-08-12,,,,"ADL is a formal language to express archetypes, independent of standards or 
 domain. However, its specification is not precise enough in relation to the 
 specialization and semantic of archetypes, presenting difficulties in 
 implementation and a few available tools. Archetypes may be implemented using 
 other languages such as XML or OWL, increasing integration with Semantic Web 
 tools. Exchanging and transforming data can be better implemented with semantics 
 oriented models, for example using OWL which is a language to define and 
 instantiate Web ontologies defined by W3C. OWL permits defining significant, 
 detailed, precise and consistent distinctions among classes, properties and 
 relations by the user, ensuring the consistency of knowledge than using ADL 
 techniques. This paper presents a process of an openEHR ADL archetypes 
 representation in OWL ontologies. This process consists of ADL archetypes 
 conversion in OWL ontologies and validation of OWL resultant ontologies using 
 the mutation test.
",,,,
26262114,Automatic Selection of Clinical Trials Based on A Semantic Web Approach,"Cuggia M, Campillo-Gimenez B, Bouzille G, Besana P, Jouini W, Dufour JC, Zekri O, Gibaud I, Garde C, Duvauferier R.",Stud Health Technol Inform. 2015;216:564-8.,Cuggia M,Stud Health Technol Inform,2015,2015-08-12,,,,"Recruitment of patients in clinical trials is nowadays preoccupying, as the 
 inclusion rate is particularly low. The main identified factors are the 
 multiplicity of open clinical trials, the high number and complexity of 
 eligibility criteria, and the additional workload that a systematic search of 
 the clinical trials a patient could be enrolled in for a physician. The 
 principal objective of the ASTEC project is to automate the prescreening phase 
 during multidisciplinary meetings (MDM). This paper presents the evaluation of a 
 computerized recruitment support systems (CRSS) based on semantic web approach. 
 The evaluation of the system was based on data collected retrospectively from a 
 6 month period of MDM in Urology and on 4 clinical trials of prostate cancer. 
 The classification performance of the ASTEC system had a precision of 21%, 
 recall of 93%, and an error rate equal to 37%. Missing data was the main issue 
 encountered. The system was designed to be both scalable to other clinical 
 domains and usable during MDM process.
",,,,
26262333,A Frequency-based Strategy of Obtaining Sentences from Clinical Data Repository for Crowdsourcing,"Li D, Rastegar Mojarad M, Li Y, Sohn S, Mehrabi S, Komandur Elayavilli R, Yu Y, Liu H.",Stud Health Technol Inform. 2015;216:1033-4.,Li D,Stud Health Technol Inform,2015,2015-08-12,PMC5859924,NIHMS949906,,"In clinical NLP, one major barrier to adopting crowdsourcing for NLP annotation 
 is the issue of confidentiality for protected health information (PHI) in 
 clinical narratives. In this paper, we investigated the use of a frequency-based 
 approach to extract sentences without PHI. Our approach is based on the 
 assumption that sentences appearing frequently tend to contain no PHI. Both 
 manual and automatic evaluations on 500 sentences out of the 7.9 million 
 sentences of frequencies higher than one show that no PHI can be found among 
 them. The promising results provide potentials of releasing those sentences for 
 obtaining sentence-level NLP annotations via crowdsourcing.
",,,,
26262331,Development and evaluation of task-specific NLP framework in China,"Ge C, Zhang Y, Huang Z, Jia Z, Ju M, Duan H, Li H.",Stud Health Technol Inform. 2015;216:1031.,Ge C,Stud Health Technol Inform,2015,2015-08-12,,,,"Natural language processing (NLP) has been designed to convert narrative text 
 into structured data. Although some general NLP architectures have been 
 developed, a task-specific NLP framework to facilitate the effective use of data 
 is still a challenge in lexical resource limited regions, such as China. The 
 purpose of this study is to design and develop a task-specific NLP framework to 
 extract targeted information from particular documents by adopting dedicated 
 algorithms on current limited lexical resources. In this framework, a shared and 
 evolving ontology mechanism was designed. The result has shown that such a free 
 text driven platform will accelerate the NLP technology acceptance in China.
",,,,
26262036,Toward User-Centered Patient Safety Event Reporting System: A Trial of Text Prediction in Clinical Data Entry,"Hua L, Gong Y.",Stud Health Technol Inform. 2015;216:188-92.,Hua L,Stud Health Technol Inform,2015,2015-08-12,,,,"As a primary source for learning from lessons, patient safety event reporting 
 systems have been widely adopted. Nevertheless, underreporting and low quality 
 of reports pervade the system. To address these issues, the study proposed two 
 text prediction functions as data entry aids to system users. With 52 subjects, 
 a two-group randomized experiment was conducted to quantify the impacts in terms 
 of the reporting efficiency, quality, and usability attitudes. Consequentially, 
 on structured data entry, the results were an overall 13.0% time reduction and 
 3.9% increase of response accuracy with the functions; on unstructured data 
 entry, there was an overall 70.5% increase in the text generation rate, a 34.1% 
 increase in the reporting completeness score, and a 14.5% reduction on the 
 amount of text fields ignored by subjects. Subjects' usability attitudes were 
 slightly improved with the proposed functions according to the questionnaire 
 results.
",,,,
26262400,Evaluating a Hierarchical Clinical Event Linkage Model for Clinic-Specific Databases,"Liu J, Truong T.",Stud Health Technol Inform. 2015;216:1101.,Liu J,Stud Health Technol Inform,2015,2015-08-12,,,,"A relational database model is presented that stores the hierarchical linkages 
 between clinical events with qualifier codes, such that the explicit contextual 
 meaning of an event's attributes is preserved upon retrieval. A retrospective 
 analysis of 302 forms built upon the model showed that 91% of 17,899 data 
 elements requested by clinicians and researchers from 19 clinics were 
 successfully represented, but that 62% were never used more than once. These 
 results reinforce the specificity of clinic-specific databases and the need for 
 unambiguous, explicitly-stored clinical data.
",,,,
26262356,Integrated Database And Knowledge Base For Genomic Prospective Cohort Study In Tohoku Medical Megabank Toward Personalized Prevention And Medicine,"Ogishima S, Takai T, Shimokawa K, Nagaie S, Tanaka H, Nakaya J.",Stud Health Technol Inform. 2015;216:1057.,Ogishima S,Stud Health Technol Inform,2015,2015-08-12,,,,"The Tohoku Medical Megabank project is a national project to revitalization of 
 the disaster area in the Tohoku region by the Great East Japan Earthquake, and 
 have conducted large-scale prospective genome-cohort study. Along with 
 prospective genome-cohort study, we have developed integrated database and 
 knowledge base which will be key database for realizing personalized prevention 
 and medicine.
",,,,
26262184,Validation for Accuracy of Cancer Diagnosis in Electronic Medical Records Using a Text Mining Method,"Lee Y, Shin SY, Ahn SM, Lee JH, Kim WS.",Stud Health Technol Inform. 2015;216:882.,Lee Y,Stud Health Technol Inform,2015,2015-08-12,,,,"To validate the accuracy of data in electronic medical record, we compared 
 cancer diagnosis and key words in pathologic reports of cancer patients in a 
 tertiary hospital, using text mining method. We investigated in fourteen kinds 
 of cancers that had highest incidence rates in Korea. Approximately two-third 
 (71.0%) of total patients had right match in cancer diagnosis with pathologic 
 report. The ratio of concurrence was the highest (86.3%) in thyroid cancer 
 patients, however, the ratio was the lowest (49.9%) in liver cancer patients. To 
 prevent the errors in data input, a systematic alarm and feedback to clinicians 
 should be required.
",,,,
25991133,Normalized medical information visualization,"Sánchez-de-Madariaga R, Muñoz A, Somolinos R, Castro A, Velázquez I, Moreno O, García-Pacheco JL, Pascual M, Salvador CH.",Stud Health Technol Inform. 2015;210:215-7.,Sánchez-de-Madariaga R,Stud Health Technol Inform,2015,2015-05-21,,,,"A new mark-up programming language is introduced in order to facilitate and 
 improve the visualization of ISO/EN 13606 dual model-based normalized medical 
 information. This is the first time that visualization of normalized medical 
 information is addressed and the programming language is intended to be used by 
 medical non-IT professionals.
",,,,
25991244,Integrating medical and research information: a big data approach,"Tilve Álvarez CM, Ayora Pais A, Ruíz Romero C, Llamas Gómez D, Carrajo García L, Blanco García FJ, Vázquez González G.",Stud Health Technol Inform. 2015;210:707-11.,Tilve Álvarez CM,Stud Health Technol Inform,2015,2015-05-21,,,,"Most of the information collected in different fields by Instituto de 
 Investigación Biomédica de A Coruña (INIBIC) is classified as unstructured due 
 to its high volume and heterogeneity. This situation, linked to the recent 
 requirement of integrating it to the medical information, makes it necessary to 
 implant specific architectures to collect and organize it before it can be 
 analysed. The purpose of this article is to present the Hadoop framework as a 
 solution to the problem of integrating research information in the Business 
 Intelligence field. This framework can collect, explore, process and structure 
 the aforementioned information, which allow us to develop an equivalent function 
 to a data mart in an Intelligence Business system.
",,,,
26262124,Classifying the Indication for Colonoscopy Procedures: A Comparison of NLP Approaches in a Diverse National Healthcare System,"Patterson OV, Forbush TB, Saini SD, Moser SE, DuVall SL.",Stud Health Technol Inform. 2015;216:614-8.,Patterson OV,Stud Health Technol Inform,2015,2015-08-12,,,,"In order to measure the level of utilization of colonoscopy procedures, 
 identifying the primary indication for the procedure is required. Colonoscopies 
 may be utilized not only for screening, but also for diagnostic or therapeutic 
 purposes. To determine whether a colonoscopy was performed for screening, we 
 created a natural language processing system to identify colonoscopy reports in 
 the electronic medical record system and extract indications for the procedure. 
 A rule-based model and three machine-learning models were created using 2,000 
 manually annotated clinical notes of patients cared for in the Department of 
 Veterans Affairs. Performance of the models was measured and compared. Analysis 
 of the models on a test set of 1,000 documents indicates that the rule-based 
 system performance stays fairly constant as evaluated on training and testing 
 sets. However, the machine learning model without feature selection showed 
 significant decrease in performance. Therefore, rule-based classification system 
 appears to be more robust than a machine-learning system in cases when no 
 feature selection is performed.
",,,,
26262126,Named Entity Recognition in Chinese Clinical Text Using Deep Neural Network,"Wu Y, Jiang M, Lei J, Xu H.",Stud Health Technol Inform. 2015;216:624-8.,Wu Y,Stud Health Technol Inform,2015,2015-08-12,PMC4624324,NIHMS708181,,"Rapid growth in electronic health records (EHRs) use has led to an unprecedented 
 expansion of available clinical data in electronic formats. However, much of the 
 important healthcare information is locked in the narrative documents. Therefore 
 Natural Language Processing (NLP) technologies, e.g., Named Entity Recognition 
 that identifies boundaries and types of entities, has been extensively studied 
 to unlock important clinical information in free text. In this study, we 
 investigated a novel deep learning method to recognize clinical entities in 
 Chinese clinical documents using the minimal feature engineering approach. We 
 developed a deep neural network (DNN) to generate word embeddings from a large 
 unlabeled corpus through unsupervised learning and another DNN for the NER task. 
 The experiment results showed that the DNN with word embeddings trained from the 
 large unlabeled corpus outperformed the state-of-the-art CRF's model in the 
 minimal feature engineering setting, achieving the highest F1-score of 0.9280. 
 Further analysis showed that word embeddings derived through unsupervised 
 learning from large unlabeled corpus remarkably improved the DNN with randomized 
 embedding, denoting the usefulness of unsupervised feature learning.
",,,,
25991115,Multidisciplinary Modelling of Symptoms and Signs with Archetypes and SNOMED-CT for Clinical Decision Support,"Marco-Ruiz L, Maldonado JA, Karlsen R, Bellika JG.",Stud Health Technol Inform. 2015;210:125-9.,Marco-Ruiz L,Stud Health Technol Inform,2015,2015-05-21,,,,"Clinical Decision Support Systems (CDSS) help to improve health care and reduce 
 costs. However, the lack of knowledge management and modelling hampers their 
 maintenance and reuse. Current EHR standards and terminologies can allow the 
 semantic representation of the data and knowledge of CDSS systems boosting their 
 interoperability, reuse and maintenance. This paper presents the modelling 
 process of respiratory conditions' symptoms and signs by a multidisciplinary 
 team of clinicians and information architects with the help of openEHR, SNOMED 
 and clinical information modelling tools for a CDSS. The information model of 
 the CDSS was defined by means of an archetype and the knowledge model was 
 implemented by means of an SNOMED-CT based ontology.
",,,,
26262183,Restructuring an EHR system and the Medical Markup Language (MML) standard to improve interoperability by archetype technology,"Kobayashi S, Kume N, Yoshihara H.",Stud Health Technol Inform. 2015;216:881.,Kobayashi S,Stud Health Technol Inform,2015,2015-08-12,,,,"In 2001, we developed an EHR system for regional healthcare information 
 inter-exchange and to provide individual patient data to patients. This system 
 was adopted in three regions in Japan. We also developed a Medical Markup 
 Language (MML) standard for inter- and intra-hospital communications. The system 
 was built on a legacy platform, however, and had not been appropriately 
 maintained or updated to meet clinical requirements. To improve future 
 maintenance costs, we reconstructed the EHR system using archetype technology on 
 the Ruby on Rails platform, and generated MML equivalent forms from archetypes. 
 The system was deployed as a cloud-based system for preliminary use as a 
 regional EHR. The system now has the capability to catch up with new 
 requirements, maintaining semantic interoperability with archetype technology. 
 It is also more flexible than the legacy EHR system.
",,,,
26063255,Development of text mining based classification of written communication within a telemedical collaborative network,"Gruber K, Modre-Osprian R, Kreiner K, Kastner P, Schreier G.",Stud Health Technol Inform. 2015;212:35-42.,Gruber K,Stud Health Technol Inform,2015,2015-06-12,,,,"Chronic diseases like Heart Failure are widespread in the ageing population. 
 Affected patients can be treated with the aid of a disease management program, 
 including a telemedical collaborative network. Evaluation of a currently used 
 system has shown that the information of the textual communication is of pivotal 
 importance for the collaboration in the network. Thus, the challenge is to make 
 this unstructured information useable, potentially leading to a better 
 understanding of the collaboration so as to optimize the processes. This paper 
 presents the setup of an analysis pipeline for processing textual information 
 automatically, and, how this pipeline can be utilized to train a model that is 
 able to automatically classify the written messages into a set of meaningful 
 task and status categories.
",,,,
26262337,Rule-based Cervical Spine Defect Classification Using Medical Narratives,"Deng Y, Groll MJ, Denecke K.",Stud Health Technol Inform. 2015;216:1038.,Deng Y,Stud Health Technol Inform,2015,2015-08-12,,,,"Classifying the defects occurring at the cervical spine provides the basis for 
 surgical treatment planning and therapy recommendation. This process requires 
 evidence from patient records. Further, the degree of a defect needs to be 
 encoded in a standardized from to facilitate data exchange and multimodal 
 interoperability. In this paper, a concept for automatic defect classification 
 based on information extracted from textual data of patient records is 
 presented. In a retrospective study, the classifier is applied to clinical 
 documents and the classification results are evaluated.
",,,,
25991161,Using a snowflake data model and autocompletion to support diagnostic coding in acute care hospitals,"Noussa-Yao J, Boussadi A, Richard M, Heudes D, Degoulet P.",Stud Health Technol Inform. 2015;210:334-8.,Noussa-Yao J,Stud Health Technol Inform,2015,2015-05-21,,,,"PURPOSE: Efficient and adequate coding is essential for all hospitals to 
 optimize funding, follow activity, and perform epidemiological studies.
 OBJECTIVE: We propose an autocompletion method for optimizing diagnostic coding 
 in acute care hospitals.
 METHODS: Using a terminology snowflake model integrating SNOMED 3.5 and ICD-10 
 codes, autocompletion algorithms generate a list of diagnostic expressions from 
 partial input concepts.
 RESULTS: A general autocompletion component has been developed and tested on a 
 set of inpatient summary reports. Concepts expressed as strings of three or four 
 characters return a noisy list of diagnostic labels or codes. Concepts expressed 
 as groups of strings return lists that are semantically close to the labels 
 present in hospital reports. The most pertinent information lies in the length 
 of the expressions entered.
 CONCLUSION: Autocompletion can be a complementary tool to existing coding 
 support systems.
",,,,
26261998,Validating the Access to an Electronic Health Record: Classification and Content Analysis of Access Logs,"Alassia LN, Benítez S, Luna DR, Bernaldo de Quiros FG.",Stud Health Technol Inform. 2015;216:3-6.,Alassia LN,Stud Health Technol Inform,2015,2015-08-12,,,,"Electronic Health Records (EHRs) have made patient information widely available, 
 allowing health professionals to provide better care. However, information 
 confidentiality is an issue that continually needs to be taken into account. The 
 objective of this study is to describe the implementation of rule-based access 
 permissions to an EHR system. The rules that were implemented were based on a 
 qualitative study. Every time users did not meet the specified requirements, 
 they had to justify access through a pop up window with predetermined options, 
 including a free text option (""other justification""). A secondary analysis of a 
 deidentified database was performed. From a total of 20,540,708 hits on the 
 electronic medical record database, 85% of accesses to the EHR system did not 
 require justification. Content analysis of the ""Other Justification"" option 
 allowed the identification of new types of access. At the time to justify, 
 however, users may choose the faster or less clicks option to access to EHR, 
 associating the justification of access to the EHR as a barrier.
",,,,
25991135,Enrich classifications in psychiatry with textual data: an ontology for psychiatry including social concepts,"Richard M, Aimé X, Krebs MO, Charlet J.",Stud Health Technol Inform. 2015;210:221-3.,Richard M,Stud Health Technol Inform,2015,2015-05-21,,,,"We propose a modular approach to develop an ontology of psychiatry, ONTOPSYCHIA, 
 based on Patient Discharges Summaries (PDS) and divided into three modules (i.e. 
 social, mental disorders and treatments). We decided to take into account the 
 social aspects of the patient life described in PDS to consider information such 
 as family history, social environment or education.
",,,,
26262358,Are we talking about the same patient?,"Roussi K, Soussa V, Dunn Lopez K, Balasubramanian A, Keenan GM, Burton M, Bahroos N, DiEugenio B, Boyd AD.",Stud Health Technol Inform. 2015;216:1059.,Roussi K,Stud Health Technol Inform,2015,2015-08-12,,,,"The objective of this study is to determine the degree of similarities between 
 the clinical terms used by physicians and nurses in their documentation.
",,,,
26262065,"An Intelligent Ecosystem for Providing Support in Prehospital Trauma Care in Cuenca, Ecuador","Timbi-Sisalima C, Rodas EB, Salamea JC, Sacoto H, Monje-Ortega D, Robles-Bykbaev V.",Stud Health Technol Inform. 2015;216:329-32.,Timbi-Sisalima C,Stud Health Technol Inform,2015,2015-08-12,,,,"According to facts given by the World Health Organization, one in ten deaths 
 worldwide is due to an external cause of injury. In the field of pre-hospital 
 trauma care, adequate and timely treatment in the golden period can impact the 
 survival of a patient. The aim of this paper is to show the design of a complete 
 ecosystem proposed to support the evaluation and treatment of trauma victims, 
 using standard tools and vocabulary such as OpenEHR, as well as mobile systems 
 and expert systems to support decision-making. Preliminary results of the 
 developed applications are presented, as well as trauma-related data from the 
 city of Cuenca, Ecuador.
",,,,
26262397,A Standards-based Semantic Metadata Repository to Support EHR-driven Phenotype Authoring and Execution,"Jiang G, Solbrig HR, Kiefer R, Rasmussen LV, Mo H, Speltz P, Thompson WK, Denny JC, Chute CG, Pathak J.",Stud Health Technol Inform. 2015;216:1098.,Jiang G,Stud Health Technol Inform,2015,2015-08-12,PMC4898771,NIHMS791419,,"This study describes our efforts in developing a standards-based semantic 
 metadata repository for supporting electronic health record (EHR)-driven 
 phenotype authoring and execution. Our system comprises three layers: 1) a 
 semantic data element repository layer; 2) a semantic services layer; and 3) a 
 phenotype application layer. In a prototype implementation, we developed the 
 repository and services through integrating the data elements from both Quality 
 Data Model (QDM) and HL7 Fast Healthcare Inteoroperability Resources (FHIR) 
 models. We discuss the modeling challenges and the potential of our system to 
 support EHR phenotype authoring and execution applications.
",,,,
25991243,Semantic integration of medication data into the EHOP Clinical Data Warehouse,"Delamarre D, Bouzille G, Dalleau K, Courtel D, Cuggia M.",Stud Health Technol Inform. 2015;210:702-6.,Delamarre D,Stud Health Technol Inform,2015,2015-05-21,,,,"Reusing medication data is crucial for many medical research domains. Semantic 
 integration of such data in clinical data warehouse (CDW) is quite challenging. 
 Our objective was to develop a reliable and scalable method for integrating 
 prescription data into EHOP (a French CDW).
 METHOD: PN13/PHAST was used as the semantic interoperability standard during the 
 ETL process, and to store the prescriptions as documents in the CDW. Theriaque 
 was used as a drug knowledge database (DKDB), to annotate the prescription 
 dataset with the finest granularity, and to provide semantic capabilities to the 
 EHOP query workbench.
 RESULTS: the system was evaluated on a clinical data set. Depending on the use 
 case, the precision ranged from 52% to 100%, Recall was always 100%.
 CONCLUSION: interoperability standards and DKDB, document approach, and the 
 finest granularity approach are the key factors for successful drug data 
 integration in CDW.
",,,,
25991117,"Design, development and first validation of a transcoding system from ICD-9-CM to ICD-10 in the IT.DRG Italian project","Della Mea V, Vuattolo O, Frattura L, Munari F, Verdini E, Zanier L, Arcangeli L, Carle F.",Stud Health Technol Inform. 2015;210:135-9.,Della Mea V,Stud Health Technol Inform,2015,2015-05-21,,,,"In Italy, ICD-9-CM is currently used for coding health conditions at hospital 
 discharge, but ICD-10 is being introduced thanks to the IT-DRG Project. In this 
 project, one needed component is a set of transcoding rules and associated tools 
 for easing coders work in the transition. The present paper illustrates design 
 and development of those transcoding rules, and their preliminary testing on a 
 subset of Italian hospital discharge data.
",,,,
26262108,Recruit--An Ontology Based Information Retrieval System for Clinical Trials Recruitment,"Patrão DF, Oleynik M, Massicano F, Morassi Sasso A.",Stud Health Technol Inform. 2015;216:534-8.,Patrão DF,Stud Health Technol Inform,2015,2015-08-12,,,,"Clinical trials are studies designed to assess whether a new intervention is 
 better than the current alternatives. However, most of them fail to recruit 
 participants on schedule. It is hard to use Electronic Health Record (EHR) data 
 to find eligible patients, therefore studies rely on manual assessment, which is 
 time consuming, inefficient and requires specialized training. In this work we 
 describe the design and development of an information retrieval system with the 
 objective of finding eligible patients for cancer trials. The Recruit system has 
 been in use at A. C. Camargo Cancer Center since August/2014 and contains data 
 from more than 500,000 patients and 9 databases. It uses ontologies to integrate 
 data from several sources and represent medical knowledge, which helps enhance 
 results. One can search both in structured data and inside free text reports. 
 The preliminary quality assessments shows excellent recall rates. Recruit proved 
 to be an useful tool for researchers and its modular design could be applied to 
 other clinical conditions and hospitals.
",,,,
26063253,Standardized mappings--a framework to combine different semantic mappers into a standardized web-API,"Neuhaus P, Doods J, Dugas M.",Stud Health Technol Inform. 2015;212:23-6.,Neuhaus P,Stud Health Technol Inform,2015,2015-06-12,,,,"BACKGROUND: Automatic coding of medical terms is an important, but highly 
 complicated and laborious task.
 OBJECTIVES: To compare and evaluate different strategies a framework with a 
 standardized web-interface was created. Two UMLS mapping strategies are compared 
 to demonstrate the interface.
 METHODS: The framework is a Java Spring application running on a Tomcat 
 application server. It accepts different parameters and returns results in JSON 
 format. To demonstrate the framework, a list of medical data items was mapped by 
 two different methods: similarity search in a large table of terminology codes 
 versus search in a manually curated repository. These mappings were reviewed by 
 a specialist.
 RESULTS: The evaluation shows that the framework is flexible (due to 
 standardized interfaces like HTTP and JSON), performant and reliable. Accuracy 
 of automatically assigned codes is limited (up to 40%).
 CONCLUSION: Combining different semantic mappers into a standardized Web-API is 
 feasible. This framework can be easily enhanced due to its modular design.
",,,,
26262055,Understanding Deviations from Clinical Practice Guidelines in Adult Soft Tissue Sarcoma,"Goldbraich E, Waks Z, Farkash A, Monti M, Torresani M, Bertulli R, Casali PG, Carmeli B.",Stud Health Technol Inform. 2015;216:280-4.,Goldbraich E,Stud Health Technol Inform,2015,2015-08-12,,,,"In recent years we have witnessed the increasing adoption of clinical practice 
 guidelines (CPGs) as decision support tools that guide medical treatment. As 
 CPGs gain popularity, it has become evident that physicians frequently deviate 
 from CPG recommendations, both erroneously and due to sound medical rationale. 
 In this study we developed a methodology to computationally identify these 
 deviation cases and understand their movitation. This was achieved using an 
 integrated approach consisting of natural language processing, data modeling, 
 and comparison methods to characterize deviations from CPG recommendations for 
 1431 adult soft tissue sarcoma patients. The results show that 48.9% of patient 
 treatment programs deviate from CPG recommendations, with the largest deviation 
 type being overtreatment, followed by differences in drug treatments. 
 Interestingly, we identified over a dozen potential reasons for these 
 deviations, with those directly related to the patients' cancer status being 
 most abundant. These findings can be used to modify CPGs, increase adherence to 
 CPG recommendations, reduce treatment cost, and potentially impact sarcoma care. 
 Our approach can be applied to additional diseases that are subject to high 
 deviation levels from CPGs.
",,,,
26262419,Clinical application of the integrated multicenter discharge summary database,"Takahiro S, Shunsuke D, Yutaka H, Masayuki H, Yasushi M, Gen S, Mitsuhiro T, Shusaku T, Hideto Y, Katsuhiko T.",Stud Health Technol Inform. 2015;216:1120.,Takahiro S,Stud Health Technol Inform,2015,2015-08-12,,,,"We performed the multi-year project to collect discharge summary from multiple 
 hospitals and made the big text database to build a common document vector 
 space, and developed various applications. We extracted 243,907 discharge 
 summaries from seven hospitals. There was a difference in term structure and 
 number of terms between the hospitals, however the differences by disease were 
 similar. We built the vector space using TF-IDF method. We performed a 
 cross-match analysis of DPC selection among seven hospitals. About 80% cases 
 were correctly matched. The use of model data of other hospitals reduced 
 selection rate to around 10%; however, integrated model data from all hospitals 
 restored the selection rate.
",,,,
26262113,Normalization of Phenotypic Data from a Clinical Data Warehouse: Case Study of Heterogeneous Blood Type Data with Surprising Results,Cimino JJ.,Stud Health Technol Inform. 2015;216:559-63.,Cimino JJ,Stud Health Technol Inform,2015,2015-08-12,PMC5502805,NIHMS811334,,"Clinical data warehouses often contain analogous data from disparate sources, 
 resulting in heterogeneous formats and semantics. We have developed an approach 
 that attempts to represent such phenotypic data in its most atomic form to 
 facilitate aggregation. We illustrate this approach with human blood antigen 
 typing (ABO-Rh) data drawn from the National Institutes of Health's Biomedical 
 Translational Research Information System (BTRIS). In applying the method to 
 actual patient data, we discovered a 2% incidence of changed blood types. We 
 believe our approach can be applied to any institution's data to obtain 
 comparable patient phenotypes. The actual discrepant blood type data will form 
 the basis for a future study of the reasons for blood typing variation.
",,,,
26262143,Automated Detection of Postoperative Surgical Site Infections Using Supervised Methods with Electronic Health Record Data,"Hu Z, Simon GJ, Arsoniadis EG, Wang Y, Kwaan MR, Melton GB.",Stud Health Technol Inform. 2015;216:706-10.,Hu Z,Stud Health Technol Inform,2015,2015-08-12,PMC5648590,NIHMS888349,,"Comment in
     AORN J. 2018 Jun;107(6):776-781.
",,,,
26210422,Incidence Rate of Prediabetes: An Analysis of New Zealand Primary Care Data,"Gu Y, Warren J, Kennelly J, Walker N, Harwood M.",Stud Health Technol Inform. 2015;214:81-6.,Gu Y,Stud Health Technol Inform,2015,2015-07-27,,,,"INTRODUCTION: Diabetes is a common disease affecting 9% of the adult population 
 worldwide. People with impaired glucose tolerance ('prediabetes') are at high 
 risk of progressing to type 2 diabetes.
 METHODS: To understand prediabetes incidence rate, we analysed the electronic 
 medical records (EMR) from 14 New Zealand general practices regarding patients 
 aged ≥20 years and enrolled with the practices between 2009 and 2012. 
 Prediabetes incidence rate was calculated by the number of patients with an 
 initial HbA1c of 41-49 mmol/mol in 2011 among those who had not been diagnosed 
 or treated for diabetes.
 RESULTS: 28,192 adults were included in the analysis, 11% of this cohort had 
 diabetes before 2011. 1,276 new cases of prediabetes were identified in 2011, 
 giving a 5.0% incidence rate. The relative risk (RR) for prediabetes was 
 increased for the Māori and Pacific groups versus non-Māori/non-Pacific people, 
 with RR of 1.97 in the younger age groups (&lt;50 years) and RR of 1.42 in the 
 50+ group. The RR for having uncontrolled HbA1c (highest HbA1c in 2011 ≥65 
 mmol/mol) among the whole adult population was also increased for the Māori and 
 Pacific groups versus non-Māori/non-Pacific people (RR=3.35 among those &lt;50 
 years, RR=4.35 in the 50+ group).
 DISCUSSION AND CONCLUSION: EMR analysis identified an alarming incidence rate of 
 prediabetes, especially among Māori and Pacific groups, highlighting the need to 
 better prevent and manage the condition.
",,,,
25991168,Using EHRs for Heart Failure Therapy Recommendation Using Multidimensional Patient Similarity Analytics,"Panahiazar M, Taslimitehrani V, Pereira NL, Pathak J.",Stud Health Technol Inform. 2015;210:369-73.,Panahiazar M,Stud Health Technol Inform,2015,2015-05-21,PMC4899831,NIHMS791412,,"Electronic Health Records (EHRs) contain a wealth of information about an 
 individual patient's diagnosis, treatment and health outcomes. This information 
 can be leveraged effectively to identify patients who are similar to each for 
 disease diagnosis and prognosis. In recent years, several machine learning 
 methods have been proposed to assessing patient similarity, although the 
 techniques have primarily focused on the use of patient diagnoses data from EHRs 
 for the learning task. In this study, we develop a multidimensional patient 
 similarity assessment technique that leverages multiple types of information 
 from the EHR and predicts a medication plan for each new patient based on prior 
 knowledge and data from similar patients. In our algorithm, patients have been 
 clustered into different groups using a hierarchical clustering approach and 
 subsequently have been assigned a medication plan based on the similarity index 
 to the overall patient population. We evaluated the performance of our approach 
 on a cohort of heart failure patients (N=1386) identified from EHR data at Mayo 
 Clinic and achieved an AUC of 0.74. Our results suggest that it is feasible to 
 harness population-based information from EHRs for an individual 
 patient-specific assessment.
",,,,
26262228,A Development of Automatic Audit System for Written Informed Consent using Machine Learning,"Yamada H, Takemura T, Asai T, Okamoto K, Kuroda T, Kuwata S.",Stud Health Technol Inform. 2015;216:926.,Yamada H,Stud Health Technol Inform,2015,2015-08-12,,,,"In Japan, most of all the university and advanced hospitals have implemented 
 both electronic order entry systems and electronic charting. In addition, all 
 medical records are subjected to inspector audit for quality assurance. The 
 record of informed consent (IC) is very important as this provides evidence of 
 consent from the patient or patient's family and health care provider. 
 Therefore, we developed an automatic audit system for a hospital information 
 system (HIS) that is able to evaluate IC automatically using machine learning.
",,,,
26063262,Web-based multi-site feasibility questionnaire tool,"Soto-Rey I, Trinczek B, Amo JI, Bauselas J, Dugas M, Fritz F.",Stud Health Technol Inform. 2015;212:88-93.,Soto-Rey I,Stud Health Technol Inform,2015,2015-06-12,,,,"The design of clinical trial (CT) study protocols, currently supported by 
 clinicians, is often a slow and cumbersome process. The Electronic Health 
 Records for Clinical Research (EHR4CR) project supports the design of study 
 protocols through a multi-site patient count cohort system. However, there is 
 still a need to improve the process step in which the clinicians are involved. 
 This research aims to enhance the EHR4CR platform with a tool to support the 
 contact of CT sponsors with clinical investigators to obtain their input 
 regarding feasibility data for the CT protocol design. From a list of 
 requirements, a technical architecture that responds to the needs of feasibility 
 assessments was modelled. With this architecture as a basis, a system that 
 allows users to generate, send, fill out and visualise results of feasibility 
 questionnaires across clinical sites was developed and integrated within the 
 EHR4CR platform. The resulting system improves the current methods by providing 
 direct contact to clinical investigators, facilitating the creation and answer 
 of feasibility questionnaires for CTs.
",,,,
26063254,Standardized data sharing in a paediatric oncology research network--a proof-of-concept study,"Hochedlinger N, Nitzlnader M, Falgenhauer M, Welte S, Hayn D, Koumakis L, Potamias G, Tsiknakis M, Saraceno D, Rinaldi E, Ladenstein R, Schreier G.",Stud Health Technol Inform. 2015;212:27-34.,Hochedlinger N,Stud Health Technol Inform,2015,2015-06-12,,,,"Data that has been collected in the course of clinical trials are potentially 
 valuable for additional scientific research questions in so called secondary use 
 scenarios. This is of particular importance in rare disease areas like 
 paediatric oncology. If data from several research projects need to be 
 connected, so called Core Datasets can be used to define which information needs 
 to be extracted from every involved source system. In this work, the utility of 
 the Clinical Data Interchange Standards Consortium (CDISC) Operational Data 
 Model (ODM) as a format for Core Datasets was evaluated and a web tool was 
 developed which received Source ODM XML files and--via Extensible Stylesheet 
 Language Transformation (XSLT)--generated standardized Core Dataset ODM XML 
 files. Using this tool, data from different source systems were extracted and 
 pooled for joined analysis in a proof-of-concept study, facilitating both, basic 
 syntactic and semantic interoperability.
",,,,
25991120,Clinical Decision Support using a Terminology Server to improve Patient Safety,"Garcia-Jimenez A, Moreno-Conde A, Martínez-García A, Marín-León I, Medrano-Ortega FJ, Parra-Calderón CL.",Stud Health Technol Inform. 2015;210:150-4.,Garcia-Jimenez A,Stud Health Technol Inform,2015,2015-05-21,,,,"Clinical Decision Support Systems (CDSS) are software applications that support 
 clinicians in making healthcare decisions providing relevant information for 
 individual patients about their specific conditions. The lack of integration 
 between CDSS and Electronic Health Record (EHR) has been identified as a 
 significant barrier to CDSS development and adoption. Andalusia Healthcare 
 Public System (AHPS) provides an interoperable health information infrastructure 
 based on a Service Oriented Architecture (SOA) that eases CDSS implementation. 
 This paper details the deployment of a CDSS jointly with the deployment of a 
 Terminology Server (TS) within the AHPS infrastructure. It also explains a case 
 study about the application of decision support to thromboembolism patients and 
 its potential impact on improving patient safety. We will apply the inSPECt tool 
 proposal to evaluate the appropriateness of alerts in this scenario.
",,,,
25991114,Improvement of Diagnosis Coding by Analysing EHR and Using Rule Engine: Application to the Chronic Kidney Disease,"Lardon J, Asfari H, Souvignet J, Trombert-Paviot B, Bousquet C.",Stud Health Technol Inform. 2015;210:120-4.,Lardon J,Stud Health Technol Inform,2015,2015-05-21,,,,"Coding medical diagnosis in case mix databases is a time-consuming task as every 
 information available in patient records has to be taken into account. We 
 developed rules based on EHR data with the Drools rules engine in order to 
 support diagnosis coding of chronic kidney disease (CKD) in our hospital. 520 
 patients had a GFR &lt; 60 ml/min as estimated by the Cockroft-Gault formula and 
 corresponded to 429 case mix database entries. We compared stays in which the 
 patient was older than 12 and younger than 65 or 80 at the time of the stay. We 
 concluded that our rules engine implementation may improve coding of CKD for 
 45.6% of patients with a GFR &lt; 60 ml/min and younger than 65. When patients 
 are older than 65 our rule engine may be less useful for suggesting missing 
 codes of CKD because the estimation of GFR by the Cockroft-Gault formula becomes 
 less reliable as patients get older.
",,,,
26262142,"Development and preliminary validation of a dynamic, patient-tailored method to detect abnormal laboratory test results","Fraccaro P, Brown B, Prosperi M, Sperrin M, Buchan I, Peek N.",Stud Health Technol Inform. 2015;216:701-5.,Fraccaro P,Stud Health Technol Inform,2015,2015-08-12,,,,"Laboratory test results in primary care are flagged as 'abnormal' when they fall 
 outside a population-based Reference Interval (RI), typically generating many 
 alerts with a low specificity. In order to decrease alert frequency while 
 retaining clinical relevance, we developed a method to assess dynamic, 
 patient-tailored RIs based on mixed-effects linear regression models. Potassium 
 test results from primary care were used as proof-of-concept test bed. Clinical 
 relevance was assessed via a survey administered to general practitioners (GPs). 
 Overall, the dynamic, patient-tailored method and the combination of both 
 methods flagged 20% and 36% fewer values as abnormal than the population-based 
 method. Nineteen out of 43 invited GPs (44%) completed the survey. The 
 population-based method yielded a better sensitivity than the patient-tailored 
 and the combined methods (0.51 vs 0.41 and 0.38, respectively) but a lower PPV 
 (0.66 vs 0.67 and 0.76, respectively). We conclude that a combination of 
 population-based and patient-tailored RIs can improve the detection of abnormal 
 laboratory results. We suggest that lab values outside both RIs be flagged with 
 high priority in clinical practice.
",,,,
25991118,Re-use of SNOMED CT subset in development of the Danish national standard for home care nursing problems,"Højen AR, Gøeg KR, Elberg PB.",Stud Health Technol Inform. 2015;210:140-4.,Højen AR,Stud Health Technol Inform,2015,2015-05-21,,,,"SNOMED CT was chosen as reference terminology for standardisation of homecare 
 nursing documentation to make reporting comparable across the 98 Danish 
 municipalities. The method outlined in this paper for developing a Danish 
 national homecare nursing SNOMED CT subsets is a pragmatic approach to build new 
 SNOMED CT subsets drawing on existing and available SNOMED CT subsets. Combining 
 this approach with awareness of hierarchical coherency in SNOMED CT subsets 
 makes effective retrieval of data possible.
",,,,
26262010,Nonadherence to Oral Antihyperglycemic Agents: Subsequent Hospitalization and Mortality among Patients with Type 2 Diabetes in Clinical Practice,"Zhu VJ, Tu W, Rosenman MB, Overhage JM.",Stud Health Technol Inform. 2015;216:60-3.,Zhu VJ,Stud Health Technol Inform,2015,2015-08-12,,,,"Using real-world clinical data from the Indiana Network for Patient Care, we 
 analyzed the associations between non-adherence to oral antihyperglycemic agents 
 (OHA) and subsequent diabetes-related hospitalization and all-cause mortality 
 for patients with type 2 diabetes. OHA adherence was measured by the annual 
 proportion of days covered (PDC) for 2008 and 2009. Among 24,067 eligible 
 patients, 35,507 annual PDCs were formed. Over 90% (n=21,798) of the patients 
 had a PDC less than 80%. In generalized linear mixed model analyses, OHA 
 non-adherence is significantly associated with diabetes related hospitalizations 
 (OR: 1.2; 95% CI [1.1,1.3]; p&lt;0.0001). Older patients, white patients, or 
 patients who had ischemic heart disease, stroke, or renal disease had higher 
 odds of hospitalization. Similarly, OHA non-adherence increased subsequent 
 mortality (OR: 1.3; 95% CI [1.02, 1.61]; p&lt;0.0001). Patient age, male gender, 
 income and presence of ischemic heart diseases, stroke, and renal disease were 
 also significantly associated with subsequent all-cause death.
",,,,
26262146,Effects of Plasma Transfusion on Perioperative Bleeding Complications: A Machine Learning Approach,"Ngufor C, Murphree D, Upadhyaya S, Madde N, Kor D, Pathak J.",Stud Health Technol Inform. 2015;216:721-5.,Ngufor C,Stud Health Technol Inform,2015,2015-08-12,PMC4899868,NIHMS791405,,"Perioperative bleeding (PB) is associated with increased patient morbidity and 
 mortality, and results in substantial health care resource utilization. To 
 assess bleeding risk, a routine practice in most centers is to use indicators 
 such as elevated values of the International Normalized Ratio (INR). For 
 patients with elevated INR, the routine therapy option is plasma transfusion. 
 However, the predictive accuracy of INR and the value of plasma transfusion 
 still remains unclear. Accurate methods are therefore needed to identify early 
 the patients with increased risk of bleeding. The goal of this work is to apply 
 advanced machine learning methods to study the relationship between preoperative 
 plasma transfusion (PPT) and PB in patients with elevated INR undergoing 
 noncardiac surgery. The problem is cast under the framework of causal inference 
 where robust meaningful measures to quantify the effect of PPT on PB are 
 estimated. Results show that both machine learning and standard statistical 
 methods generally agree that PPT negatively impacts PB and other important 
 patient outcomes. However, machine learning methods show significant results, 
 and machine learning boosting methods are found to make less errors in 
 predicting PB.
",,,,
26262122,Identification of Patients with Family History of Pancreatic Cancer--Investigation of an NLP System Portability,"Mehrabi S, Krishnan A, Roch AM, Schmidt H, Li D, Kesterson J, Beesley C, Dexter P, Schmidt M, Palakal M, Liu H.",Stud Health Technol Inform. 2015;216:604-8.,Mehrabi S,Stud Health Technol Inform,2015,2015-08-12,PMC5863760,NIHMS949926,,"In this study we have developed a rule-based natural language processing (NLP) 
 system to identify patients with family history of pancreatic cancer. The 
 algorithm was developed in a Unstructured Information Management Architecture 
 (UIMA) framework and consisted of section segmentation, relation discovery, and 
 negation detection. The system was evaluated on data from two institutions. The 
 family history identification precision was consistent across the institutions 
 shifting from 88.9% on Indiana University (IU) dataset to 87.8% on Mayo Clinic 
 dataset. Customizing the algorithm on the the Mayo Clinic data, increased its 
 precision to 88.1%. The family member relation discovery achieved precision, 
 recall, and F-measure of 75.3%, 91.6% and 82.6% respectively. Negation detection 
 resulted in precision of 99.1%. The results show that rule-based NLP approaches 
 for specific information extraction tasks are portable across institutions; 
 however customization of the algorithm on the new dataset improves its 
 performance.
",,,,
25991273,A health analytics semantic ETL service for obesity surveillance,"Poulymenopoulou M, Papakonstantinou D, Malamateniou F, Vassilacopoulos G.",Stud Health Technol Inform. 2015;210:840-4.,Poulymenopoulou M,Stud Health Technol Inform,2015,2015-05-21,,,,"The increasingly large amount of data produced in healthcare (e.g. collected 
 through health information systems such as electronic medical records - EMRs or 
 collected through novel data sources such as personal health records - PHRs, 
 social media, web resources) enable the creation of detailed records about 
 people's health, sentiments and activities (e.g. physical activity, diet, sleep 
 quality) that can be used in the public health area among others. However, 
 despite the transformative potential of big data in public health surveillance 
 there are several challenges in integrating big data. In this paper, the 
 interoperability challenge is tackled and a semantic Extract Transform Load 
 (ETL) service is proposed that seeks to semantically annotate big data to result 
 into valuable data for analysis. This service is considered as part of a health 
 analytics engine on the cloud that interacts with existing healthcare 
 information exchange networks, like the Integrating the Healthcare Enterprise 
 (IHE), PHRs, sensors, mobile applications, and other web resources to retrieve 
 patient health, behavioral and daily activity data. The semantic ETL service 
 aims at semantically integrating big data for use by analytic mechanisms. An 
 illustrative implementation of the service on big data which is potentially 
 relevant to human obesity, enables using appropriate analytic techniques (e.g. 
 machine learning, text mining) that are expected to assist in identifying 
 patterns and contributing factors (e.g. genetic background, social, 
 environmental) for this social phenomenon and, hence, drive health policy 
 changes and promote healthy behaviors where residents live, work, learn, shop 
 and play.
",,,,
26262148,Fusing Heterogeneous Data for Alzheimer's Disease Classification,"Pillai PS, Leong TY; Alzheimer's Disease Neuroimaging Initiative.",Stud Health Technol Inform. 2015;216:731-5.,Pillai PS,Stud Health Technol Inform,2015,2015-08-12,,,,"In multi-view learning, multimodal representations of a real world object or 
 situation are integrated to learn its overall picture. Feature sets from 
 distinct data sources carry different, yet complementary, information which, if 
 analysed together, usually yield better insights and more accurate results. 
 Neuro-degenerative disorders such as dementia are characterized by changes in 
 multiple biomarkers. This work combines the features from neuroimaging and 
 cerebrospinal fluid studies to distinguish Alzheimer's disease patients from 
 healthy subjects. We apply statistical data fusion techniques on 101 subjects 
 from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database. We examine 
 whether fusion of biomarkers helps to improve diagnostic accuracy and how the 
 methods compare against each other for this problem. Our results indicate that 
 multimodal data fusion improves classification accuracy.
",,,,
26262118,Patient-Centered Outcomes Research in Practice: The CAPriCORN Infrastructure,"Solomonides A, Goel S, Hynes D, Silverstein JC, Hota B, Trick W, Angulo F, Price R, Sadhu E, Zelisko S, Fischer J, Furner B, Hamilton A, Phua J, Brown W, Hohmann SF, Meltzer D, Tarlov E, Weaver FM, Zhang H, Concannon T, Kho A.",Stud Health Technol Inform. 2015;216:584-8.,Solomonides A,Stud Health Technol Inform,2015,2015-08-12,,,,"CAPriCORN, the Chicago Area Patient Centered Outcomes Research Network, is one 
 of the eleven PCORI-funded Clinical Data Research Networks. A collaboration of 
 six academic medical centers, a Chicago public hospital, two VA hospitals and a 
 network of federally qualified health centers, CAPriCORN addresses the needs of 
 a diverse community and overlapping populations. To capture complete medical 
 records without compromising patient privacy and confidentiality, the network 
 created policies and mechanisms for patient consultation, central IRB approval, 
 de-identification, de-duplication, and integration of patient data by study 
 cohort, randomization and sampling, re-identification for consent by providers 
 and patients, and communication with patients to elicit patient-reported 
 outcomes through validated instruments. The paper describes these policies and 
 mechanisms and discusses two case studies to prove the feasibility and 
 effectiveness of the network.
",,,,
26262141,A Two-stage Dynamic Model to Enable Updating of Clinical Risk Prediction from Longitudinal Health Record Data: Illustrated with Kidney Function,"Akbarov A, Williams R, Brown B, Mamas M, Peek N, Buchan I, Sperrin M.",Stud Health Technol Inform. 2015;216:696-700.,Akbarov A,Stud Health Technol Inform,2015,2015-08-12,,,,"We demonstrate the use of electronic records and repeated measures of risk 
 factors therein, to enable deeper understanding of the relationship between the 
 full longitudinal trajectory of risk factors and outcomes. To illustrate, 
 dynamic mixed effect modelling is used to summarise the level, trend and 
 monitoring intensity of kidney function. The output from this model then forms 
 covariates for a recurrent event Cox proportional hazards model for predicting 
 adverse events (AE). Using data from Salford, UK, our multivariate model finds 
 that steeper declines in kidney function raise the hazard of AE (HR: 1.13, 95% 
 CI (1.05, 1.22)). There is a non-proportional relationship between the hazard of 
 AE and the monitoring intensity of kidney function. Neither of these variables 
 would be present in a classical risk prediction model.. This work illustrates 
 the potential of using the full longitudinal profile of risk factors, rather 
 than just their level. There is an opportunity for deep statistical learning 
 leading to rich clinical insight using longitudinal signals in electronic data.
",,,,
25991173,"Evaluation of compliance with recommendations of prevention of thromboembolism in atrial fibrillation in the elderly, by data reuse of electronic health records","Ferret L, Beuscart JB, Ficheur G, Beuscart R, Luyckx M, Chazard E.",Stud Health Technol Inform. 2015;210:394-8.,Ferret L,Stud Health Technol Inform,2015,2015-05-21,,,,"Under-prescription of anticoagulants in the elderly with atrial fibrillation 
 (AF) has been described in several studies, showing that only 15 to 44% of them 
 receive anticoagulants. However, the European Society of Cardiology 
 recommendations state that anticoagulants should be systematically prescribed. 
 In case of refusal of the treatment by the patient, a platelet aggregation 
 inhibitor should be prescribed in monotherapy or bitherapy according to the 
 HAS-BLED bleeding risk score. In all the cases the patient should receive an 
 antithrombotic treatment. In this work we observe the adequacy of prescription 
 practices to the recommendations for AF in the elderly by data reuse on a 
 monocentric observational retrospective cohort. Data of a 222 beds French 
 community hospital were extracted for the year 2013. The patients aged over 75 
 years and presenting AF were selected. The HAS-BLED score was calculated and the 
 consistency of the prescriptions with the recommendations of the European 
 Society of Cardiology was verified. Then the compliance rate to the 
 recommendations was calculated. The rules detected 433 patients with AF and aged 
 over 75 years. From those patients, 45% received an anticoagulant, 32.1% 
 received platelet aggregation inhibitors and 22.9% did not receive any 
 antithrombotic treatment. When a platelet aggregation inhibitor was prescribed 
 the recommendation for bitherapy was not followed in 97% of the cases. The 
 compliance rate to the recommendations was 47.8%. This work highlights a major 
 problem of quality of the prescriptions in the hospital field and shows how data 
 reuse can help describing this type of issues.
",,,,
27350471,Finding 'Evidence of Absence' in Medical Notes: Using NLP for Clinical Inferencing,"Carter ME, Divita G, Redd A, Rubin MA, Samore MH, Gupta K, Trautner BW, Gundlapalli AV.",Stud Health Technol Inform. 2016;226:79-82.,Carter ME,Stud Health Technol Inform,2016,2016-06-29,,,,"Extracting evidence of the absence of a target of interest from medical text can 
 be useful in clinical inferencing. The purpose of our study was to develop a 
 natural language processing (NLP) pipelineto identify the presence of indwelling 
 urinary catheters from electronic medical notes to aid in detection of 
 catheter-associated urinary tract infections (CAUTI). Finding clear evidence 
 that a patient does not have an indwelling urinary catheter is useful in making 
 a determination regarding CAUTI. We developed a lexicon of seven core concepts 
 to infer the absence of a urinary catheter. Of the 990,391 concepts extractedby 
 NLP from a large corpus of 744,285 electronic medical notes from 5589 
 hospitalized patients, 63,516 were labeled as evidence of absence.Human review 
 revealed three primary causes for false negatives. The lexicon and NLP pipeline 
 were refined using this information, resulting in outputs with an acceptable 
 false positive rate of 11%.
",,,,
27139386,Automated Transformation of openEHR Data Instances to OWL,"Haarbrandt B, Jack T, Marschollek M.",Stud Health Technol Inform. 2016;223:63-70.,Haarbrandt B,Stud Health Technol Inform,2016,2016-05-04,,,,"Standard-based integration and semantic enrichment of clinical data originating 
 from electronic medical records has shown to be critical to enable secondary 
 use. To facilitate the utilization of semantic technologies on clinical data, we 
 introduce a methodology to enable automated transformation of openEHR-based data 
 to Web Ontology Language (OWL) individuals. To test the correctness of the 
 implementation, de-identified data of 229 patients of the pediatric intensive 
 care unit of Hannover Medical School has been transformed into 2.983.436 
 individuals. Querying of the resulting ontology for symptoms of the systemic 
 inflammatory response syndrome (SIRS) yielded the same result set as a SQL query 
 on an openEHR-based clinical data repository.
",,,,
27332231,Identifying Outliers in Data from Patient Record,"Baumberger D, Buergin R.",Stud Health Technol Inform. 2016;225:402-6.,Baumberger D,Stud Health Technol Inform,2016,2016-06-23,,,,"It is important for health services to be able to identify potential outliers 
 with minimal effort as part of their daily evaluation of care data from patient 
 record. This study evaluates the suitability of three statistical methods for 
 identifying nursing outliers. The results show that by using methods implemented 
 in the nursing workload measurement system ""LEP"" with reference to real data, 
 unusual LEP minute profiles (movement, nutrition and so on) can be identified 
 with little effort and therefore seem promising for application to the health 
 services' daily evaluation process. The lessons learned are used to create 
 requirement criteria for the further development of software solutions. It is 
 recommended that the methods for identifying outliers in the daily evaluation 
 process should be standardized in order to increase the efficiency of secondary 
 use of care data from patient record.
",,,,
27071884,Elderly Surgical Patients: Automated Computation of Healthcare Quality Indicators by Data Reuse of EHR,"Ficheur G, Schaffar A, Caron A, Balcaen T, Beuscart JB, Chazard E.",Stud Health Technol Inform. 2016;221:92-6.,Ficheur G,Stud Health Technol Inform,2016,2016-04-14,,,,"The objective of the work is to implement and evaluate the automated computation 
 of 9 healthcare quality indicators, by data reuse of electronic health records, 
 in the field of elderly surgical patients.
 METHODS: Data are extracted from EHR, including administrative data, ICD10 
 diagnoses, laboratory results, procedures, administered drugs, and free-text 
 letters. The indicators are implemented by a medical data reuse specialist. The 
 conformity rate is automatically computed (3.5 minutes for 15,000 inpatient 
 stays and 9 indicators). A medical expert reviews 45 stays per indicator. The 
 precision is the proportion of non-conform inpatient stays among the cases 
 detected as non-conform by the algorithms.
 RESULTS: the paper describes the implemented algorithms, the conformity rates 
 and the precisions. Two indicators have a precision of 0%, 3 indicators have a 
 precision of 40 to 60%, and four indicators have a precision from 80 to 100% 
 (for 2 of them, the conformity rate is lower than 2.5%!). This demonstrates that 
 automated quality screening is possible and enables to detect threatening 
 situations. The implementation of the indicators requires special skills in 
 medicine, medical information sciences, and algorithmics. Failures of precision 
 are mainly due to defaults of information quality (missing codes), and could 
 benefit from text analysis.
",,,,
27071886,Automated Data Aggregation for Time-Series Analysis: Study Case on Anaesthesia Data Warehouse,"Lamer A, Jeanne M, Ficheur G, Marcilly R.",Stud Health Technol Inform. 2016;221:102-6.,Lamer A,Stud Health Technol Inform,2016,2016-04-14,,,,"Data stored in operational databases are not reusable directly. Aggregation 
 modules are necessary to facilitate secondary use. They decrease volume of data 
 while increasing the number of available information. In this paper, we present 
 four automated engines of aggregation, integrated into an anaesthesia data 
 warehouse. Four instances of clinical questions illustrate the use of those 
 engines for various improvements of quality of care: duration of procedure, drug 
 administration, assessment of hypotension and its related treatment.
",,,,
27332355,Using a Text-Mining Approach to Evaluate the Quality of Nursing Records,"Chang HM, Chiou SF, Liu HY, Yu HC.",Stud Health Technol Inform. 2016;225:813-4.,Chang HM,Stud Health Technol Inform,2016,2016-06-23,,,,"Nursing records in Taiwan have been computerized, but their quality has rarely 
 been discussed. Therefore, this study employed a text-mining approach and a 
 cross-sectional retrospective research design to evaluate the quality of 
 electronic nursing records at a medical center in Northern Taiwan. SAS Text 
 Miner software Version 13.2 was employed to analyze unstructured nursing event 
 records. The results show that SAS Text Miner is suitable for developing a 
 textmining model for validating nursing records. The sensitivity of SAS Text 
 Miner was approximately 0.94, and the specificity and accuracy were 0.99. Thus, 
 SAS Text Miner software is an effective tool for auditing unstructured 
 electronic nursing records.
",,,,
27139387,Extraction of UMLS® Concepts Using Apache cTAKES™ for German Language,"Becker M, Böckmann B.",Stud Health Technol Inform. 2016;223:71-6.,Becker M,Stud Health Technol Inform,2016,2016-05-04,,,,"Automatic information extraction of medical concepts and classification with 
 semantic standards from medical reports is useful for standardization and for 
 clinical research. This paper presents an approach for an UMLS concept 
 extraction with a customized natural language processing pipeline for German 
 clinical notes using Apache cTAKES. The objectives are, to test the natural 
 language processing tool for German language if it is suitable to identify UMLS 
 concepts and map these with SNOMED-CT. The German UMLS database and German 
 OpenNLP models extended the natural language processing pipeline, so the 
 pipeline can normalize to domain ontologies such as SNOMED-CT using the German 
 concepts. For testing, the ShARe/CLEF eHealth 2013 training dataset translated 
 into German was used. The implemented algorithms are tested with a set of 199 
 German reports, obtaining a result of average 0.36 F1 measure without German 
 stemming, pre- and post-processing of the reports.
",,,,
27071889,Retrieving Clinical and Omic Data from Electronic Health Records,"Cabot C, Lelong R, Grosjean J, Soualmia LF, Darmoni SJ.",Stud Health Technol Inform. 2016;221:115.,Cabot C,Stud Health Technol Inform,2016,2016-04-14,,,,"PMID: 27071889 [Indexed for MEDLINE]
",,,,
27332326,Harmonising ICNP and SNOMED CT: A Model for Effective Collaboration,Hardiker N.,Stud Health Technol Inform. 2016;225:744-5.,Hardiker N,Stud Health Technol Inform,2016,2016-06-23,,,,"The purpose of this panel was to demonstrate an approach to collaborative 
 working within nursing and health informatics. The panel took as an example an 
 initiative to harmonise between two large-scale terminologies, namely the 
 International Classification for Nursing Practice (ICNP) and SNOMED Clinical 
 Terms (SNOMED CT). A number of practical topics were framed within a context of 
 collaboration, including semi-automated and manual approaches to mapping, 
 consensus working, clinical validation, formal concept modelling, etc. Those 
 attending the panel, nurses and informatics professional alike, came away with 
 an increased understanding of a range of approaches to collaborative working 
 within nursing and health informatics.
",,,,
27332177,Computerization of a Nursing Chart According to the Nursing Process,"Schachner MB, González ZA, Sommer JA, Recondo FJ, Gassino FD, Luna DR, Benítez SE.",Stud Health Technol Inform. 2016;225:133-7.,Schachner MB,Stud Health Technol Inform,2016,2016-06-23,,,,"The benefits associated with the computerization of clinical records are known 
 since a long time ago. Documentation evolution from paper to electronic format 
 aims to always improve communication, reduce errors and facilitate continuity of 
 care. Ideally when improvements to nursing records are contemplated, they should 
 consider the nurses needs, new functionality workflow impacts and correspondence 
 with representation models of standardized data that are specific to their 
 domains practices. The aim of this study was to describe the development and 
 implementation of computerized nursing record at Hospital Italiano de Buenos 
 Aires.
",,,,
27071880,Ontological Foundations for Tracking Data Quality through the Internet of Things,"Ceusters W, Bona J.",Stud Health Technol Inform. 2016;221:74-8.,Ceusters W,Stud Health Technol Inform,2016,2016-04-14,,,,"Amongst the positive outcomes expected from the Internet of Things for Health 
 are longitudinal patient records that are more complete and less erroneous by 
 complementing manual data entry with automatic data feeds from sensors. 
 Unfortunately, devices are fallible too. Quality control procedures such as 
 inspection, testing and maintenance can prevent devices from producing errors. 
 The additional approach envisioned here is to establish constant data quality 
 monitoring through analytics procedures on patient data that exploit not only 
 the ontological principles ascribed to patients and their bodily features, but 
 also to observation and measurement processes in which devices and patients 
 participate, including the, perhaps erroneous, representations that are 
 generated. Using existing realism-based ontologies, we propose a set of 
 categories that analytics procedures should be able to reason with and highlight 
 the importance of unique identification of not only patients, caregivers and 
 devices, but of everything involved in those measurements. This approach 
 supports the thesis that the majority of what tends to be viewed as 'metadata' 
 are actually data about first-order entities.
",,,,
27332176,Functionality of Triggers for Epilepsy Patients Assessed by Text and Data Mining of Medical and Nursing Records,"Kivekäs E, Kinnunen UM, Paananen P, Kälviäinen R, Haatainen K, Saranto K.",Stud Health Technol Inform. 2016;225:128-32.,Kivekäs E,Stud Health Technol Inform,2016,2016-06-23,,,,"A trigger is a powerful tool for identifying adverse events to measure the level 
 of any kind of harm caused in patient care. Studies with epilepsy patients have 
 illustrated that using triggers as a methodology with data mining may increase 
 patient well-being. The purpose of this study is to test the functionality and 
 validity of the previously defined triggers to describe the status of epilepsy 
 patient's well-being. In both medical and nursing data, the triggers described 
 patients' well-being comprehensively. The narratives showed that there was 
 overlapping in triggers. The preliminary results of triggers encourage us to 
 develop some reminders to the documentation of epilepsy patient well-being. 
 These provide healthcare professionals with further and more detailed 
 information when necessary.
",,,,
27139390,SEMCARE: Multilingual Semantic Search in Semi-Structured Clinical Data,"López-García P, Kreuzthaler M, Schulz S, Scherr D, Daumke P, Markó K, Kors JA, van Mulligen EM, Wang X, Gonna H, Behr E, Honrado Á.",Stud Health Technol Inform. 2016;223:93-9.,López-García P,Stud Health Technol Inform,2016,2016-05-04,,,,"The vast amount of clinical data in electronic health records constitutes a 
 great potential for secondary use. However, most of this content consists of 
 unstructured or semi-structured texts, which is difficult to process. Several 
 challenges are still pending: medical language idiosyncrasies in different 
 natural languages, and the large variety of medical terminology systems. In this 
 paper we present SEMCARE, a European initiative designed to minimize these 
 problems by providing a multi-lingual platform (English, German, and Dutch) that 
 allows users to express complex queries and obtain relevant search results from 
 clinical texts. SEMCARE is based on a selection of adapted biomedical 
 terminologies, together with Apache UIMA and Apache Solr as open source 
 state-of-the-art natural language pipeline and indexing technologies. SEMCARE 
 has been deployed and is currently being tested at three medical institutions in 
 the UK, Austria, and the Netherlands, showing promising results in a cardiology 
 use case.
",,,,
27332377,Mining Clinicians' Electronic Documentation to Identify Heart Failure Patients with Ineffective Self-Management: A Pilot Text-Mining Study,"Topaz M, Radhakrishnan K, Lei V, Zhou L.",Stud Health Technol Inform. 2016;225:856-7.,Topaz M,Stud Health Technol Inform,2016,2016-06-23,,,,"Effective self-management can decrease up to 50% of heart failure 
 hospitalizations. Unfortunately, self-management by patients with heart failure 
 remains poor. This pilot study aimed to explore the use of text-mining to 
 identify heart failure patients with ineffective self-management. We first built 
 a comprehensive self-management vocabulary based on the literature and clinical 
 notes review. We then randomly selected 545 heart failure patients treated 
 within Partners Healthcare hospitals (Boston, MA, USA) and conducted a regular 
 expression search with the compiled vocabulary within 43,107 interdisciplinary 
 clinical notes of these patients. We found that 38.2% (n = 208) patients had 
 documentation of ineffective heart failure self-management in the domains of 
 poor diet adherence (28.4%), missed medical encounters (26.4%) poor medication 
 adherence (20.2%) and non-specified self-management issues (e.g., ""compliance 
 issues"", 34.6%). We showed the feasibility of using text-mining to identify 
 patients with ineffective self-management. More natural language processing 
 algorithms are needed to help busy clinicians identify these patients.
",,,,
27332460,Cross-Mapping Diagnostic Nursing Concepts Between the ICNP and the ICF for Expressing Nursing in the Health Care Record,"Florin J, Jansson I, Strandberg E, Ehrenberg A, Björvell C.",Stud Health Technol Inform. 2016;225:1016-7.,Florin J,Stud Health Technol Inform,2016,2016-06-23,,,,"PMID: 27332460 [Indexed for MEDLINE]
",,,,
27332463,Is the ISO Reference Terminology Model for Nursing Actions Enough to Describe Nursing Actions?,"Lee JY, Park HA.",Stud Health Technol Inform. 2016;225:1022-3.,Lee JY,Stud Health Technol Inform,2016,2016-06-23,,,,"The aim of this study is to test the applicability of the International 
 Standards Organization (ISO) Reference terminology model (RTM) for nursing 
 action to describe Detailed Clinical Models (DCMs) for nursing action. All verb 
 and target terms were mapped to 'Action' and 'Target' category of RTM for 
 nursing actions. Among 72 attributes qualifying the verb terms, 50 attributes 
 were mapped to Means, Route, Timing, or Site categories of the nursing action 
 model. Among 142 attributes qualifying the target terms, 20 attributes were 
 mapped to Means, Timing, or Site categories of the nursing action model and 6 
 attributes were mapped to Degree or Judgment categories of the nursing diagnosis 
 model. The findings suggest the need for an integrated RTM for nursing.
",,,,
27332245,Harmonising Nursing Terminologies Using a Conceptual Framework,"Jansen K, Kim TY, Coenen A, Saba V, Hardiker N.",Stud Health Technol Inform. 2016;225:471-5.,Jansen K,Stud Health Technol Inform,2016,2016-06-23,,,,"The International Classification for Nursing Practice (ICNP®) and the Clinical 
 Care Classification (CCC) System are standardised nursing terminologies that 
 identify discrete elements of nursing practice, including nursing diagnoses, 
 interventions, and outcomes. While CCC uses a conceptual framework or model with 
 21 Care Components to classify these elements, ICNP, built on a formal Web 
 Ontology Language (OWL) description logic foundation, uses a logical 
 hierarchical framework that is useful for computing and maintenance of ICNP. 
 Since the logical framework of ICNP may not always align with the needs of 
 nursing practice, an informal framework may be a more useful organisational tool 
 to represent nursing content. The purpose of this study was to classify ICNP 
 nursing diagnoses using the 21 Care Components of the CCC as a conceptual 
 framework to facilitate usability and inter-operability of nursing diagnoses in 
 electronic health records. Findings resulted in all 521 ICNP diagnoses being 
 assigned to one of the 21 CCC Care Components. Further research is needed to 
 validate the resulting product of this study with practitioners and develop 
 recommendations for improvement of both terminologies.
",,,,
27577448,Beyond Cohort Selection: An Analytics-Enabled i2b2,"Gabetta M, Malovini A, Bucalo M, Zini E, Tibollo V, Priori SG, Vettoretti S, Larizza C, Bellazzi R, Barbarini N.",Stud Health Technol Inform. 2016;228:572-6.,Gabetta M,Stud Health Technol Inform,2016,2016-09-01,,,,"The i2b2 software is a widely adopted solution for secondary use of clinical 
 data for clinical research, specifically designed for cohort identification. 
 i2b2 is still lacking functionalities for data analysis. The aim of this work is 
 to empower the i2b2 framework enabling clinical researchers to perform 
 statistical analyses for accelerating the process of hypothesis testing. To this 
 aim we have developed a flexible extension of i2b2 able to exploit different 
 statistical engines. We have implemented some first applications for basic 
 statistics and survival analyses, exploiting this extension and accessible 
 through suitable user interfaces designed with a special consideration for 
 usability.
",,,,
27332220,Exchange of Information Between Hospital and Home Health Care: A Longitudinal Perspective,"Hellesø R, Melby L, Brattheim B, Toussaint P.",Stud Health Technol Inform. 2016;225:349-53.,Hellesø R,Stud Health Technol Inform,2016,2016-06-23,,,,"In this paper we present a longitudinal perspective of exchange of information 
 providers in hospital and home health care. More specifically we address how 
 this practice has changed over the last six years. In three different studies we 
 have investigated how the information exchange between hospital and home health 
 care throughout a patient transition from admission to discharge has changed 
 over the last six years. The information processes have gone from being mainly 
 paper-based to being digitalized. However, there are still professional 
 challenges to overcome which may contribute to improvements for patients in 
 transition.
",,,,
27577501,Electronic Medical Record-Based Predictive Model for Acute Kidney Injury in an Acute Care Hospital,"Laszczyńska O, Severo M, Azevedo A.",Stud Health Technol Inform. 2016;228:810-2.,Laszczyńska O,Stud Health Technol Inform,2016,2016-09-01,,,,"Patients with acute kidney injury (AKI) are at risk for increased morbidity and 
 mortality. Lack of specific treatment has meant that efforts have focused on 
 early diagnosis and timely treatment. Advanced algorithms for clinical 
 assistance including AKI prediction models have potential to provide accurate 
 risk estimates. In this project, we aim to provide a clinical decision 
 supporting system (CDSS) based on a self-learning predictive model for AKI in 
 patients of an acute care hospital. Data of all in-patient episodes in adults 
 admitted will be analysed using ""data mining"" techniques to build a prediction 
 model. The subsequent machine-learning process including two algorithms for data 
 stream and concept drift will refine the predictive ability of the model. 
 Simulation studies on the model will be used to quantify the expected impact of 
 several scenarios of change in factors that influence AKI incidence. The 
 proposed dynamic CDSS will apply to future in-hospital AKI surveillance in 
 clinical practice.
",,,,
27071877,Remote Monitoring of Cardiac Implantable Devices: Ontology Driven Classification of the Alerts,"Rosier A, Mabo P, Temal L, Van Hille P, Dameron O, Deleger L, Grouin C, Zweigenbaum P, Jacques J, Chazard E, Laporte L, Henry C, Burgun A.",Stud Health Technol Inform. 2016;221:59-63.,Rosier A,Stud Health Technol Inform,2016,2016-04-14,,,,"The number of patients that benefit from remote monitoring of cardiac 
 implantable electronic devices, such as pacemakers and defibrillators, is 
 growing rapidly. Consequently, the huge number of alerts that are generated and 
 transmitted to the physicians represents a challenge to handle. We have 
 developed a system based on a formal ontology that integrates the alert 
 information and the patient data extracted from the electronic health record in 
 order to better classify the importance of alerts. A pilot study was conducted 
 on atrial fibrillation alerts. We show some examples of alert processing. The 
 results suggest that this approach has the potential to significantly reduce the 
 alert burden in telecardiology. The methods may be extended to other types of 
 connected devices.
",,,,
29295114,Extracting Sexual Trauma Mentions from Electronic Medical Notes Using Natural Language Processing,"Divita G, Brignone E, Carter ME, Suo Y, Blais RK, Samore MH, Fargo JD, Gundlapalli AV.",Stud Health Technol Inform. 2017;245:351-355.,Divita G,Stud Health Technol Inform,2017,2018-01-04,,,,"Patient history of sexual trauma is of clinical relevance to healthcare 
 providers as survivors face adverse health-related outcomes. This paper 
 describes a method for identifying mentions of sexual trauma within the free 
 text of electronic medical notes. A natural language processing pipeline for 
 information extraction was developed and scaled to handle a large corpus of 
 electronic medical notes used for this study from US Veterans Health 
 Administration medical facilities. The tool was used to identify sexual trauma 
 mentions and create snippets around every asserted mention based on a 
 domain-specific lexicon developed for this purpose. All snippets were evaluated 
 by trained human reviewers. An overall positive predictive value (PPV) of 0.90 
 for identifying sexual trauma mentions from the free text and a PPV of 0.71 at 
 the patient level are reported. The metrics are superior for records from female 
 patients.
",,,,
29295115,General Symptom Extraction from VA Electronic Medical Notes,"Divita G, Luo G, Tran LT, Workman TE, Gundlapalli AV, Samore MH.",Stud Health Technol Inform. 2017;245:356-360.,Divita G,Stud Health Technol Inform,2017,2018-01-04,,,,"There is need for cataloging signs and symptoms, but not all are documented in 
 structured data. The text from clinical records are an additional source of 
 signs and symptoms. We describe a Natural Language Processing (NLP) technique to 
 identify symptoms from text. Using a human-annotated reference corpus from VA 
 electronic medical notes we trained and tested an NLP pipeline to identify and 
 categorize symptoms. The technique includes a model created from an automatic 
 machine learning model selection tool. Tested on a hold-out set, its precision 
 at the mention level was 0.80, recall 0.74 and an overall f-score of 0.80. The 
 tool was scaled-up to process a large corpus of 964,105 patient records.
",,,,
29295172,Aligned-Layer Text Search in Clinical Notes,"Wu S, Wen A, Wang Y, Liu S, Liu H.",Stud Health Technol Inform. 2017;245:629-633.,Wu S,Stud Health Technol Inform,2017,2018-01-04,PMC7466869,NIHMS1618552,,"Search techniques in clinical text need to make fine-grained semantic 
 distinctions, since medical terms may be negated, about someone other than the 
 patient, or at some time other than the present. While natural language 
 processing (NLP) approaches address these fine-grained distinctions, a task like 
 patient cohort identification from electronic health records (EHRs) 
 simultaneously requires a much more coarse-grained combination of evidence from 
 the text and structured data of each patient's health records. We thus introduce 
 aligned-layer language models, a novel approach to information retrieval (IR) 
 that incorporates the output of other NLP systems. We show that this framework 
 is able to represent standard IR queries, formulate previously impossible 
 multi-layered queries, and customize the desired degree of linguistic 
 granularity.
",,,,
28423792,Acronym Disambiguation in Spanish Electronic Health Narratives Using Machine Learning Techniques,"Rubio-López I, Costumero R, Ambit H, Gonzalo-Martín C, Menasalvas E, Rodríguez González A.",Stud Health Technol Inform. 2017;235:251-255.,Rubio-López I,Stud Health Technol Inform,2017,2017-04-21,,,,"Electronic Health Records (EHRs) are now being massively used in hospitals what 
 has motivated current developments of new methods to process clinical narratives 
 (unstructured data) making it possible to perform context-based searches. 
 Current approaches to process the unstructured texts in EHRs are based in 
 applying text mining or natural language processing (NLP) techniques over the 
 data. In particular Named Entity Recognition (NER) is of paramount importance to 
 retrieve specific biomedical concepts from the text providing the semantic type 
 of the concept retrieved. However, it is very common that clinical notes contain 
 lots of acronyms that cannot be identified by NER processes and even if they are 
 identified, an acronym may correspond to several meanings, so disambiguation of 
 the found term is needed. In this work we provide an approach to perform acronym 
 disambiguation in Spanish EHR using machine learning techniques.
",,,,
28423779,Fast and Efficient Feature Engineering for Multi-Cohort Analysis of EHR Data,"Ozery-Flato M, Yanover C, Gottlieb A, Weissbrod O, Parush Shear-Yashuv N, Goldschmidt Y.",Stud Health Technol Inform. 2017;235:181-185.,Ozery-Flato M,Stud Health Technol Inform,2017,2017-04-21,,,,"We present a framework for feature engineering, tailored for longitudinal 
 structured data, such as electronic health records (EHRs). To fast-track feature 
 engineering and extraction, the framework combines general-use plug-in 
 extractors, a multi-cohort management mechanism, and modular memoization. Using 
 this framework, we rapidly extracted thousands of features from diverse and 
 large healthcare data sources in multiple projects.
",,,,
29295240,An OMOP CDM-Based Relational Database of Clinical Research Eligibility Criteria,"Si Y, Weng C.",Stud Health Technol Inform. 2017;245:950-954.,Si Y,Stud Health Technol Inform,2017,2018-01-04,PMC5893219,NIHMS955981,,"Eligibility criteria are important for clinical research protocols or clinical 
 practice guidelines for determining who qualify for studies and to whom clinical 
 evidence is applicable, but the free-text format is not amenable for 
 computational processing. In this paper, we described a practical method for 
 transforming free-text clinical research eligibility criteria of Alzheimer's 
 clinical trials into a structured relational database compliant with standards 
 for medical terminologies and clinical data models. We utilized a hybrid natural 
 language processing system and a concept normalization tool to extract medical 
 terms in clinical research eligibility criteria and represent them using the 
 OMOP Common Data Model (CDM) v5. We created a database schema design to store 
 syntactic relations to facilitate efficient cohort queries. We further discussed 
 the potential of applying this method to trials on other diseases and the 
 promise of using it to accelerate clinical research with electronic health 
 records.
",,,,
28423786,Prevalence Estimation of Protected Health Information in Swedish Clinical Text,"Henriksson A, Kvist M, Dalianis H.",Stud Health Technol Inform. 2017;235:216-220.,Henriksson A,Stud Health Technol Inform,2017,2017-04-21,,,,"Obscuring protected health information (PHI) in the clinical text of health 
 records facilitates the secondary use of healthcare data in a privacy-preserving 
 manner. Although automatic de-identification of clinical text using machine 
 learning holds much promise, little is known about the relative prevalence of 
 PHI in different types of clinical text and whether there is a need for domain 
 adaptation when learning predictive models from one particular domain and 
 applying it to another. In this study, we address these questions by training a 
 predictive model and using it to estimate the prevalence of PHI in clinical text 
 written (1) in different clinical specialties, (2) in different types of notes 
 (i.e., under different headings), and (3) by persons in different professional 
 roles. It is demonstrated that the overall PHI density is 1.57%; however, 
 substantial differences exist across domains.
",,,,
29295100,MedEx/J: A One-Scan Simple and Fast NLP Tool for Japanese Clinical Texts,"Aramaki E, Yano K, Wakamiya S.",Stud Health Technol Inform. 2017;245:285-288.,Aramaki E,Stud Health Technol Inform,2017,2018-01-04,,,,"Because of recent replacement of physical documents with electronic medical 
 records (EMR), the importance of information processing in the medical field has 
 increased. In light of this trend, we have been developing MedEx/J, which 
 retrieves important Japanese language information from medical reports. MedEx/J 
 executes two tasks simultaneously: (1) term extraction, and (2) positive and 
 negative event classification. We designate this approach as a one-scan 
 approach, providing simplicity of systems and reasonable accuracy. MedEx/J 
 performance on the two tasks is described herein: (1) term extraction (F<inf>β = 
 1</inf> = 0.87) and (2) positive-negative classification (F<inf>β = 1</inf> = 
 0.63). This paper also presents discussion and explains remaining issues in the 
 medical natural language processing field.
",,,,
28508775,Semantic Technologies for Re-Use of Clinical Routine Data,"Kreuzthaler M, Martínez-Costa C, Kaiser P, Schulz S.",Stud Health Technol Inform. 2017;236:24-31.,Kreuzthaler M,Stud Health Technol Inform,2017,2017-05-17,,,,"Routine patient data in electronic patient records are only partly structured, 
 and an even smaller segment is coded, mainly for administrative purposes. Large 
 parts are only available as free text. Transforming this content into a 
 structured and semantically explicit form is a prerequisite for querying and 
 information extraction. The core of the system architecture presented in this 
 paper is based on SAP HANA in-memory database technology using the SAP Connected 
 Health platform for data integration as well as for clinical data warehousing. A 
 natural language processing pipeline analyses unstructured content and maps it 
 to a standardized vocabulary within a well-defined information model. The 
 resulting semantically standardized patient profiles are used for a broad range 
 of clinical and research application scenarios.
",,,,
28423790,Improving Terminology Mapping in Clinical Text with Context-Sensitive Spelling Correction,"Dziadek J, Henriksson A, Duneld M.",Stud Health Technol Inform. 2017;235:241-245.,Dziadek J,Stud Health Technol Inform,2017,2017-04-21,,,,"The mapping of unstructured clinical text to an ontology facilitates meaningful 
 secondary use of health records but is non-trivial due to lexical variation and 
 the abundance of misspellings in hurriedly produced notes. Here, we apply 
 several spelling correction methods to Swedish medical text and evaluate their 
 impact on SNOMED CT mapping; first in a controlled evaluation using medical 
 literature text with induced errors, followed by a partial evaluation on 
 clinical notes. It is shown that the best-performing method is 
 context-sensitive, taking into account trigram frequencies and utilizing a 
 corpus-based dictionary.
",,,,
28423797,HTP-NLP: A New NLP System for High Throughput Phenotyping,"Schlegel DR, Crowner C, Lehoullier F, Elkin PL.",Stud Health Technol Inform. 2017;235:276-280.,Schlegel DR,Stud Health Technol Inform,2017,2017-04-21,PMC7767581,NIHMS1655780,,"Secondary use of clinical data for research requires a method to quickly process 
 the data so that researchers can quickly extract cohorts. We present two 
 advances in the High Throughput Phenotyping NLP system which support the aim of 
 truly high throughput processing of clinical data, inspired by a 
 characterization of the linguistic properties of such data. Semantic indexing to 
 store and generalize partially-processed results and the use of compositional 
 expressions for ungrammatical text are discussed, along with a set of initial 
 timing results for the system.
",,,,
29295354,Usability Evaluation of NLP-PIER: A Clinical Document Search Engine for Researchers,"Hultman G, McEwan R, Pakhomov S, Lindemann E, Skube S, Melton GB.",Stud Health Technol Inform. 2017;245:1269.,Hultman G,Stud Health Technol Inform,2017,2018-01-04,PMC6188640,NIHMS990719,,"NLP-PIER (Natural Language Processing - Patient Information Extraction for 
 Research) is a self-service platform with a search engine for clinical 
 researchers to perform natural language processing (NLP) queries using clinical 
 notes. We conducted user-centered testing of NLP-PIER's usability to inform 
 future design decisions. Quantitative and qualitative data were analyzed. Our 
 findings will be used to improve the usability of NLP-PIER.
",,,,
29295113,Translational Morphosyntax: Distribution of Negation in Clinical Records and Biomedical Journal Articles,"Cohen KB, Goss FR, Zweigenbaum P, Hunter LE.",Stud Health Technol Inform. 2017;245:346-350.,Cohen KB,Stud Health Technol Inform,2017,2018-01-04,,,,"Prior knowledge of the distributional characteristics of linguistic phenomena 
 can be useful for a variety of language processing tasks. This paper describes 
 the distribution of negation in two types of biomedical texts: scientific 
 journal articles and progress notes. Two types of negation are examined: 
 explicit negation at the syntactic level and affixal negation at the sub-word 
 level. The data show that the distribution of negation is significantly 
 different in the two document types, with explicit negation more frequent in the 
 clinical documents than in the scientific publications and affixal negation more 
 frequent in the journal articles at the type level and token levels. All code is 
 available on GitHub <fnr rid=""fn001"" /><fn 
 id=""fn001"">https://github.com/KevinBretonnelCohen/NegationDistribution </fn>.
",,,,
28186017,Storing and Querying Longitudinal Data Sets in an Open Source EHR,"Chelsom J, Dogar N.",Stud Health Technol Inform. 2017;234:65-69.,Chelsom J,Stud Health Technol Inform,2017,2017-02-11,,,,"The cityEHR is an example of an open source EHR system which stores clinical 
 data as collections of XML documents. The records gathered in routine clinical 
 care are a rich source of longitudinal data for use in clinical studies. We 
 describe how the standard language XQuery can be used to identify cohorts of 
 patients, matching specified criteria. We discuss methods for ensuring good data 
 quality and the issues in implementing XML queries on longitudinal data sets.
",,,,
28679906,Comparison of Grouping Methods for Template Extraction from VA Medical Record Text,"Redd AM, Gundlapalli AV, Divita G, Tran LT, Pettey WBP, Samore MH.",Stud Health Technol Inform. 2017;238:136-139.,Redd AM,Stud Health Technol Inform,2017,2017-07-07,,,,"We investigate options for grouping templates for the purpose of template 
 identification and extraction from electronic medical records. We sampled a 
 corpus of 1000 documents originating from Veterans Health Administration (VA) 
 electronic medical record. We grouped documents through hashing and binning 
 tokens (Hashed) as well as by the top 5% of tokens identified as important 
 through the term frequency inverse document frequency metric (TF-IDF). We then 
 compared the approaches on the number of groups with 3 or more and the resulting 
 longest common subsequences (LCSs) common to all documents in the group. We 
 found that the Hashed method had a higher success rate for finding LCSs, and 
 longer LCSs than the TF-IDF method, however the TF-IDF approach found more 
 groups than the Hashed and subsequently more long sequences, however the average 
 length of LCSs were lower. In conclusion, each algorithm appears to have areas 
 where it appears to be superior.
",,,,
29295123,Detecting Protected Health Information in Heterogeneous Clinical Notes,"Henriksson A, Kvist M, Dalianis H.",Stud Health Technol Inform. 2017;245:393-397.,Henriksson A,Stud Health Technol Inform,2017,2018-01-04,,,,"To enable secondary use of healthcare data in a privacy-preserving manner, there 
 is a need for methods capable of automatically identifying protected health 
 information (PHI) in clinical text. To that end, learning predictive models from 
 labeled examples has emerged as a promising alternative to rule-based systems. 
 However, little is known about differences with respect to PHI prevalence in 
 different types of clinical notes and how potential domain differences may 
 affect the performance of predictive models trained on one particular type of 
 note and applied to another. In this study, we analyze the performance of a 
 predictive model trained on an existing PHI corpus of Swedish clinical notes and 
 applied to a variety of clinical notes: written (i) in different clinical 
 specialties, (ii) under different headings, and (iii) by persons in different 
 professions. The results indicate that domain adaption is needed for effective 
 detection of PHI in heterogeneous clinical notes.
",,,,
28423767,Querying EHRs with a Semantic and Entity-Oriented Query Language,"Lelong R, Soualmia L, Dahamna B, Griffon N, Darmoni SJ.",Stud Health Technol Inform. 2017;235:121-125.,Lelong R,Stud Health Technol Inform,2017,2017-04-21,,,,"While the digitization of medical documents has greatly expanded during the past 
 decade, health information retrieval has become a great challenge to address 
 many issues in medical research. Information retrieval in electronic health 
 records (EHR) should also reduce the difficult tasks of manual information 
 retrieval from records in paper format or computer. The aim of this article was 
 to present the features of a semantic search engine implemented in EHRs. A 
 flexible, scalable and entity-oriented query language tool is proposed. The 
 program is designed to retrieve and visualize data which can support any 
 Conceptual Data Model. The search engine deals with structured and unstructured 
 data, for a sole patient from a caregiver perspective, and for a number of 
 patients (e.g. epidemiology). Several types of queries on a test database 
 containing 2,000 anonymized patients EHRs (i.e. approximately 200,000 records) 
 were tested. These queries were able to accurately treat symbolic, textual, 
 numerical and chronological data.
",,,,
28423796,Personalized Guideline-Based Treatment Recommendations Using Natural Language Processing Techniques,"Becker M, Böckmann B.",Stud Health Technol Inform. 2017;235:271-275.,Becker M,Stud Health Technol Inform,2017,2017-04-21,,,,"Clinical guidelines and clinical pathways are accepted and proven instruments 
 for quality assurance and process optimization. Today, electronic representation 
 of clinical guidelines exists as unstructured text, but is not well-integrated 
 with patient-specific information from electronic health records. Consequently, 
 generic content of the clinical guidelines is accessible, but it is not possible 
 to visualize the position of the patient on the clinical pathway, decision 
 support cannot be provided by personalized guidelines for the next treatment 
 step. The Systematized Nomenclature of Medicine - Clinical Terms (SNOMED CT) 
 provides common reference terminology as well as the semantic link for combining 
 the pathways and the patient-specific information. This paper proposes a 
 model-based approach to support the development of guideline-compliant pathways 
 combined with patient-specific structured and unstructured information using 
 SNOMED CT. To identify SNOMED CT concepts, a software was developed to extract 
 SNOMED CT codes out of structured and unstructured German data to map these with 
 clinical pathways annotated in accordance with the systematized nomenclature.
",,,,
28423780,Development and Evaluation of a Case-Based Retrieval Service,"Pasche E, Chinali M, Gobeill J, Ruch P.",Stud Health Technol Inform. 2017;235:186-190.,Pasche E,Stud Health Technol Inform,2017,2017-04-21,,,,"Identifying similar patients might greatly facilitate the treatment of a given 
 patient, enabling to observe the response and outcome to a particular treatment. 
 Case-based retrieval services dealing with natural language processing are of 
 major importance to deal with the significant amount of unstructured clinical 
 data. In this paper, we present the development and evaluation of a case-based 
 retrieval (CBR) service tested on a collection of Italian pediatric cardiology 
 cases. Cases are indexed and a search engine is proposed. Search 
 functionalities, such as interactive MeSH normalization and relevance feedback, 
 are proposed. While the qualitative evaluation aims to provide feedback and 
 recommendations, the quantitative evaluation enables to estimate the precision 
 of the system. In more than half of the cases and for up to two thirds of them, 
 the system is able to suggest a similar episode of care at first rank. With an 
 improvement of the feedback relevance strategy, we can expect an improvement of 
 the precision. The CBR can be expanded to multilingual EHR and other fields.
",,,,
29295117,Development and Validation of Various Phenotyping Algorithms for Diabetes Mellitus Using Data from Electronic Health Records,"Esteban S, Rodríguez Tablado M, Peper F, Mahumud YS, Ricci RI, Kopitowski K, Terrasa S.",Stud Health Technol Inform. 2017;245:366-369.,Esteban S,Stud Health Technol Inform,2017,2018-01-04,,,,"Precision medicine requires extremely large samples. Electronic health records 
 (EHR) are thought to be a cost-effective source of data for that purpose. 
 Phenotyping algorithms help reduce classification errors, making EHR a more 
 reliable source of information for research. Four algorithm development 
 strategies for classifying patients according to their diabetes status 
 (diabetics; non-diabetics; inconclusive) were tested (one codes-only algorithm; 
 one boolean algorithm, four statistical learning algorithms and six stacked 
 generalization meta-learners). The best performing algorithms within each 
 strategy were tested on the validation set. The stacked generalization algorithm 
 yielded the highest Kappa coefficient value in the validation set (0.95 95% CI 
 0.91, 0.98). The implementation of these algorithms allows for the exploitation 
 of data from thousands of patients accurately, greatly reducing the costs of 
 constructing retrospective cohorts for research.
",,,,
29295366,Identifying Patients' Smoking Status from Electronic Dental Records Data,"Patel J, Siddiqui Z, Krishnan A, Thyvalikakath T.",Stud Health Technol Inform. 2017;245:1281.,Patel J,Stud Health Technol Inform,2017,2018-01-04,,,,"Smoking is a significant risk factor for initiation and progression of oral 
 diseases. A patient's current smoking status and tobacco dependency can aid 
 clinical decision making and treatment planning. The free-text nature of this 
 data limits accessibility causing obstacles during the time of care and research 
 utility. No studies exist on extracting patient's smoking status automatically 
 from the Electronic Dental Record. This study reports the development and 
 evaluation of an NLP system for this purpose.
",,,,
28186006,What We Can Learn from Amazon for Clinical Decision Support Systems,"Abid S, Keshavjee K, Karim A, Guergachi A.",Stud Health Technol Inform. 2017;234:1-5.,Abid S,Stud Health Technol Inform,2017,2017-02-11,,,,"Health care continue to lag behind other industries, such as retail and 
 financial services, in the use of decision-support-like tools. Amazon is 
 particularly prolific in the use of advanced predictive and prescriptive 
 analytics to assist its customers to purchase more, while increasing 
 satisfaction, retention, repeat-purchases and loyalty. How can we do the same in 
 health care? In this paper, we explore various elements of the Amazon website 
 and Amazon's data science and big data practices to gather inspiration for 
 re-designing clinical decision support in the health care sector. For each 
 Amazon element we identified, we present one or more clinical applications to 
 help us better understand where Amazon's.
",,,,
29295346,Classifying Clinical Notes with Pain Assessment,"Fodeh SJ, Finch D, Bouayad L, Luther S, Kerns RD, Brandt C.",Stud Health Technol Inform. 2017;245:1261.,Fodeh SJ,Stud Health Technol Inform,2017,2018-01-04,,,,"Pain is a significant public health problem, affecting an estimated 100 million 
 Americans. Evidence has highlighted that patients with chronic pain often suffer 
 from deficits in pain care quality (PCQ). Efforts to improve PCQ hinge on the 
 identification of reliable PCQ indicators such as pain assessment. In this 
 study, we developed a classifier that leverages narratives in clinical notes to 
 derive indicators of pain assessment for patients with chronic pain.
",,,,
28423783,Automated Diagnosis Coding with Combined Text Representations,"Berndorfer S, Henriksson A.",Stud Health Technol Inform. 2017;235:201-205.,Berndorfer S,Stud Health Technol Inform,2017,2017-04-21,,,,"Automated diagnosis coding can be provided efficiently by learning predictive 
 models from historical data; however, discriminating between thousands of codes 
 while allowing a variable number of codes to be assigned is extremely difficult. 
 Here, we explore various text representations and classification models for 
 assigning ICD-9 codes to discharge summaries in MIMIC-III. It is shown that the 
 relative effectiveness of the investigated representations depends on the 
 frequency of the diagnosis code under consideration and that the best 
 performance is obtained by combining models built using different 
 representations.
",,,,
29295112,Classification of Clinical Research Study Eligibility Criteria to Support Multi-Stage Cohort Identification Using Clinical Data Repositories,"Cimino JJ, Lancaster WJ, Wyatt MC.",Stud Health Technol Inform. 2017;245:341-345.,Cimino JJ,Stud Health Technol Inform,2017,2018-01-04,,,,"One of the challenges to using electronic health record (EHR) repositories for 
 research is the difficulty mapping study subject eligibility criteria to the 
 query capabilities of the repository. We sought to characterize criteria as 
 ""easy"" (searchable in a typical repository), ""hard"" (requiring manual review of 
 the record data), and ""impossible"" (not typically available in EHR 
 repositories). We obtained 292 criteria from 20 studies available from Clinical 
 Trials.gov and rated them according to our three types, plus a fourth ""mixed"" 
 type. We had good agreement among three independent reviewers and chose 274 
 criteria that were characterized by single types for further analysis. The 
 resulting analysis showed typical features of criteria that do and don't map to 
 repositories. We propose that these features be used to guide researchers in 
 specifying eligibility criteria to improve development of enrollment workflow, 
 including the definition of EHR repository queries for self-service or 
 analyst-mediated retrievals.
",,,,
29295131,"The Impact of ""Possible Patients"" on Phenotyping Algorithms: Electronic Phenotype Algorithms Can Only Be Reproduced by Sharing Detailed Annotation Criteria","Kagawa R, Kawazoe Y, Shinohara E, Imai T, Ohe K.",Stud Health Technol Inform. 2017;245:432-436.,Kagawa R,Stud Health Technol Inform,2017,2018-01-04,,,,"Phenotyping is an automated technique for identifying patients diagnosed with a 
 particular disease based on electronic health records (EHRs). To evaluate 
 phenotyping algorithms, which should be reproducible, the annotation of EHRs as 
 a gold standard is critical. However, we have found that the different types of 
 EHRs cannot be definitively annotated into CASEs or CONTROLs. The influence of 
 such ""possible patients"" on phenotyping algorithms is unknown. To assess these 
 issues, for four chronic diseases, we annotated EHRs by using information not 
 directly referring to the diseases and developed two types of phenotyping 
 algorithms for each disease. We confirmed that each disease included different 
 types of possible patients. The performance of phenotyping algorithms differed 
 depending on whether possible patients were considered as CASEs, and this was 
 independent of the type of algorithms. Our results indicate that researchers 
 must share annotation criteria for classifying the possible patients to 
 reproduce phenotyping algorithms.
",,,,
29295174,Applying Risk Models on Patients with Unknown Predictor Values: An Incremental Learning Approach,"Xu E, Li X, Mei J, Zhao S, Hu G, Xia E, Liu H, Xie G, Xu M, Li X.",Stud Health Technol Inform. 2017;245:639-643.,Xu E,Stud Health Technol Inform,2017,2018-01-04,,,,"In clinical practice, many patients may have unknown or missing values for some 
 predictors, causing that the developed risk models cannot be directly applied on 
 these patients. In this paper, we propose an incremental learning approach to 
 apply a developed risk model on new patients with unknown predictor values, 
 which imputes a patient's unknown values based on his/her k-nearest neighbors 
 (k-NN) from the incremental population. We perform a real world case study by 
 developing a risk prediction model of stroke for patients with Type 2 diabetes 
 mellitus from EHR data, and incrementally applying the risk model on a sequence 
 of new patients. The experimental results show that our risk prediction model of 
 stroke has good prediction performance. And the k-nearest neighbors based 
 incremental learning approach for data imputation can gradually increase the 
 prediction performance when the model is applied on new patients.
",,,,
29295370,Using Human Phenotype Ontology for Phenotypic Analysis of Clinical Notes,"Shen F, Wang L, Liu H.",Stud Health Technol Inform. 2017;245:1285.,Shen F,Stud Health Technol Inform,2017,2018-01-04,,,,"Phenotypes are defined as observable characteristics of organisms. To facilitate 
 the translation between genotype and phenotype, Human Phenotype Ontology (HPO) 
 was developed as a semantically computable standardized vocabulary to capture 
 phenotypic abnormalities found in human. In this study, we investigated the use 
 of HPO to annotate phenotypic information in clinical domain by leveraging a 
 corpus of 12.8 million clinical notes created from 2010 to 2015 for 729 thousand 
 patients at Mayo Clinic Rochester campus.
",,,,
28423803,Business Rules to Improve Secondary Data Use of Electronic Healthcare Systems,"Blaisure J, Ceusters W.",Stud Health Technol Inform. 2017;235:303-307.,Blaisure J,Stud Health Technol Inform,2017,2017-04-21,,,,"The 'fit for purpose' paradigm used for data quality assessment in electronic 
 healthcare record (EHR) systems is not so fit when assessed in the light of 
 secondary data use. An analysis of the difficulties encountered in trying to use 
 existing EHR data for cohort identification for prospective clinical trials and 
 retrograde data analytics, revealed the root causes to fall in three categories: 
 (1) issues in workflow and data registration, (2) preventable inadequacies in 
 software configuration and personalization and (3) software development issues 
 on the side of the vendor. By reviewing secondary data use requirements and 
 formulating value adding business rules, development and data collection 
 practices can be steered towards greater value in secondary data consumption.
",,,,
29295223,Shiny FHIR: An Integrated Framework Leveraging Shiny R and HL7 FHIR to Empower Standards-Based Clinical Data Applications,"Hong N, Prodduturi N, Wang C, Jiang G.",Stud Health Technol Inform. 2017;245:868-872.,Hong N,Stud Health Technol Inform,2017,2018-01-04,PMC5939961,NIHMS961586,,"In this study, we describe our efforts in building a clinical statistics and 
 analysis application platform using an emerging clinical data standard, HL7 
 FHIR, and an open source web application framework, Shiny. We designed two 
 primary workflows that integrate a series of R packages to enable both 
 patient-centered and cohort-based interactive analyses. We leveraged Shiny with 
 R to develop interactive interfaces on FHIR-based data and used ovarian cancer 
 study datasets as a use case to implement a prototype. Specifically, we 
 implemented patient index, patient-centered data report and analysis, and cohort 
 analysis. The evaluation of our study was performed by testing the adaptability 
 of the framework on two public FHIR servers. We identify common research 
 requirements and current outstanding issues, and discuss future enhancement work 
 of the current studies. Overall, our study demonstrated that it is feasible to 
 use Shiny for implementing interactive analysis on FHIR-based standardized 
 clinical data.
",,,,
29295315,Connecting PHRs and EHRs for a Sustainable National Health System,"Hovenga E, Grain H.",Stud Health Technol Inform. 2017;245:1228.,Hovenga E,Stud Health Technol Inform,2017,2018-01-04,,,,"An EHR for integrated care (IEHR) is defined by the International Organization 
 for Standardization (ISO) [1]: ""…a repository of information regarding the 
 health status of a subject of care, in computer processable form, stored and 
 transmitted securely, and accessible by multiple authorised users, having a 
 standardized or commonly agreed logical information model that is independent of 
 EHR systems and whose primary purpose is the support of continuing, efficient 
 and quality integrated health care. It contains information which is 
 retrospective, concurrent and prospective."" We need to differentiate between 
 EMR/EHR and the lifelong PHR in terms of type of data storage, sharing and use 
 [2-3].
",,,,
29295056,Patient Portal Adoption Rates: A Systematic Literature Review and Meta-Analysis,"Fraccaro P, Vigo M, Balatsoukas P, Buchan IE, Peek N, van der Veer SN.",Stud Health Technol Inform. 2017;245:79-83.,Fraccaro P,Stud Health Technol Inform,2017,2018-01-04,,,,"Despite the increasing availability of online patient portals that provide 
 access to electronic health records, little is known about their adoption by 
 patients. We systematically reviewed the literature to investigate adoption of 
 patient portals across studies. We searched MEDLINE and Scopus to identify 
 relevant papers. We included 40 studies: 24 were controlled experiments, with 
 prospective data collection in an actively recruited population; 16 were 
 real-world experiments, with adoption being evaluated retrospectively after 
 system deployment in clinical practice. Our meta-analysis showed an overall mean 
 adoption rate of 52% (95% Confidence Interval [CI], 42 to 62%). Rates differed 
 markedly between study types: controlled experiments yielded a mean adoption 
 rate of 71% (95% CI 64 to 79%), compared to 23% (95% CI, 13 to 33%) in 
 real-world experiments. This difference was confirmed in a meta-regression 
 analysis of the influence of study characteristics on adoption rates. Our 
 findings suggest that adoption rates reported in controlled studies do not 
 reflect those in everyday clinical practice. Until we understand how to 
 effectively increase adoption, patient portals are unlikely to consistently lead 
 to improvements in care processes and health outcomes.
",,,,
28809201,Secondary Use of EHR: Interpreting Clinician Inter-Rater Reliability Through Qualitative Assessment,"Mullin S, Anand E, Sinha S, Song B, Zhao J, Elkin PL.",Stud Health Technol Inform. 2017;241:165-172.,Mullin S,Stud Health Technol Inform,2017,2017-08-16,PMC5698262,NIHMS918239,,"In a retrospective secondary-use EHR study identifying a cohort of Non-Valvular 
 Atrial Fibrillation (NVAF) patients, chart abstraction was done by two sets of 
 clinicians to create a gold standard for risk measures CHA2DS2-VASc and 
 HAS-BLED. Inter-rater reliability between each set of clinicians for NVAF and 
 the outcomes of interest were variable, ranging from extremely low agreement to 
 high agreement. To assess the chart abstraction process, a focus group and a 
 survey was conducted. Survey findings revealed patterns of difficulty in 
 assessing certain items dealing with temporality and social data. The focus 
 group raised issues on the quality and completeness of EHR data, including 
 missing encounters, truncated notes, and low granularity. It also raised the 
 issue of the usability of the data system, the Clinical Data Viewer, which did 
 not mirror a live EHR and made it difficult to record outcomes. Finally, the 
 focus group found it was difficult to infer certain outcomes, like severity, 
 from the provided data. These factors produced differences in clinician rated 
 outcomes.
",,,,
30147065,De-Identification of German Medical Admission Notes,"Richter-Pechanski P, Riezler S, Dieterich C.",Stud Health Technol Inform. 2018;253:165-169.,Richter-Pechanski P,Stud Health Technol Inform,2018,2018-08-28,,,,"Medical texts are a vast resource for medical and computational research. In 
 contrast to newswire or wikipedia texts medical texts need to be de-identified 
 before making them accessible to a wider NLP research community. We created a 
 prototype for German medical text de-identification and named entity recognition 
 using a three-step approach. First, we used well known rule-based models based 
 on regular expressions and gazetteers, second we used a spelling variant 
 detector based on Levenshtein distance, exploiting the fact that the medical 
 texts contain semi-structured headers including sensible personal data, and 
 third we trained a named entity recognition model on out of domain data to add 
 statistical capabilities to our prototype. Using a baseline based on regular 
 expressions and gazetteers we could improve F2-score from 78% to 85% for 
 de-identification. Our prototype is a first step for further research on German 
 medical text de-identification and could show that using spelling variant 
 detection and out of domain trained statistical models can improve 
 de-identification performance significantly.
",,,,
29968609,Structuring Clinical Decision Support Rules for Drug Safety Using Natural Language Processing,"Despotou G, Korkontzelos I, Matragkas N, Bilici E, Arvanitis TN.",Stud Health Technol Inform. 2018;251:89-92.,Despotou G,Stud Health Technol Inform,2018,2018-07-04,,,,"Drug safety is an important aspect in healthcare, resulting in a number of 
 inadvertent events, which may harm the patients. IT based Clinical Decision 
 Support (CDS), integrated in electronic-prescription or Electronic Health 
 Records (EHR) systems, can provide a means for checking prescriptions for 
 errors. This requires expressing prescription guidelines in a way that can be 
 interpreted by IT systems. The paper uses Natural Language Processing (NLP), to 
 interpret drug guidelines by the UK NICE BNF offered in free text. The employed 
 NLP component, MetaMap, identifies the concepts in the instructions and 
 interprets their semantic meaning. The UMLS semantic types that correspond to 
 these concepts are then processed, in order to understand the concepts that are 
 needed to be implemented in software engineering for a CDS engine.
",,,,
29726425,EHR Text Categorization for Enhanced Patient-Based Document Navigation,"Kreuzthaler M, Pfeifer B, Vera Ramos JA, Kramer D, Grogger V, Bredenfeldt S, Pedevilla M, Krisper P, Schulz S.",Stud Health Technol Inform. 2018;248:100-107.,Kreuzthaler M,Stud Health Technol Inform,2018,2018-05-05,,,,"Patients with multiple disorders usually have long diagnosis lists, constitute 
 by ICD-10 codes together with individual free-text descriptions. These text 
 snippets are produced by overwriting standardized ICD-Code topics by the 
 physicians at the point of care. They provide highly compact expert descriptions 
 within a 50-character long text field frequently not assigned to a specific 
 ICD-10 code. The high redundancy of these lists would benefit from content-based 
 categorization within different hospital-based application scenarios. This work 
 demonstrates how to accurately group diagnosis lists via a combination of 
 natural language processing and hierarchical clustering with an overall 
 F-measure value of 0.87. In addition, it compresses the initial diagnosis list 
 up to 89%. The manuscript discusses pitfall and challenges as well as the 
 potential of a large-scale approach for tackling this problem.
",,,,
29677933,Using Machine Learning Approaches for Emergency Room Visit Prediction Based on Electronic Health Record Data,"Qiao Z, Sun N, Li X, Xia E, Zhao S, Qin Y.",Stud Health Technol Inform. 2018;247:111-115.,Qiao Z,Stud Health Technol Inform,2018,2018-04-22,,,,"Emergency room(ER) visit prediction, especially whether visit ER or not and ER 
 visit count, is crucial for hospitals to reasonably adapt resource allocation 
 and` for patients to know future health state. Some existing studies have 
 explored to use machine learning methods especially kinds of general linear 
 model to settle down the task. But, in the clinical problems, there exist 
 complex correlation between targets and features. Generally, liner model is 
 difficult to model complex correlation to make better prediction. Hence, in this 
 paper, we propose to use two non-linear models to settle the problem, which are 
 XGBoost and Recurrent Neural Network. Experimental results show both methods 
 have better performance.
",,,,
29968650,Evaluating the Impact of Incorrect Diabetes Coding on the Performance of Multivariable Prediction Models,"Jauk S, Kramer D, Schulz S, Leodolter W.",Stud Health Technol Inform. 2018;251:249-252.,Jauk S,Stud Health Technol Inform,2018,2018-07-04,,,,"The use of electronic health records for risk prediction models requires a 
 sufficient quality of input data to ensure patient safety. The aim of our study 
 was to evaluate the influence of incorrect administrative diabetes coding on the 
 performance of a risk prediction model for delirium, as diabetes is known to be 
 one of the most relevant variables for delirium prediction. We used four data 
 sets varying in their correctness and completeness of diabetes coding as input 
 for different machine learning algorithms. Although there was a higher 
 prevalence of diabetes in delirium patients, the model performance parameters 
 did not vary between the data sets. Hence, there was no significant impact of 
 incorrect diabetes coding on the performance for our model predicting delirium.
",,,,
31156092,Extraction from Medical Records,"Dudchenko A, Dudchenko P, Ganzinger M, Kopanitsa G.",Stud Health Technol Inform. 2019;261:62-67.,Dudchenko A,Stud Health Technol Inform,2019,2019-06-04,,,,"Despite using electronic medical records, free narrative text is still widely 
 used for medical records. Such text cannot be analyzed by statistical tools and 
 be proceed by decision support systems. To make data from texts available for 
 such tasks a supervised machine learning algorithms might be successfully 
 applied. In this work, we develop and compare a prototype of a medical data 
 extraction system based on different artificial neuron networks architectures to 
 process free medical texts in Russian language. The best F-score (0.9763) 
 achieved on a combination of CNN prediction model and large pre-trained word2vec 
 model. The very close result (0.9741) has shown by the MLP model with the same 
 embedding.
",,,,
30741241,Cancer Phenotype Development: A Literature Review,"Wang P, Garza M, Zozus M.",Stud Health Technol Inform. 2019;257:468-472.,Wang P,Stud Health Technol Inform,2019,2019-02-12,,,,"EHR-based, computable phenotypes can be leveraged by healthcare organizations 
 and researchers to improve the cohort identification process. The ability to 
 identify patient cohorts using aspects of care and outcomes based on clinical 
 characteristics or diagnostic conditions and/or risk factors presents 
 opportunities to researchers targeting specific populations for drug development 
 and disease interventions. The objective of this review was to summarize the 
 literature describing the development and use of phenotypes for cohort 
 identification of cancer patients. A survey of the literature indexed in PubMed 
 was performed to identify studies using EHR-based phenotypes for use in cancer 
 studies. Specific search criteria were formulated by leveraging a phenotype 
 identification guideline developed by the Phenotypes, Data Standards, and Data 
 Quality Core of the NIH Health Care Systems Research Collaboratory. The final 
 set of articles was examined further to identify 1) the cancer of interest and 
 2) the different approaches used for phenotype development, validation and 
 implementation. The articles reviewed were specific to breast cancer, colorectal 
 cancer, ovarian cancer, and lung cancer. The approaches taken for phenotype 
 development and validation varied slightly among the relevant publications. Four 
 studies relied on chart review, three utilized machine learning techniques, one 
 took an ontological approach, and one utilized natural language processing 
 (NLP).
",,,,
31437986,Improving Adherence to Clinical Pathways Through Natural Language Processing on Electronic Medical Records,"Cruz NP, Canales L, Muñoz JG, Pérez B, Arnott I.",Stud Health Technol Inform. 2019 Aug 21;264:561-565. doi: 10.3233/SHTI190285.,Cruz NP,Stud Health Technol Inform,2019,2019-08-24,,,10.3233/SHTI190285,"This paper presents a pioneering and practical experience in the development and 
 implementation of a clinical decision support system (CDSS) based on natural 
 language processing (NLP) and artificial intelligence (AI) techniques. Our CDSS 
 notifies primary care physicians in real time about recommendations regarding 
 the healthcare process. This is, to the best of our knowledge, the first 
 real-time CDSS implemented in the Spanish National Health System. We achieved 
 adherence rate improvements in eight out of 18 practices. Moreover, the 
 provider's feedback was very positive, describing the solution as fast, useful, 
 and unintrusive. Our CDSS reduced clinical variability and revealed the 
 usefulness of NLP and AI techniques for the evaluation and improvement of health 
 care.
",,,,
31483261,Deep Learning Approaches Outperform Conventional Strategies in De-Identification of German Medical Reports,"Richter-Pechanski P, Amr A, Katus HA, Dieterich C.",Stud Health Technol Inform. 2019 Sep 3;267:101-109. doi: 10.3233/SHTI190813.,Richter-Pechanski P,Stud Health Technol Inform,2019,2019-09-05,,,10.3233/SHTI190813,"One of the major obstacles for research on German medical reports is the lack of 
 de-identified medical corpora. Previous de-identification tasks focused on 
 non-German medical texts, which raised the demand for an in-depth evaluation of 
 de-identification methods on German medical texts. Because of remarkable 
 advancements in natural language processing using supervised machine learning 
 methods on limited training data, we evaluated them for the first time on German 
 medical reports using our annotated data set consisting of 113 medical reports 
 from the cardiology domain. We applied state-of-the-art deep learning methods 
 using pre-trained models as input to a bidirectional LSTM network and 
 well-established conditional random fields for de-identification of German 
 medical reports. We performed an extensive evaluation for de-identification and 
 multiclass named entity recognition. Using rule based and out of domain machine 
 learning methods as a baseline, the conditional random field improved F2-score 
 from 70 to 93% for de-identification, the neural approach reached 96% in 
 F2-score while keeping balanced precision and recall rates. These results show, 
 that state-of-the-art machine learning methods can play a crucial role in 
 de-identification of German medical reports.
",,,,
31437921,Combining Structured and Unstructured Data for Predicting Risk of Readmission for Heart Failure Patients,"Mahajan SM, Ghani R.",Stud Health Technol Inform. 2019 Aug 21;264:238-242. doi: 10.3233/SHTI190219.,Mahajan SM,Stud Health Technol Inform,2019,2019-08-24,,,10.3233/SHTI190219,"Researchers have studied many models for predicting the risk of readmission for 
 heart failure over the last decade. Most models have used a parametric 
 statistical approach while a few have ventured into using machine learning 
 methods such as statistical natural language processing. We created three 
 predictive models by combining these two techniques for the cohort of 1,629 
 patients from six hosptials using structured data along with their 136,963 
 clinical notes till their index admission, stored in the EMR system over five 
 years. The AUCs for structured and combined models were very close (0.6494 and 
 0.6447) and that for the unstructured model was 0.5219. The clinical impact of 
 the models using decision curve analysis showed that, at a threshold predicted 
 probability of 0.20, the combined model offered 15%, 30%, and 70% net benefit 
 over its individual counterparts, treat-all, and treat-none strategy 
 respectively.
",,,,
31437957,Annotating Temporal Relations to Determine the Onset of Psychosis Symptoms,"Viani N, Kam J, Yin L, Verma S, Stewart R, Patel R, Velupillai S.",Stud Health Technol Inform. 2019 Aug 21;264:418-422. doi: 10.3233/SHTI190255.,Viani N,Stud Health Technol Inform,2019,2019-08-24,,,10.3233/SHTI190255,"For patients with a diagnosis of schizophrenia, determining symptom onset is 
 crucial for timely and successful intervention. In mental health records, 
 information about early symptoms is often documented only in free text, and thus 
 needs to be extracted to support clinical research. To achieve this, natural 
 language processing (NLP) methods can be used. Development and evaluation of NLP 
 systems requires manually annotated corpora. We present a corpus of mental 
 health records annotated with temporal relations for psychosis symptoms. We 
 propose a methodology for document selection and manual annotation to detect 
 symptom onset information, and develop an annotated corpus. To assess the 
 utility of the created corpus, we propose a pilot NLP system. To the best of our 
 knowledge, this is the first temporally-annotated corpus tailored to a specific 
 clinical use-case.
",,,,
31438086,Extracting Alcohol and Substance Abuse Status from Clinical Notes: The Added Value of Nursing Data,"Topaz M, Murga L, Bar-Bachar O, Cato K, Collins S.",Stud Health Technol Inform. 2019 Aug 21;264:1056-1060. doi: 10.3233/SHTI190386.,Topaz M,Stud Health Technol Inform,2019,2019-08-24,,,10.3233/SHTI190386,"We applied an open source natural language processing (NLP) system ""NimbleMiner"" 
 to identify clinical notes with mentions of alcohol and substance abuse. 
 NimbleMiner allows users to rapidly discover clinical vocabularies (using word 
 embedding model) and then implement machine learning for text classification. We 
 used a large inpatient dataset with over 50,000 intensive care unit admissions 
 (MIMIC II). Clinical notes included physician-written discharge summaries (n = 
 51,201) and nursing notes (n = 412,343). We first used physician-written 
 discharge summaries to train the system's algorithm and then added nursing notes 
 to the physician-written discharge summaries and evaluated algorithms prediction 
 accuracy. Adding nursing notes to the physician-written discharge summaries 
 resulted in almost two-fold vocabulary expansion. NimbleMiner slightly 
 outperformed other state-of-the-art NLP systems (average F-score = .84), while 
 requiring significantly less time for the algorithms development.: Our findings 
 underline the importance of nursing data for the analysis of electronic patient 
 records.
",,,,
31437914,Annotating German Clinical Documents for De-Identification,"Kolditz T, Lohr C, Hellrich J, Modersohn L, Betz B, Kiehntopf M, Hahn U.",Stud Health Technol Inform. 2019 Aug 21;264:203-207. doi: 10.3233/SHTI190212.,Kolditz T,Stud Health Technol Inform,2019,2019-08-24,,,10.3233/SHTI190212,"We devised annotation guidelines for the de-identification of German clinical 
 documents and assembled a corpus of 1,106 discharge summaries and transfer 
 letters with 44K annotated protected health information (PHI) items. After three 
 iteration rounds, our annotation team finally reached an inter-annotator 
 agreement of 0.96 on the instance level and 0.97 on the token level of 
 annotation (averaged pair-wise F1 score). To establish a baseline for automatic 
 de-identification on our corpus, we trained a recurrent neural network (RNN) and 
 achieved F1 scores greater than 0.9 on most major PHI categories.
",,,,
31438230,Do You Need Embeddings Trained on a Massive Specialized Corpus for Your Clinical Natural Language Processing Task?,"Neuraz A, Looten V, Rance B, Daniel N, Garcelon N, Llanos LC, Burgun A, Rosset S.",Stud Health Technol Inform. 2019 Aug 21;264:1558-1559. doi: 10.3233/SHTI190533.,Neuraz A,Stud Health Technol Inform,2019,2019-08-24,,,10.3233/SHTI190533,"We explore the impact of data source on word representations for different NLP 
 tasks in the clinical domain in French (natural language understanding and text 
 classification). We compared word embeddings (Fasttext) and language models 
 (ELMo), learned either on the general domain (Wikipedia) or on specialized data 
 (electronic health records, EHR). The best results were obtained with ELMo 
 representations learned on EHR data for one of the two tasks(+7% and +8% of gain 
 in F1-score).
",,,,
31438083,Developing Customizable Cancer Information Extraction Modules for Pathology Reports Using CLAMP,"Soysal E, Warner JL, Wang J, Jiang M, Harvey K, Jain SK, Dong X, Song HY, Siddhanamatha H, Wang L, Dai Q, Chen Q, Du X, Tao C, Yang P, Denny JC, Liu H, Xu H.",Stud Health Technol Inform. 2019 Aug 21;264:1041-1045. doi: 10.3233/SHTI190383.,Soysal E,Stud Health Technol Inform,2019,2019-08-24,PMC7359882,NIHMS1603895,10.3233/SHTI190383,"Natural language processing (NLP) technologies have been successfully applied to 
 cancer research by enabling automated phenotypic information extraction from 
 narratives in electronic health records (EHRs) such as pathology reports; 
 however, developing customized NLP solutions requires substantial effort. To 
 facilitate the adoption of NLP in cancer research, we have developed a set of 
 customizable modules for extracting comprehensive types of cancer-related 
 information in pathology reports (e.g., tumor size, tumor stage, and 
 biomarkers), by leveraging the existing CLAMP system, which provides 
 user-friendly interfaces for building customized NLP solutions for individual 
 needs. Evaluation using annotated data at Vanderbilt University Medical Center 
 showed that CLAMP-Cancer could extract diverse types of cancer information with 
 good F-measures (0.80-0.98). We then applied CLAMP-Cancer to an information 
 extraction task at Mayo Clinic and showed that we can quickly build a customized 
 NLP system with comparable performance with an existing system at Mayo Clinic. 
 CLAMP-Cancer is freely available for academic use.
",,,,
31437952,Identifying Diabetes in Clinical Notes in Hebrew: A Novel Text Classification Approach Based on Word Embedding,"Topaz M, Murga L, Grossman C, Daliyot D, Jacobson S, Rozendorn N, Zimlichman E, Furie N.",Stud Health Technol Inform. 2019 Aug 21;264:393-397. doi: 10.3233/SHTI190250.,Topaz M,Stud Health Technol Inform,2019,2019-08-24,,,10.3233/SHTI190250,"NimbleMiner is a word embedding-based, language-agnostic natural language 
 processing system for clinical text classification. Previously, NimbleMiner was 
 applied in English and this study applied NimbleMiner on a large sample of 
 inpatient clinical notes in Hebrew to identify instances of diabetes mellitus. 
 The study data included 521,278 clinical notes (one admission and one discharge 
 note per patient) for 268,664 hospital admissions to medical-surgical units of a 
 large hospital in Israel. NimbleMiner achieved overall good performance (F-score 
 =.94) when tested on a gold standard human annotated dataset of 800 clinical 
 notes. We found 15% more patients with diabetes mentioned in the clinical notes 
 compared with diagnoses data. Our findings about underreporting of diabetes in 
 the coded diagnoses data highlight the urgent need for tools and algorithms that 
 will help busy providers identify a range of useful information, like having a 
 diabetes.
",,,,
31438217,Using Enriched Samples for Semi-Automated Vocabulary Expansion to Identify Rare Events in Clinical Text: Sexual Orientation as a Use Case,"Lynch KE, Alba P, Viernes B, DuVall SL.",Stud Health Technol Inform. 2019 Aug 21;264:1532-1533. doi: 10.3233/SHTI190520.,Lynch KE,Stud Health Technol Inform,2019,2019-08-24,,,10.3233/SHTI190520,"We demonstrate the utility of concept lexicon expansion and evaluation using 
 enriched samples of patients and documents with sexual orientation as a use case 
 for rare event detection in electronic medical records. Using this approach, we 
 found 7 additional words and 21 misspellings beyond our initial set of five seed 
 words. We can use the expanded vocabulary to further develop a full natural 
 language processing system to identify instances where sexual orientation is 
 documented.
",,,,
31438179,Identifying Patients with Significant Problems Related to Social Determinants of Health with Natural Language Processing,"Dorr D, Bejan CA, Pizzimenti C, Singh S, Storer M, Quinones A.",Stud Health Technol Inform. 2019 Aug 21;264:1456-1457. doi: 10.3233/SHTI190482.,Dorr D,Stud Health Technol Inform,2019,2019-08-24,,,10.3233/SHTI190482,"Social and behavioral factors influence health but are infrequently recorded in 
 electronic health records (EHRs). Here, we demonstrate that psychosocial vital 
 signs can be extracted from EHR data. We processed structured and unstructured 
 EHR data using expert-driven queries and Natural Language Processing (NLP), 
 validating results through structured annotation. We found that although these 
 vital signs are present in EHRs, with 681 structured entries identified for 
 psychosocial concepts, NLP identified a nearly 90-fold increase in patients.
",,,,
30741243,Data Profiling in Support of Entity Resolution of Multi-Institutional EHR Data,"Wang P, Pullen D, Garza M, Walden A, Zozus M.",Stud Health Technol Inform. 2019;257:479-483.,Wang P,Stud Health Technol Inform,2019,2019-02-12,PMC6692113,NIHMS1044280,,"Information Quality (IQ) is a core tenant of contemporary data management 
 practices. Across many disciplines and industries, it has become a necessary 
 process to improve value and reduce liability in data driven processes. 
 Information quality is a multifaceted discipline with many degrees of complexity 
 in implementation, especially in healthcare. Data profiling is one of the 
 simpler tasks that an organization can perform to understand and monitor the 
 intrinsic quality of its data. This case study demonstrates the application of 
 core concepts of data profiling to entity resolution of multi-institutional 
 Electronic Health Record (EHR) data. We discuss the benefits of using data 
 profiling to better understand quality issues and their impact on entity 
 resolution and how data profiling might be augmented to increase utility to 
 clinical data.
",,,,
31437894,"Evaluating the Impact of Text Duplications on a Corpus of More than 600,000 Clinical Narratives in a French Hospital","Digan W, Wack M, Looten V, Neuraz A, Burgun A, Rance B.",Stud Health Technol Inform. 2019 Aug 21;264:103-107. doi: 10.3233/SHTI190192.,Digan W,Stud Health Technol Inform,2019,2019-08-24,,,10.3233/SHTI190192,"A significant part of medical knowledge is stored as unstructured free text. 
 However, clinical narratives are known to contain duplicated sections due to 
 clinicians' copy/paste parts of a former report into a new one. In this study, 
 we aim at evaluating the duplications found within patient records in more than 
 650,000 French clinical narratives. We adapted a method to identify efficiently 
 duplicated zones in a reasonable time. We evaluated the potential impact of 
 duplications in two use cases: the presence of (i) treatments and/or (ii) 
 relative dates. We identified an average rate of duplication of 33%. We found 
 that 20% of the document contained drugs mentioned only in duplicated zones and 
 that 1.45% of the document contained mentions of relative dates in duplicated 
 zone, that could potentially lead to erroneous interpretation. We suggest the 
 systematic identification and annotation of duplicated zones in clinical 
 narratives for information extraction and temporal-oriented tasks.
",,,,
31437956,Identifying Suicidal Adolescents from Mental Health Records Using Natural Language Processing,"Velupillai S, Epstein S, Bittar A, Stephenson T, Dutta R, Downs J.",Stud Health Technol Inform. 2019 Aug 21;264:413-417. doi: 10.3233/SHTI190254.,Velupillai S,Stud Health Technol Inform,2019,2019-08-24,,,10.3233/SHTI190254,"Suicidal ideation is a risk factor for self-harm, completed suicide and can be 
 indicative of mental health issues. Adolescents are a particularly vulnerable 
 group, but few studies have examined suicidal behaviour prevalence in large 
 cohorts. Electronic Health Records (EHRs) are a rich source of secondary health 
 care data that could be used to estimate prevalence. Most EHR documentation 
 related to suicide risk is written in free text, thus requiring Natural Language 
 Processing (NLP) approaches. We adapted and evaluated a simple lexicon- and 
 rule-based NLP approach to identify suicidal adolescents from a large EHR 
 database. We developed a comprehensive manually annotated EHR reference standard 
 and assessed NLP performance at both document and patient level on data from 200 
 patients ( 5000 documents). We achieved promising results (>80% f1 score at both 
 document and patient level). Simple NLP approaches can be successfully used to 
 identify patients who exhibit suicidal risk behaviour, and our proposed approach 
 could be useful for other populations and settings.
",,,,
30942761,Analysis of Primary Care Computerised Medical Records with Deep Learning,"de Lusignan S, Smith N, Livina V, Yonova I, Webb R, Thomas SA.",Stud Health Technol Inform. 2019;258:249-250.,de Lusignan S,Stud Health Technol Inform,2019,2019-04-04,,,,"The analysis of primary care data plays an important role in understanding 
 health at an individual and population level. Currently the utilization of 
 computerized medical records is low due to the complexities, heterogeneities and 
 veracity associated with these data. We present a deep learning methodology that 
 clusters 11,000 records in an unsupervised manner identifying non-linear 
 patterns in the data. This provides a useful tool for visualization as well as 
 identify features driving the formation of clusters. Further analysis reveal the 
 features that differentiate sub-groups that can aid clinical decision making. 
 Our results uncover subsets that contain the highest proportion of missing data, 
 specifically Episode type, as well as the sources that provide the most complete 
 data.
",,,,
31438212,Machine Learning Approaches for Extracting Stage from Pathology Reports in Prostate Cancer,"Lenain R, Seneviratne MG, Bozkurt S, Blayney DW, Brooks JD, Hernandez-Boussard T.",Stud Health Technol Inform. 2019 Aug 21;264:1522-1523. doi: 10.3233/SHTI190515.,Lenain R,Stud Health Technol Inform,2019,2019-08-24,PMC6712988,NIHMS1047784,10.3233/SHTI190515,"Clinical and pathological stage are defining parameters in oncology, which 
 direct a patient's treatment options and prognosis. Pathology reports contain a 
 wealth of staging information that is not stored in structured form in most 
 electronic health records (EHRs). Therefore, we evaluated three supervised 
 machine learning methods (Support Vector Machine, Decision Trees, Gradient 
 Boosting) to classify free-text pathology reports for prostate cancer into T, N 
 and M stage groups.
",,,,
31349300,An Information Extraction Algorithm for Detecting Adverse Events in Neurosurgery Using Documents Written in a Natural Rich-in-Morphology Language,"Danilov G, Shifrin M, Strunina U, Pronkina T, Potapov A.",Stud Health Technol Inform. 2019 Jul 4;262:194-197. doi: 10.3233/SHTI190051.,Danilov G,Stud Health Technol Inform,2019,2019-07-27,,,10.3233/SHTI190051,"Rich-in-morphology language, such as Russian, present a challenge for extraction 
 of professional medical information. In this paper, we report on our solution to 
 identify adverse events (complications) in neurosurgery based on natural 
 language processing and professional medical judgment. The algorithm we proposed 
 is easily implemented and feasible in a broad spectrum of clinical studies.
",,,,
31437925,Knowledge Learning Symbiosis for Developing Risk Prediction Models from Regional EHR Repositories,"Mei J, Xia E.",Stud Health Technol Inform. 2019 Aug 21;264:258-262. doi: 10.3233/SHTI190223.,Mei J,Stud Health Technol Inform,2019,2019-08-24,,,10.3233/SHTI190223,"Secondary use of regional EHR data suffers several problems, including data 
 selection bias and limited data size caused by data incompleteness. Here, we 
 propose knowledge learning symbiosis (KLS) as a framework to incorporate domain 
 knowledge to address the problems and make better secondary use of EHR data. 
 Under the framework, we introduce three main categories of methods: knowledge 
 injection to input features, objective functions, and output labels, where 
 knowledge-enhanced neural network (KENN) was first introduced to inject 
 knowledge into objective functions. A case study was conducted to build a 
 cardiovascular disease risk prediction model on the type 2 diabetes patient 
 cohort using regional EHR repositories. By incorporating a well-established 
 knowledge risk model as domain knowledge under our KLS framework, we increased 
 risk prediction performance both on small and biased data, where KENN showed the 
 best performance among all methods.
",,,,
31437930,Impact of De-Identification on Clinical Text Classification Using Traditional and Deep Learning Classifiers,"Obeid JS, Heider PM, Weeda ER, Matuskowitz AJ, Carr CM, Gagnon K, Crawford T, Meystre SM.",Stud Health Technol Inform. 2019 Aug 21;264:283-287. doi: 10.3233/SHTI190228.,Obeid JS,Stud Health Technol Inform,2019,2019-08-24,PMC6779034,NIHMS1051218,10.3233/SHTI190228,"Clinical text de-identification enables collaborative research while protecting 
 patient privacy and confidentiality; however, concerns persist about the 
 reduction in the utility of the de-identified text for information extraction 
 and machine learning tasks. In the context of a deep learning experiment to 
 detect altered mental status in emergency department provider notes, we tested 
 several classifiers on clinical notes in their original form and on their 
 automatically de-identified counterpart. We tested both traditional bag-of-words 
 based machine learning models as well as word-embedding based deep learning 
 models. We evaluated the models on 1,113 history of present illness notes. A 
 total of 1,795 protected health information tokens were replaced in the 
 de-identification process across all notes. The deep learning models had the 
 best performance with accuracies of 95% on both original and de-identified 
 notes. However, there was no significant difference in the performance of any of 
 the models on the original vs. the de-identified notes.
",,,,
31438275,Responses of Staff Nurses to an EMR-Based Clinical Decision Support Service for Predicting Inpatient Fall Risk,"Cho I, Jin I.",Stud Health Technol Inform. 2019 Aug 21;264:1650-1651. doi: 10.3233/SHTI190579.,Cho I,Stud Health Technol Inform,2019,2019-08-24,,,10.3233/SHTI190579,"Wide spread of electronic medical records provide an opportunity to use 
 time-variant longuitudinal data near real time. Hospital nurses would benefit 
 greatly from the ability to use such data to predict adverse event risks of 
 individual patient. We have developed an clinical decision support service to 
 predict inpatient falling using machine learning and clinical big data approach. 
 This study reports the initial responses of nurses to the service in an acute 
 care setting.
",,,,
31437900,Interactive Machine Learning for Laboratory Data Integration,"Fillmore N, Do N, Brophy M, Zimolzak A.",Stud Health Technol Inform. 2019 Aug 21;264:133-137. doi: 10.3233/SHTI190198.,Fillmore N,Stud Health Technol Inform,2019,2019-08-24,,,10.3233/SHTI190198,"Laboratory data collected in the electronic health record as part of routine 
 care can be used in secondary research. For example, the US Department of 
 Veterans Affairs maintains a data warehouse covering over 20 million individuals 
 and 6.6 billion lab tests. However, data aggregation in such a data warehouse 
 can be difficult. In order to retrieve all or nearly all of one type of lab 
 result with a high degree of precision, we perform clinical concept 
 adjudication, which is the process of an expert determining which database 
 records correspond to a target clinical concept. In this work, we develop an 
 interactive machine learning tool to ""extend the reach"" of expert laboratory 
 test adjudicators. Our tool provides access to automatic laboratory 
 classification in a user-facing front end that covers all steps in an 
 adjudication workflow, in order to lower barriers to collaboration, increase 
 transparency of adjudication, and to promote efficiencies and data reuse.
",,,,
31438200,The Development of an Electronic Phenotyping Algorithm for Identifying Rhabdomyolysis Patients in the MID-NET Database,"Izukura R, Kandabashi T, Wakata Y, Nojiri C, Nohara Y, Yamashita T, Takada A, Park J, Uyama Y, Nakashima N.",Stud Health Technol Inform. 2019 Aug 21;264:1498-1499. doi: 10.3233/SHTI190503.,Izukura R,Stud Health Technol Inform,2019,2019-08-24,,,10.3233/SHTI190503,"We aimed to develop rhabdomyolysis (RB) phenotyping algorithms using machine 
 learning techniques and to create subphenotyping algorithms to identify RB 
 patients who lack RB diagnosis. Two pattern algorithms, one with a focus on 
 improving predictive value and one focused on improving sensitivity, were 
 finally created and had a high area under the curve value of 0.846. Although we 
 were unable to create subphenotyping algorithms, an attempt to detect unknown RB 
 patients is important for epidemiological studies.
",,,,
30942728,Prediction of Postoperative Hospital Stay with Deep Learning Based on 101 654 Operative Reports in Neurosurgery,"Danilov G, Kotik K, Shifrin M, Strunina U, Pronkina T, Potapov A.",Stud Health Technol Inform. 2019;258:125-129.,Danilov G,Stud Health Technol Inform,2019,2019-04-04,,,,"Electronic Health Records (EHRs) conceal a hidden knowledge that could be mined 
 with data science tools. This is relevant for N.N. Burdenko Neurosurgery Center 
 taking the advantage of a large EHRs archive collected for a period between 2000 
 and 2017. This study was aimed at testing the informativeness of neurosurgical 
 operative reports for predicting the duration of postoperative stay in a 
 hospital using deep learning techniques. The recurrent neuronal networks (GRU) 
 were applied to the word-embedded texts in our experiments. The mean absolute 
 error of prediction in 90% of cases was 2.8 days. These results demonstrate the 
 potential utility of narrative medical texts as a substrate for decision support 
 technologies in neurosurgery.
",,,,
31437912,A Study of Medical Problem Extraction for Better Disease Management,"Kim Y, Meystre SM.",Stud Health Technol Inform. 2019 Aug 21;264:193-197. doi: 10.3233/SHTI190210.,Kim Y,Stud Health Technol Inform,2019,2019-08-24,,,10.3233/SHTI190210,"This study focuses on the extraction of medical problems mentioned in electric 
 health records to support disease management. We experimented with a variety of 
 information extraction methods based on rules, on knowledge bases, and on 
 machine learning, and combined them in an ensemble method approach. A new 
 dataset drawn from cancer patient medical records at the University of Utah 
 Healthcare was manually annotated for all mentions of a selection of the most 
 frequent medical problems in this institution. Our experimental results show 
 that a medical knowledge base can improve shallow and deep learning-based 
 sequence labeling methods. The voting ensemble method combining information 
 extraction models outperformed individual models and yielded more precise 
 extraction of medical problems. As an example of applications benefiting from 
 acurate medical problems extraction, we compared document-level cancer type 
 classifiers and demonstrated that using only medical concepts yielded more 
 accurate classification than using all the words in a clinical note.
",,,,
31437902,Learning to Identify Severe Maternal Morbidity from Electronic Health Records,"Gao C, Osmundson S, Yan X, Edwards DV, Malin BA, Chen Y.",Stud Health Technol Inform. 2019 Aug 21;264:143-147. doi: 10.3233/SHTI190200.,Gao C,Stud Health Technol Inform,2019,2019-08-24,PMC7337420,NIHMS1602913,10.3233/SHTI190200,"Severe maternal morbidity (SMM) is broadly defined as significant complications 
 in pregnancy that have an adverse effect on women's health. Identifying women 
 who experience SMM and reviewing their obstetric care can assist healthcare 
 organizations in recognizing risk factors and best practices for management. 
 Various definitions of SMM have been posited, but there is no consensus. 
 Existing definitions are further limited in that they 1) are often rooted in 
 existing clinical knowledge (which is problematic as many risk factors remain 
 unknown), leading to poor positive predictive performance (PPV), and 2) have 
 limited scalability as they often require substantial chart review. Thus, in 
 this paper, a machine learning framework was introduced to automatically 
 identify SMM and relevant risk factors from electronic health records (EHRs). We 
 evaluated this framework with EHR data from 45,858 deliveries at a large 
 academic medical center. The framework outperformed a state-of-the-art model 
 from the U.S. Centers for Disease Control and Prevention (AUC of 0.94 vs. 0.80). 
 Specially, it improved upon PPV by 59% (CDC: 0.22 vs. our model: 0.35). In the 
 process, we revealed several novel SMM indicators, including disorders of fluid 
 or electrolytes, systemic inflammatory response syndrome, and acidosis.
",,,,
31483269,Design and Concept of the SMITH Phenotyping Pipeline,"Meineke FA, Stäubert S, Löbe M, Uciteli A, Löffler M.",Stud Health Technol Inform. 2019 Sep 3;267:164-172. doi: 10.3233/SHTI190821.,Meineke FA,Stud Health Technol Inform,2019,2019-09-05,,,10.3233/SHTI190821,"Phenotyping means the determination of clinical relevant phenotypes, e.g. by 
 classification or calculation based on EHR data. Within the German Medical 
 Informatics Initiative, the SMITH consortium is working on the implementation of 
 a phenotyping pipeline. to extract, structure and normalize information from the 
 EHR data of the hospital information systems of the participating sites; to 
 automatically apply complex algorithms and models and to enrich the data within 
 the research data warehouses of the distributed data integration centers with 
 the computed results. Here we present the overall picture and essential building 
 blocks and workflows of this concept.
",,,,
31437880,Carnival: A Graph-Based Data Integration and Query Tool to Support Patient Cohort Generation for Clinical Research,"Birtwell D, Williams H, Pyeritz R, Damrauer S, Mowery DL.",Stud Health Technol Inform. 2019 Aug 21;264:35-39. doi: 10.3233/SHTI190178.,Birtwell D,Stud Health Technol Inform,2019,2019-08-24,,,10.3233/SHTI190178,"Clinical research studies often leverage various heterogeneous data sources 
 including patient electronic health record, online survey, and genomic data. We 
 introduce a graph-based, data integration and query tool called Carnival. We 
 demonstrate its powerful ability to unify data from these disparate data sources 
 to create datasets for two studies: prevalence and incidence case/control 
 matches for coronary artery disease and controls for Marfan syndrome. We 
 conclude with future directions for Carnival development.
",,,,
31438052,Using Electronic Health Records and Machine Learning to Predict Postpartum Depression,"Wang S, Pathak J, Zhang Y.",Stud Health Technol Inform. 2019 Aug 21;264:888-892. doi: 10.3233/SHTI190351.,Wang S,Stud Health Technol Inform,2019,2019-08-24,,,10.3233/SHTI190351,"Postpartum depression (PPD) is one of the most frequent maternal morbidities 
 after delivery with serious implications. Currently, there is a lack of 
 effective screening strategies and high-quality clinical trials. The ability to 
 leverage a large amount of detailed patient data from electronic health records 
 (EHRs) to predict PPD could enable the implementation of effective clinical 
 decision support interventions. To develop a PPD prediction model, using EHRs 
 from Weill Cornell Medicine and NewYork-Presbyterian Hospital between 2015-17, 
 9,980 episodes of pregnancy were identified. Six machine learning algorithms, 
 including L2-regularized Logistic Regression, Support Vector Machine, Decision 
 Tree, Naïve Bayes, XGBoost, and Random forest were constructed. Our model's best 
 prediction performance achieved an AUC of 0.79. Race, obesity, anxiety, 
 depression, different types of pain, antidepressants, and anti-inflammatory 
 drugs during pregnancy were among the significant predictors. Our results 
 suggest a potential for applying machine learning to EHR data to predict PPD and 
 inform healthcare delivery.
",,,,
31118336,Is Regular Re-Training of a Predictive Delirium Model Necessary After Deployment in Routine Care?,"Veeranki SPK, Kramer D, Hayn D, Jauk S, Eggerth A, Quehenberger F, Leodolter W, Schreier G.",Stud Health Technol Inform. 2019;260:186-191.,Veeranki SPK,Stud Health Technol Inform,2019,2019-05-24,,,,"Adoption of electronic medical records in hospitals generates a large amount of 
 data. Health care professionals can easily lose their sight on the important 
 insights of the patients' clinical and medical history. Although machine 
 learning algorithms have already proved their significance in healthcare 
 research, remains a challenge translation and dissemination of fully automated 
 prediction algorithms from research to decision support at the point of care. In 
 this paper, we address the effect of changes in the characteristics of data over 
 time on the performance of deployed models for the use case of predicting 
 delirium in hospitalised patients. We have analysed the stability of models 
 trained with subsets of data from one single year (2012, 2013...2016, 
 respectively), and tested the models with data from 2017. Our results show that 
 in the case of delirium prediction, the models were stable over time, indicating 
 that re-training the models is not necessary e.g. once per year might be more 
 than sufficient.
",,,,
31118320,Information Adapted Machine Learning Models for Prediction in Clinical Workflow,"Jauk S, Kramer D, Quehenberger F, Veeranki SPK, Hayn D, Schreier G, Leodolter W.",Stud Health Technol Inform. 2019;260:65-72.,Jauk S,Stud Health Technol Inform,2019,2019-05-24,,,,"BACKGROUND: In a database of electronic health records, the amount of available 
 information varies widely between patients. In a real-time prediction scenario, 
 a machine learning model may receive limited information for some patients.
 OBJECTIVES: Our aim was to evaluate the influence of missing data on real-time 
 prediction of delirium, and detect changes in prediction performance when 
 training separate models for patients with missing data.
 METHODS: We compared a model trained specifically on data with missing values to 
 the currently implemented model predicting delirium. Also, we simulated five 
 test data sets with different amount of missing data and compared the prediction 
 results to the prediction on complete data set when using the same model.
 RESULTS: For patients with missing laboratory and nursing assessment data, a 
 model trained especially for this scenario performed significantly better than 
 the implemented model. The combination of procedure data and demographic data 
 achieved the closest results to a prediction with a complete data set.
 CONCLUSION: An ongoing evaluation of real-time prediction is indispensable. 
 Additional models adapted to the information available might improve prediction 
 performance.
",,,,
31438036,Evaluating the Scope of Clinical Electronic Messaging to Coordinate Care in a Breast Cancer Cohort,"Steitz BD, Levy MA.",Stud Health Technol Inform. 2019 Aug 21;264:808-812. doi: 10.3233/SHTI190335.,Steitz BD,Stud Health Technol Inform,2019,2019-08-24,,,10.3233/SHTI190335,"Care coordination has received attention as an opportunity to improve healthcare 
 delivery. Current work to quantify provider coordination has primarily relied on 
 identifying shared patients, but neglects to understand communication patterns. 
 We applied social network analysis to electronic health record (EHR) secure 
 messaging data to compare networks of providers who share patients and networks 
 of providers who communicate about patients. We studied 2175 stage I-III breast 
 cancer patients who received outpatient treatment from 1758 providers at a large 
 academic medical center in the southeastern United States. Patients in our 
 cohort were involved in 94324 appointments and were the subject of 307144 
 message threads. We found that 9.9% of provider-provider pairs that shared 
 patients were mutually involved in electronic communication about their 
 patients. EHR data sources can be used to evaluate provider communication across 
 a clinical enterprise, which can help identify opportunities to improve 
 collaboration and reduce provider burnout.
",,,,
31349307,Phenotyping UK Electronic Health Records from 15 Million Individuals for Precision Medicine: The CALIBER Resource,"Denaxas S, Gonzalez-Izquierdo A, Fitzpatrick N, Direk K, Hemingway H.",Stud Health Technol Inform. 2019 Jul 4;262:220-223. doi: 10.3233/SHTI190058.,Denaxas S,Stud Health Technol Inform,2019,2019-07-27,,,10.3233/SHTI190058,"Electronic health records (EHR) are increasingly being used for observational 
 research at scale. In the UK, we have established the CALIBER research resource 
 which utilizes national primary and hospital EHR data sources and enables 
 researchers to create and validate longitudinal disease phenotypes at scale. In 
 this work, we will describe the core components of the resource and provide 
 results from three exemplar research studies on high-resolution epidemiology, 
 disease risk prediction and subtype discovery which demonstrate both the 
 opportunities and challenges of using EHR for research.
",,,,
30942709,Complementing Medical Records with Precalculated Data Items to Facilitate Decision Support and Phenotyping,"Kraus S, Prokosch HU.",Stud Health Technol Inform. 2019;258:36-40.,Kraus S,Stud Health Technol Inform,2019,2019-04-04,,,,"The Arden Syntax is a standard for clinical decision support functions in the 
 form of Medical Logic Modules (MLMs). While the data type system of the early 
 versions was limited to flat lists, later versions introduced an object type, 
 supporting complex data structures, even up to entire electronic medical records 
 (EMRs). Such objects are static insofar as their structure cannot be modified at 
 MLM runtime. University Hospital Erlangen uses an experimental Arden Syntax 
 version termed PLAIN, which provides an integrated mapper for arbitrary data 
 structures, including entire EMRs. To facilitate knowledge encoding and reduce 
 MLM complexity, we searched for a way to complement patient records with 
 precalculated data items. We modified the object data type in two ways. The 
 first was to include a statement for the explicit creation of new attributes; 
 the second was to implicitly create an attribute whenever a value is assigned to 
 a previously non-existing attribute. As a proof of concept, we complemented the 
 ventilation section of every accessed EMR with a patient-individual 
 recommendation for the expiratory tidal volume. A means to extend the structure 
 of an object at runtime provides several advantages. The precalculated data 
 items need no longer be calculated by the MLMs themselves, which reduces 
 complexity and facilitates code maintenance. This might be beneficial not only 
 for clinical decision support, but also with respect to the use of Arden Syntax 
 language constructs for phenotyping queries, as well as with respect to the 
 frequently required preprocessing of EMR data.
",,,,
31437881,Text Classification to Inform Suicide Risk Assessment in Electronic Health Records,"Bittar A, Velupillai S, Roberts A, Dutta R.",Stud Health Technol Inform. 2019 Aug 21;264:40-44. doi: 10.3233/SHTI190179.,Bittar A,Stud Health Technol Inform,2019,2019-08-24,,,10.3233/SHTI190179,"Assessing a patient's risk of an impending suicide attempt has been hampered by 
 limited information about dynamic factors that change rapidly in the days 
 leading up to an attempt. The storage of patient data in electronic health 
 records (EHRs) has facilitated population-level risk assessment studies using 
 machine learning techniques. Until recently, most such work has used only 
 structured EHR data and excluded the unstructured text of clinical notes. In 
 this article, we describe our experiments on suicide risk assessment, modelling 
 the problem as a classification task. Given the wealth of text data in mental 
 health EHRs, we aimed to assess the impact of using this data in distinguishing 
 periods prior to a suicide attempt from those not preceding such an attempt. We 
 compare three different feature sets, one structured and two text-based, and 
 show that inclusion of text features significantly improves classification 
 accuracy in suicide risk assessment.
",,,,
31437920,Transforming Two Decades of ePR Data to OMOP CDM for Clinical Research,"Lima DM, Rodrigues-Jr JF, Traina AJM, Pires FA, Gutierrez MA.",Stud Health Technol Inform. 2019 Aug 21;264:233-237. doi: 10.3233/SHTI190218.,Lima DM,Stud Health Technol Inform,2019,2019-08-24,,,10.3233/SHTI190218,"This paper presents the extract-transform-and-load (ETL) process from the 
 Electronic Patient Records (ePR) at the Heart Institute (InCor) to the OMOP 
 Common Data Model (CDM) format. We describe the initial database 
 characterization, relational source mappings, selection filters, data 
 transformations and patient de-identification using the open-source OHDSI tools 
 and SQL scripts. We evaluate the resulting InCor-CDM database by recreating the 
 same patient cohort from a previous reference study (over the original data 
 source) and comparing the cohorts' descriptive statistics and inclusion reports. 
 The results exhibit that up to 91% of the reference patients were retrieved by 
 our method from the ePR through InCor-CDM, with AUC=0.938. The results indicate 
 that the method that we employed was able to produce a new database that was 
 both consistent with the original data and in accordance to the OMOP CDM 
 standard.
",,,,
31438326,The Impact of Hybridisation on the Accuracy of Fluid Balance Documentation: A Retrospective Cross-Sectional Analysis of Intravenous Fluid Order and Administration Documentation Using a Partly-Computerized Medical Record in an Australian Tertiary Teaching Hospital,"Perotti S, Ritchie A.",Stud Health Technol Inform. 2019 Aug 21;264:1751-1752. doi: 10.3233/SHTI190630.,Perotti S,Stud Health Technol Inform,2019,2019-08-24,,,10.3233/SHTI190630,"Inaccurate intravenous (IV) fluid documentation remains a major cause of 
 fluid-related adverse health outcomes in hospitals. In this study, we 
 characterise the integrity and documentation completeness of a hybrid 
 paper-computer documentation system for IV fluids and explore how 
 inconsistencies within it are associated with adverse patient health outcomes. 
 We highlight key areas of weakness specific to IV fluid documentation that need 
 to be addressed in moving to a fully computerised system in the future.
",,,,
30741192,Using Digital Health to Support Best Practices: Impact of MRI Ordering Guidelines Embedded Within an Electronic Referral Solution,"Huebner LA, Mohammed HT, Menezes R.",Stud Health Technol Inform. 2019;257:176-183.,Huebner LA,Stud Health Technol Inform,2019,2019-02-12,,,,"BACKGROUND: Between 2003 and 2012, the number of MRIs performed in Canada more 
 than doubled to 1.7 million [1]. According to a 2010 Health Council of Canada 
 report nearly 30% of MRIs were inappropriately ordered [2]. The use of 
 diagnostic imaging referral guidelines has been shown to improve the 
 appropriateness of imaging orders [3, 4].
 OBJECTIVES: To identify the number of unnecessary pre-consult MRIs ordered for 
 patients with knee pain. As well, the impact that new evidence-based clinical 
 decision support (DS) guidelines embedded within the referral form has had on 
 the number of unnecessary MRIs was investigated.
 METHODS: This study employed a retrospective design approach. Charts of all knee 
 pain patients over the age of 55 who were referred for consultation to the 5 
 participating orthopedic surgeons during the study period were reviewed by three 
 medical students.
 RESULTS: 270 patient charts were included in this study. MRI was ordered for 60 
 patients with only 56.7% having had a prior X-ray. Of the 60 ordered MRIs, 50 
 (84%) were considered inappropriate, while only 10 (16%) were appropriate. Our 
 results were compared to previous results of a quality improvement study 
 implemented at the same clinic. A substantial reduction of 12% in the number of 
 pre-consult MRIs and a 5% increase in the number of ordered X-rays before 
 consultation was demonstrated.
 CONCLUSION: This work highlights the impact of including DS tools within an 
 electronic referral form to support clinical best practices.
",,,,
32570397,Machine Learning for Automatic Encoding of French Electronic Medical Records: Is More Data Better?,"Gobeill J, Ruch P, Meyer R.",Stud Health Technol Inform. 2020 Jun 16;270:312-316. doi: 10.3233/SHTI200173.,Gobeill J,Stud Health Technol Inform,2020,2020-06-24,,,10.3233/SHTI200173,"The encoding of Electronic Medical Records is a complex and time-consuming task. 
 We report on a machine learning model for proposing diagnoses and procedures 
 codes, from a large realistic dataset of 245 000 electronic medical records at 
 the University Hospitals of Geneva. Our study particularly focuses on the impact 
 of training data quantity on the model's performances. We show that the 
 performances of the models do not increase while encoded instances from previous 
 years are exploited for learning data. Furthermore, supervised models are shown 
 to be highly perishable: we show a potential drop in performances of around -10% 
 per year. Consequently, great and constant care must be exercised for designing 
 and updating the content of such knowledge bases exploited by machine learning.
",,,,
32570367,Detection of Muscle Weakness in Medical Texts Using Natural Language Processing,"Danilov G, Shifrin M, Strunina Y, Kotik K, Tsukanova T, Pronkina T, Ishankulov T, Makashova E, Kosyrkova A, Potapov A.",Stud Health Technol Inform. 2020 Jun 16;270:163-167. doi: 10.3233/SHTI200143.,Danilov G,Stud Health Technol Inform,2020,2020-06-24,,,10.3233/SHTI200143,"Identifying adverse events in clinical documents is demanded in retrospective 
 clinical research and prospective monitoring of treatment safety and 
 cost-effectiveness. We proposed and evaluated a few methods of semi-automated 
 muscle weakness detection in preoperative clinical notes for a larger project on 
 predicting paresis by images. The combination of semi-expert and machine 
 learning methods demonstrated maximized sensitivity = 0.860 and specificity = 
 0.919, and largest AUC = 0.943 with a 95% CI [0.874; 0.991], outperforming each 
 method used individually. Our approaches are expected to be effective for 
 autoshaping a well- verified training dataset for supervised machine learning.
",,,,
32570364,De-Identifying Swedish EHR Text Using Public Resources in the General Domain,"Chomutare T, Yigzaw KY, Budrionis A, Makhlysheva A, Godtliebsen F, Dalianis H.",Stud Health Technol Inform. 2020 Jun 16;270:148-152. doi: 10.3233/SHTI200140.,Chomutare T,Stud Health Technol Inform,2020,2020-06-24,,,10.3233/SHTI200140,"Sensitive data is normally required to develop rule-based or train machine 
 learning-based models for de-identifying electronic health record (EHR) clinical 
 notes; and this presents important problems for patient privacy. In this study, 
 we add non-sensitive public datasets to EHR training data; (i) scientific 
 medical text and (ii) Wikipedia word vectors. The data, all in Swedish, is used 
 to train a deep learning model using recurrent neural networks. Tests on 
 pseudonymized Swedish EHR clinical notes showed improved precision and recall 
 from 55.62% and 80.02% with the base EHR embedding layer, to 85.01% and 87.15% 
 when Wikipedia word vectors are added. These results suggest that non-sensitive 
 text from the general domain can be used to train robust models for 
 de-identifying Swedish clinical text; and this could be useful in cases where 
 the data is both sensitive and in low-resource languages.
",,,,
32604599,Semiautomated Approach for Muscle Weakness Detection in Clinical Texts,"Danilov G, Shifrin M, Strunina Y, Kotik K, Tsukanova T, Pronkina T, Ishankulov T, Makashova E, Kosyrkova A, Melchenko S, Zagidullin T, Potapov A.",Stud Health Technol Inform. 2020 Jun 26;272:55-58. doi: 10.3233/SHTI200492.,Danilov G,Stud Health Technol Inform,2020,2020-07-02,,,10.3233/SHTI200492,"The automated detection of adverse events in medical records might be a 
 cost-effective solution for patient safety management or pharmacovigilance. Our 
 group proposed an information extraction algorithm (IEA) for detecting adverse 
 events in neurosurgery using documents written in a natural rich-in-morphology 
 language. In this paper, we challenge to optimize and evaluate its performance 
 for the detection of any extremity muscle weakness in clinical texts. Our 
 algorithm shows the accuracy of 0.96 and ROC AUC = 0.96 and might be easily 
 implemented in other medical domains.
",,,,
32570343,Automated Spelling Correction for Clinical Text Mining in Russian,"Balabaeva K, Funkner A, Kovalchuk S.",Stud Health Technol Inform. 2020 Jun 16;270:43-47. doi: 10.3233/SHTI200119.,Balabaeva K,Stud Health Technol Inform,2020,2020-06-24,,,10.3233/SHTI200119,"The main goal of this paper is to develop a spell checker module for clinical 
 text in Russian. The described approach combines string distance measure 
 algorithms with technics of machine learning embedding methods. Our overall 
 precision is 0.86, lexical precision - 0.975 and error precision is 0.74. We 
 develop spell checker as a part of medical text mining tool regarding the 
 problems of misspelling, negation, experiencer and temporality detection.
",,,,
32570485,Natural Language Processing for Detecting Medication-Related Notes in Heart Failure Telehealth Patients,"Eggerth A, Kreiner K, Hayn D, Pfeifer B, Pölzl G, Egelseer-Bründl T, Schreier G.",Stud Health Technol Inform. 2020 Jun 16;270:761-765. doi: 10.3233/SHTI200263.,Eggerth A,Stud Health Technol Inform,2020,2020-06-24,,,10.3233/SHTI200263,"Heart Failure is a severe chronic disease of the heart. Telehealth networks 
 implement closed-loop healthcare paradigms for optimal treatment of the 
 patients. For comprehensive documentation of medication treatment, health 
 professionals create free text collaboration notes in addition to structured 
 information. To make this valuable source of information available for adherence 
 analyses, we developed classifiers for automated categorization of notes based 
 on natural language processing, which allows filtering of relevant entries to 
 spare data analysts from tedious manual screening. Furthermore, we identified 
 potential improvements of the queries for structured treatment documentation. 
 For 3,952 notes, the majority of the manually annotated category tags was 
 medication-related. The highest F1-measure of our developed classifiers was 
 0.90. We conclude that our approach is a valuable tool to support adherence 
 research based on datasets containing free-text entries.
",,,,
32570421,The Impact of Specialized Corpora for Word Embeddings in Natural Langage Understanding,"Neuraz A, Rance B, Garcelon N, Llanos LC, Burgun A, Rosset S.",Stud Health Technol Inform. 2020 Jun 16;270:432-436. doi: 10.3233/SHTI200197.,Neuraz A,Stud Health Technol Inform,2020,2020-06-24,,,10.3233/SHTI200197,"Recent studies in the biomedical domain suggest that learning statistical word 
 representations (static or contextualized word embeddings) on large corpora of 
 specialized data improve the results on downstream natural language processing 
 (NLP) tasks. In this paper, we explore the impact of the data source of word 
 representations on a natural language understanding task. We compared embeddings 
 learned with Fasttext (static embedding) and ELMo (contextualized embedding) 
 representations, learned either on the general domain (Wikipedia) or on 
 specialized data (electronic health records, EHR). The best results were 
 obtained with ELMo representations learned on EHR data for the two sub-tasks 
 (+7% and +4% of gain in F1-score). Moreover, ELMo representations were trained 
 with only a fraction of the data used for Fasttext.
",,,,
32570584,Automatic Detection of Vital Signs in Clinical Notes of the Outpatient Settings,"Diaz Maffini M, Aguirre Ojea F, Manzotti M.",Stud Health Technol Inform. 2020 Jun 16;270:1211-1212. doi: 10.3233/SHTI200367.,Diaz Maffini M,Stud Health Technol Inform,2020,2020-06-24,,,10.3233/SHTI200367,"The determination of vital signs is a fundamental aspect of patient care. 
 Electronic health records have a structured format for their registration. It is 
 known that the frequency with which this data is recollected is not 
 representative of reality. To complement the missing data we have created a tool 
 that extract the information regarding blood pressure, heart rate, respiratory 
 rate, height, weight and pain level recorded in free text in the clinical notes 
 of outpatients.
",,,,
32570411,Predicting Postoperative Hospital Stay in Neurosurgery with Recurrent Neural Networks Based on Operative Reports,"Danilov G, Kotik K, Shifrin M, Strunina U, Pronkina T, Potapov A.",Stud Health Technol Inform. 2020 Jun 16;270:382-386. doi: 10.3233/SHTI200187.,Danilov G,Stud Health Technol Inform,2020,2020-06-24,,,10.3233/SHTI200187,"This study aimed to predict the duration of the postoperative in-hospital period 
 in neurosurgery based on unstructured operative reports, natural language 
 processing, and deep learning. The recurrent neuronal network (RNN-GRU) was 
 tuned on the word-embedded reports of primary surgical cases retrieved for the 
 period between 2000 and 2017. A new test dataset obtained for the primary 
 operations performed in 2018-2019 was used to evaluate model performance. The 
 mean absolute error of prediction in the final test was 3.00 days. Our study 
 demonstrated the usability of textual EHRs data for the prediction of 
 postoperative period length in neurosurgery using deep learning.
",,,,
32570403,Negation Detection for Clinical Text Mining in Russian,"Funkner A, Balabaeva K, Kovalchuk S.",Stud Health Technol Inform. 2020 Jun 16;270:342-346. doi: 10.3233/SHTI200179.,Funkner A,Stud Health Technol Inform,2020,2020-06-24,,,10.3233/SHTI200179,"Developing predictive modeling in medicine requires additional features from 
 unstructured clinical texts. In Russia, there are no instruments for natural 
 language processing to cope with problems of medical records. This paper is 
 devoted to a module of negation detection. The corpus-free machine learning 
 method is based on gradient boosting classifier is used to detect whether a 
 disease is denied, not mentioned or presented in the text. The detector 
 classifies negations for five diseases and shows average F-score from 0.81 to 
 0.93. The benefits of negation detection have been demonstrated by predicting 
 the presence of surgery for patients with the acute coronary syndrome.
",,,,
32570609,Development of a Systematic Text Annotation Standard to Extract Social Support Information form Electronic Medical Records,"Volij C, Esteban S.",Stud Health Technol Inform. 2020 Jun 16;270:1261-1262. doi: 10.3233/SHTI200392.,Volij C,Stud Health Technol Inform,2020,2020-06-24,,,10.3233/SHTI200392,"The influence of social relationships on mortality is comparable with that of 
 standard clinical factors. In order to extract this information via supervised 
 NLP algorithms, clinical notes have to be annotated manually. At present we did 
 not find any systematic annotation standards to extract social support. In this 
 work, we developed a systematic text annotation standard to detect social 
 support in couples from electronic medical records.
",,,,
32570354,Clinical History Segment Extraction from Chronic Fatigue Syndrome Assessments to Model Disease Trajectories,"Priou S, Viani N, Vernugopan V, Tytherleigh C, Hassan FA, Dutta R, Chalder T, Velupillai S.",Stud Health Technol Inform. 2020 Jun 16;270:98-102. doi: 10.3233/SHTI200130.,Priou S,Stud Health Technol Inform,2020,2020-06-24,,,10.3233/SHTI200130,"Chronic fatigue syndrome (CFS) is a long-term illness with a wide range of 
 symptoms and condition trajectories. To improve the understanding of these, 
 automated analysis of large amounts of patient data holds promise. Routinely 
 documented assessments are useful for large-scale analysis, however relevant 
 information is mainly in free text. As a first step to extract symptom and 
 condition trajectories, natural language processing (NLP) methods are useful to 
 identify important textual content and relevant information. In this paper, we 
 propose an agnostic NLP method of extracting segments of patients' clinical 
 histories in CFS assessments. Moreover, we present initial results on the 
 advantage of using these segments to quantify and analyse the presence of 
 certain clinically relevant concepts.
",,,,
32570353,Clinical Concept Normalization on Medical Records Using Word Embeddings and Heuristics,"Silva JF, Antunes R, Almeida JR, Matos S.",Stud Health Technol Inform. 2020 Jun 16;270:93-97. doi: 10.3233/SHTI200129.,Silva JF,Stud Health Technol Inform,2020,2020-06-24,,,10.3233/SHTI200129,"Electronic health records contain valuable information on patients' clinical 
 history in the form of free text. Manually analyzing millions of these documents 
 is unfeasible and automatic natural language processing methods are essential 
 for efficiently exploiting these data. Within this, normalization of clinical 
 entities, where the aim is to link entity mentions to reference vocabularies, is 
 of utmost importance to successfully extract knowledge from clinical narratives. 
 In this paper we present sieve-based models combined with heuristics and word 
 embeddings and present results of our participation in the 2019 n2c2 (National 
 NLP Clinical Challenges) shared-task on clinical concept normalization.
",,,,
32570345,Automatic Extraction of Risk Factors for Dialysis Patients from Clinical Notes Using Natural Language Processing Techniques,"Michalopoulos G, Qazi H, Wong A, Butt Z, Chen H.",Stud Health Technol Inform. 2020 Jun 16;270:53-57. doi: 10.3233/SHTI200121.,Michalopoulos G,Stud Health Technol Inform,2020,2020-06-24,,,10.3233/SHTI200121,"Studies have shown that mental health and comorbidities such as dementia, 
 diabetes and cardiovascular diseases are risk factors for dialysis patients. 
 Extracting accurate and timely information associated with these risk factors in 
 the patient health records is not only important for dialysis patient 
 management, but also for real-world evidence generation. We presented HERALD, an 
 natural language processing (NLP) system for extracting information related to 
 risk factors of dialysis patients from free-text progress notes in an electronic 
 dialysis patient management system. By converting semi-structured notes into 
 complete sentences before feeding them into the NLP module, the HERALD system 
 was able achieved 99%, 83% and 80% accuracy in identifying dementia, diabetes 
 and infarction, respectively.
",,,,
33087598,Prediction of a Due Date Based on the Pregnancy History Data Using Machine Learning,"Metsker O, Kopanitsa G, Komlichenko E, Yanushanets M, Bolgova E.",Stud Health Technol Inform. 2020 Sep 4;273:104-108. doi: 10.3233/SHTI200622.,Metsker O,Stud Health Technol Inform,2020,2020-10-22,,,10.3233/SHTI200622,"Prediction of a labor due date is important especially for the pregnancies with 
 high risk of complications where a special treatment is needed. This is 
 especially valid in the countries with multilevel health care institutions like 
 Russia. In Russia medical organizations are distributed into national, regional 
 and municipal levels. Organizations of each level can provide treatment of 
 different types and quality. For example, pregnancies with low risk of 
 complications are routed to the municipal hospitals, moderate risk pregnancies 
 are routed to the reginal and high risk of complications are routed to the 
 hospitals of the national level. In the situation of resource deficiency 
 especially on the national level it is necessary to plan admission date and a 
 treatment team in advance to provide the best possible care. When pregnancy data 
 is not standardized and semantically interoperable, data driven models. We have 
 retrospectively analyzed electronic health records from the perinatal Center of 
 the Almazov perinatal medical center in Saint-Petersburg, Russia. The dataset 
 was exported from the medical information system. It consisted of structured and 
 semi structured data with the total of 73115 lines for 12989 female patients. 
 The proposed due date prediction data-driven model allows a high accuracy 
 prediction to allow proper resource planning. The models are based on the 
 real-world evidence and can be applied with limited amount of predictors.
",,,,
32570602,Detecting Severe Incidents from Electronic Medical Records Using Machine Learning Methods,"Okamoto K, Yamamoto T, Hiragi S, Ohtera S, Sugiyama O, Yamamoto G, Hirose M, Kuroda T.",Stud Health Technol Inform. 2020 Jun 16;270:1247-1248. doi: 10.3233/SHTI200385.,Okamoto K,Stud Health Technol Inform,2020,2020-06-24,,,10.3233/SHTI200385,"The goal of this research was to design a solution to detect non-reported 
 incidents, especially severe incidents. To achieve this goal, we proposed a 
 method to process electronic medical records and automatically extract clinical 
 notes describing severe incidents. To evaluate the proposed method, we 
 implemented a system and used the system. The system successfully detected a 
 non-reported incident to the safety management department.
",,,,
32570599,Deep Learning Approach for the Development of a Novel Predictive Model for Prostate Cancer,"Islam M, Yang HC, Nguyen PA, Wang YH, Poly TN, Li YJ.",Stud Health Technol Inform. 2020 Jun 16;270:1241-1242. doi: 10.3233/SHTI200382.,Islam M,Stud Health Technol Inform,2020,2020-06-24,,,10.3233/SHTI200382,"We developed a deep learning approach for accurate prediction of PCA patients 
 one year earlier with minimal features from electronic health records. The area 
 under the receiver operating curve for prediction of PCA was 0.94. Moreover, the 
 sensitivity and specificity of CNN were 0.87 and 0.88, respectively.
",,,,
32570434,Using Unsupervised Learning to Identify Clinical Subtypes of Alzheimer's Disease in Electronic Health Records,"Alexander N, Alexander DC, Barkhof F, Denaxas S.",Stud Health Technol Inform. 2020 Jun 16;270:499-503. doi: 10.3233/SHTI200210.,Alexander N,Stud Health Technol Inform,2020,2020-06-24,,,10.3233/SHTI200210,"Identifying subtypes of Alzheimer's Disease (AD) can lead towards the creation 
 of personalized interventions and potentially improve outcomes. In this study, 
 we use UK primary care electronic health records (EHR) from the CALIBER resource 
 to identify and characterize clinically-meaningful clusters patients using 
 unsupervised learning approaches of MCA and K-means. We discovered and 
 characterized five clusters with different profiles (mental health, non-typical 
 AD, typical AD, CVD and men with cancer). The mental health cluster had faster 
 rate of progression than all the other clusters making it a target for future 
 research and intervention. Our results demonstrate that unsupervised learning 
 approaches can be utilized on EHR to identify subtypes of heterogeneous 
 conditions.
",,,,
32570505,Machine Learning-Based Identification of Obesity from Positive and Unlabelled Electronic Health Records,"Blanes-Selva V, Tortajada S, Vilar R, Valdivieso B, García-Gómez JM.",Stud Health Technol Inform. 2020 Jun 16;270:864-868. doi: 10.3233/SHTI200284.,Blanes-Selva V,Stud Health Technol Inform,2020,2020-06-24,,,10.3233/SHTI200284,"INTRODUCTION: Prevalence of overweight and obesity are increas- ing in the last 
 decades, and with them, diseases and health conditions such as diabetes, 
 hypertension or cardiovascular diseases. However, hos- pital databases usually 
 do not record such conditions in adults, neither anthropomorfic measures that 
 facilitate their identification.
 METHODS: We implemented a machine learning method based on PU (Positive and 
 Unlabelled) Learning to identify obese patients without a diagnose code of 
 obesity in the health records.
 RESULTS: The algorithm presented a high sensitivity (98%) and predicted that 
 around 18% of the patients without a diagnosis were obese. This result is 
 consistent with the report of the WHO.
",,,,
32578538,Multivariable Risk Prediction of Dysphagia in Hospitalized Patients Using Machine Learning,"Lienhart AM, Kramer D, Jauk S, Gugatschka M, Leodolter W, Schlegl T.",Stud Health Technol Inform. 2020 Jun 23;271:31-38. doi: 10.3233/SHTI200071.,Lienhart AM,Stud Health Technol Inform,2020,2020-06-25,,,10.3233/SHTI200071,"BACKGROUND: Dysphagia is a dysfunction of the swallowing act and is highly 
 prevalent in acute post-stroke patients and patients with chronic neurological 
 diseases. Dysphagia is associated with several potentially life threatening 
 complications. Thus, an early identification and treatment could reduce 
 morbidity and mortality rates.
 OBJECTIVES: The aim of the study was to develop a multivariable model predicting 
 the individual risk of dysphagia in hospitalized patients.
 METHODS: We trained different machine learning algorithms on the electronic 
 health records of over 33,000 patients.
 RESULTS: The tree-based Random Forest Classifier and Adaboost Classifier 
 algorithms achieved an area under the receiver operating characteristic curve of 
 0.94.
 CONCLUSION: The developed models outperformed previously published models 
 predicting dysphagia. In future, an implementation in the clinical workflow is 
 needed to determine the clinical benefit.
",,,,
32570420,Supervised Learning for the ICD-10 Coding of French Clinical Narratives,"Dalloux C, Claveau V, Cuggia M, Bouzillé G, Grabar N.",Stud Health Technol Inform. 2020 Jun 16;270:427-431. doi: 10.3233/SHTI200196.,Dalloux C,Stud Health Technol Inform,2020,2020-06-24,,,10.3233/SHTI200196,"Automatic detection of ICD-10 codes in clinical documents has become a 
 necessity. In this article, after a brief reminder of the existing work, we 
 present a corpus of French clinical narratives annotated with the ICD-10 codes. 
 Then, we propose automatic methods based on neural network approaches for the 
 automatic detection of the ICD-10 codes. The results show that we need 1) more 
 examples per class given the number of classes to assign, and 2) a better 
 word/concept vector representation of documents in order to accurately assign 
 codes.
",,,,
32570391,Introducing New Measures of Inter- and Intra-Rater Agreement to Assess the Reliability of Medical Ground Truth,"Campagner A, Cabitza F.",Stud Health Technol Inform. 2020 Jun 16;270:282-286. doi: 10.3233/SHTI200167.,Campagner A,Stud Health Technol Inform,2020,2020-06-24,,,10.3233/SHTI200167,"In this paper, we present and discuss two new measures of inter- and intra-rater 
 agreement to assess the reliability of the raters, and hence of their labeling, 
 in multi-rater setings, which are common in the production of ground truth for 
 machine learning models. Our proposal is more conservative of other existing 
 agreement measures, as it considers a more articulated notion of agreement by 
 chance, based on an empirical estimation of the precision (or reliability) of 
 the single raters involved. We discuss the measures in light of a realistic 
 annotation tasks that involved 13 expert radiologists in labeling the MRNet 
 dataset.
",,,,
32604585,Unsupervised Machine Learning for the Discovery of Latent Clusters in COVID-19 Patients Using Electronic Health Records,"Cui W, Robins D, Finkelstein J.",Stud Health Technol Inform. 2020 Jun 26;272:1-4. doi: 10.3233/SHTI200478.,Cui W,Stud Health Technol Inform,2020,2020-07-02,,,10.3233/SHTI200478,"The goal of this paper was to apply unsupervised machine learning techniques 
 towards the discovery of latent clusters in COVID-19 patients. Over 6,000 adult 
 patients tested positive for the SARS-CoV-2 infection at the Mount Sinai Health 
 System in New York, USA met the inclusion criteria for analysis. Patients' 
 diagnoses were mapped onto chronicity and one of the 18 body systems, and the 
 optimal number of clusters was determined using K-means algorithm and the elbow 
 method. 4 clusters were identified; the most frequently associated comorbidities 
 involved infectious, respiratory, cardiovascular, endocrine, and genitourinary 
 disorders, as well as socioeconomic factors that influence health status and 
 contact with health services. These results offer a strong direction for future 
 research and more granular analysis.
",,,,
32570402,Near Real Time EHR Data Utilization in a Clinical Study,"Penning ML, Blach C, Walden A, Wang P, Donovan KM, Garza MY, Wang Z, Frund J, Syed S, Syed M, Del Fiol G, Newby LK, Pieper C, Zozus M.",Stud Health Technol Inform. 2020 Jun 16;270:337-341. doi: 10.3233/SHTI200178.,Penning ML,Stud Health Technol Inform,2020,2020-06-24,PMC7898242,NIHMS1670224,10.3233/SHTI200178,"Extraction and use of Electronic Health Record (EHR) data is common in 
 retrospective observational studies. However, electronic extraction and use of 
 EHR data is rare during longitudinal prospective studies. One of the reasons is 
 the amount of processing needed to assess data quality and assure consistency in 
 meaning and format across multiple investigational sites. We report a case study 
 of and lessons learned from acquisition and processing of EHR data in an ongoing 
 basis during a clinical study.
",,,,
32570474,User Requirements Meet Large-Scale EHR Suites: Norwegian Preparations for Epic,"Ellingsen G, Hertzum M.",Stud Health Technol Inform. 2020 Jun 16;270:703-707. doi: 10.3233/SHTI200251.,Ellingsen G,Stud Health Technol Inform,2020,2020-06-24,,,10.3233/SHTI200251,"Electronic health records (EHRs) are becoming the norm in healthcare. Typically, 
 these EHRs are large-scale suite systems. The up-front presence of ready-for-use 
 EHR suites changes the role of user requirements and the conditions for deciding 
 which requirements to include in the final contract. In this paper, we 
 investigate how user requirements are negotiated in the ongoing preparations for 
 the implementation of Epic throughout the region of Central Norway. User 
 requirements shape vendor selection but they are also shaped by the vendors' 
 existing EHRs and by the requirements of the selected vendor's other customers.
",,,,
32570552,Designing a Solution to Manage Electronic Consent for Children,"Leeming G, Thew S, Ainsworth J.",Stud Health Technol Inform. 2020 Jun 16;270:1103-1107. doi: 10.3233/SHTI200333.,Leeming G,Stud Health Technol Inform,2020,2020-06-24,,,10.3233/SHTI200333,"Electronic systems for managing consent do exist but are generally only able to 
 record consent from the research subject directly. Consent for research is also 
 challenging to integrate into many electronic patient record systems. The Born 
 In Bradford study is a large, from birth cohort study in the North of England 
 which requires consent to be recorded by the pregnant mother of a child who will 
 be included in the study from birth. This creates a complex challenge for 
 consent management that has previously been achieved through paper-based 
 processes. As the study begins a new phase with the objective of inviting all 
 new parents within the Bradford region to participate in the study the solution 
 also needs to work with existing maternity systems. This paper considers the 
 specific challenges of converting the often grey rules around consent of 
 children into an electronic system that is transparent and supports the trust of 
 both the family and the clinical and care teams recruiting research subjects 
 into a large cohort study, and describes the user centred design and technical 
 approach taken to resolve it.
",,,,
33227735,Latent COVID-19 Clusters in Patients with Chronic Respiratory Conditions,"Cui W, Cabrera M, Finkelstein J.",Stud Health Technol Inform. 2020 Nov 23;275:32-36. doi: 10.3233/SHTI200689.,Cui W,Stud Health Technol Inform,2020,2020-11-23,,,10.3233/SHTI200689,"The goal of this paper was to apply unsupervised machine learning techniques 
 towards the discovery of latent COVID-19 clusters in patients with chronic lower 
 respiratory diseases (CLRD). Patients who underwent testing for SARS-CoV-2 were 
 identified from electronic medical records. The analytical dataset comprised 
 2,328 CLRD patients of whom 1,029 were tested COVID-19 positive. We used the 
 factor analysis for mixed data method for preprocessing. It performed principle 
 component analysis on numeric values and multiple correspondence analysis on 
 categorical values which helped convert categorical data into numeric. Cluster 
 analysis was an effective means to both distinguish subgroups of CLRD patients 
 with COVID-19 as well as identify patient clusters which were adversely affected 
 by the infection. Age, comorbidity index and race were important factors for 
 cluster separations. Furthermore, diseases of the circulatory system, the 
 nervous system and sense organs, digestive system, genitourinary system, 
 metabolic diseases and immunity disorders were also important criteria in the 
 resulting cluster analyses.
",,,,
32570500,Exploratory Analysis of HIV Status Knowledge and Associated Factors Using Data from Electronic Medical Records,"Burdisso N, Esteban S, Kopitowski KS, Terrasa SA.",Stud Health Technol Inform. 2020 Jun 16;270:838-842. doi: 10.3233/SHTI200279.,Burdisso N,Stud Health Technol Inform,2020,2020-06-24,,,10.3233/SHTI200279,"Despite recommendations for the routine HIV testing of all sexually active 
 individuals, a significant percentage of HIV-positive adults are unaware of 
 their HIV status. Therefore, a number of strategies have been implemented to 
 expand HIV testing, which in turn makes it necessary to develop tools for 
 identifying patients with unknown HIV status. This study presents the results of 
 an external validation of an electronic phenotyping algorithm for identifying 
 HIV status and its application on a retrospective cohort in order to explore 
 temporal trends of HIV knowledge status and associated factors.
",,,,
33227745,Mobile Access and Adoption of the Swedish National Patient Portal,"Hägglund M, Blease C, Scandurra I.",Stud Health Technol Inform. 2020 Nov 23;275:82-86. doi: 10.3233/SHTI200699.,Hägglund M,Stud Health Technol Inform,2020,2020-11-23,,,10.3233/SHTI200699,"Patient portals are used as a means to facilitate communication, performing 
 administrative tasks, or accessing one's health record. In a retrospective 
 analysis of real-world data from the Swedish National Patient Portal 1177.se, we 
 describe the rate of adoption over time, as well as how patterns of device usage 
 have changed over time. In Jan 2013, 53% of all visits were made from a 
 computer, and 38% from a mobile phone. By June 2020, 77% of all visits were made 
 from a mobile phone and only 20% from a computer. These results underline the 
 importance of designing responsive patient portals that allow patients to use 
 any device without losing functionality or usability.
",,,,
32570408,Performances of a Solution to Semi-Automatically Fill eCRF with Data from the Electronic Health Record: Protocol for a Prospective Individual Participant Data Meta-Analysis,"Griffon N, Pereira H, Djadi-Prat J, García MT, Testoni S, Cariou M, Hilbey J, N'Dja A, Navarro G, Gentili N, Nanni O, Raineri M, Chatellier G, Gómez De La Camara A, Lewi M, Sundgren M, Daniel C, Garvey A, Todorovic M, Ammour N.",Stud Health Technol Inform. 2020 Jun 16;270:367-371. doi: 10.3233/SHTI200184.,Griffon N,Stud Health Technol Inform,2020,2020-06-24,,,10.3233/SHTI200184,"Clinical trial data collection still relies on a manual entry from information 
 available in the medical record. This process introduces delay and error risk. 
 Automating data transfer from Electronic Health Record (EHR) to Electronic Data 
 Capture (EDC) system, under investigators' supervision, would gracefully solve 
 these issues. The present paper describes the design of the evaluation of a 
 technology allowing EHR to act as eSource for clinical trials. As part of the 
 EHR2EDC project, for 6 ongoing clinical trials, running at 3 hospitals, a 
 parallel semi-automated data collection using such technology will be conducted 
 focusing on a limited scope of data (demographic data, local laboratory results, 
 concomitant medication and vital signs). The evaluation protocol consists in an 
 individual participant data prospective meta-analysis comparing regular clinical 
 trial data collection to the semi-automated one. The main outcome is the 
 proportion of data correctly entered. Data quality and associated workload for 
 hospital staff will be compared as secondary outcomes. Results should be 
 available in 2020.
",,,,
32570595,Cross-Mapping Study of Nursing Practice Terms from a Brazilian Hospital Database,"Gonçalves LS, Andreatta D, Schamne FK.",Stud Health Technol Inform. 2020 Jun 16;270:1233-1234. doi: 10.3233/SHTI200378.,Gonçalves LS,Stud Health Technol Inform,2020,2020-06-24,,,10.3233/SHTI200378,"OBJECTIVE: To perform a cross-mapping study between nursing documentation from a 
 Electronic Health Record (EHR) of a Brazilian hospital and four nursing 
 terminology systems.
 METHOD: Descriptive, quantitative and retrospective study.
 RESULTS: The EHR presents a total of 247 anamnesis / physical examination terms, 
 75 nursing diagnoses, and 205 nursing interventions terms to nurses make their 
 choice.
 CONCLUSION: Authors strongly recommend that attempts in building more usable and 
 friendly EHRs for clínical care practice documentation consider classification 
 systems structures in their development, to ensure complete, safe, 
 evidence-based and comparable registries.
",,,,
32570380,Feasibility of Using EN 13606 Clinical Archetypes for Defining Computable Phenotypes,"Tapuria A, Kalra D, Curcin V.",Stud Health Technol Inform. 2020 Jun 16;270:228-232. doi: 10.3233/SHTI200156.,Tapuria A,Stud Health Technol Inform,2020,2020-06-24,,,10.3233/SHTI200156,"INTRODUCTION: Computable phenotypes are gaining importance as structured and 
 reproducible method of using electronic health data to identify people with 
 certain clinical conditions. A formal standard is not available for defining and 
 formally representing phenotyping algorithms. In this paper, we have tried to 
 build a formal representation of such phenotyping algorithm.
 METHODS: We built EN 13606 EHR standard for building clinical archetypes to 
 represent the computable phenotyping algorithm for 'diagnosis of cardiac 
 failure'. As part of this work, we created a set of new clinical archetypes for 
 defining 'cardiac failure diagnosis'. The EN13606 editor called Object 
 Dictionary Client was used which was in-house developed by University College 
 London. We evaluated the ability of EN 13606 to provide clinical archetypes to 
 define EHR phenotyping algorithms using the predefined desiderata for the 
 purpose [Mo et al].
 RESULTS: EN 13606 archetypes could represent phenotype components grouped and 
 nested based on their logical meaning. It was possible to build the EHR 
 phenotyping algorithm with the clinical elements and their interrelationships 
 along with hierarchical structure and temporal criteria. But the specific 
 mathematical calculation and temporal relations involved in the algorithm was 
 difficult to incorporate. These will need to be coded and integrated within the 
 clinical information system. These archetypes can be mapped for comparison with 
 the openEHR models. Binding to external clinical terminology is fully supported. 
 However, it does not satisfy all the desiderata defined by Mo et al. A possible 
 way could be an approach using phenotype ontologies and its architectural 
 representation integrated with ISO interoperability.
 CONCLUSION: The EN13606 archetypes can be used to define the phenotype algorithm 
 that basically identifies patients by a set of clinical characteristics in their 
 records. Phenotype representations defined in EN 13606 do not satisfy all the 
 desiderata proposed by Mo et al. and thus currently has a limited ability to 
 define the computable phenotyping algorithms. Further work is required to make 
 the EN13606 standard to fully support the objective.
",,,,